{
  
    
        "post0": {
            "title": "Não foi milagre",
            "content": ". O dia da independência de Israel não é nada mais que uma segunda comemoração de Chanuka. Yom haAtzmaut (Dia da Independência em hebraico) celebra o começo de uma soberania judaica na Terra de Israel, pela primeira vez desde a soberania conquistada pelos macabeus, cerca de dois mil anos antes. . É difícil saber onde uma festa começa e a outra acaba. Enquanto que é claro para todos que as tradições relacionadas a Yom haAtzmaut são bastante recentes, e obviamente não podem anteceder o próprio sionismo, é importante marcar que a festa de Chanuka como a conhecemos hoje é extremamente moderna, e é fruto da empreitada sionista. . Segundo o judaísmo rabínico, os macabeus não eram heróis. Para eles, toda a ideia da festa de Chanuka é que Deus “entregou heróis na mão dos fracos, e [entregou] os que eram muitos nas mãos dos poucos.” É assim que se lê na prece “Sobre os Milagre” (Al haNisim) de Chanuka, os heróis são os gregos, e os fracos dos judeus venceram apenas com a ajuda de Deus. . Nada disso!, disseram os primeiros sionistas, que criaram a organização Chibat Tzion, no final do século 19. Os macabeus foram resgatados como os verdadeiros heróis, aqueles cuja bravura os permitiu criar um Estado autônomo, contrariando todas as expectativas. Nada de milagres, nada de óleo que durou oito dias. Foi com os Chovevei Tzion (membros da Chibat Tzion) que Chanuka se tornou uma das festas mais importantes do calendário judaico. Há muitos outros exemplos de como a história dos macabeus inspirou o sionismo. . O pai do sionismo político, Theodor Herzl, termina seu livro “O Estado Judeu” com a seguinte frase: . Portanto, eu acredito que uma maravilhosa geração de judeus se formará. Os macabeus se levantarão novamente. Deixe-me repetir minhas primeiras palavras: Os judeus que desejarem um país o terão. Finalmente viveremos como pessoas livres em sua própria terra, e morreremos em paz em nossas próprias casas. O mundo será libertado por nossa liberdade, enriquecido com nossa riqueza, e engrandecido com nossa grandeza. E o que quer que tentemos realizar para o nosso próprio bem estar, terá efeito poderosamente e beneficialmente para todas as pessoas. . Segundo Herzl, a criação de um Estado Judeu é uma segunda versão da história dos macabeus. Max Nordau, braço direito de Herzl no movimento sionista, criou o conceito de judaísmo dos músculos. “A história do nosso povo nos conta que um dia fomos fortes fisicamente, mas hoje este não é o caso,” disse Nordau em um discurso no segundo Congresso Sionista Mundial, em 1898 na Basileia. “Ninguém pode nos negar a atividade física necessária para fazer os nossos corpos novamente saudáveis. Nós renovaremos nossa juventude […], desenvolveremos peitos largos, braços e pernas fortes, um olhar corajoso. Seremos guerreiros […] Vida longa ao esporte! Que os clubes de esporte hebraicos avancem e floresçam!” . Seguindo a visão de Nordau, foram criados diversos clubes judaicos e movimentos juvenis, muitos dos quais se uniram sob uma só organização chamada Macabi. É bem verdade que essa cultura de valor à força do corpo tem muito mais a ver com a cultura grega contra a qual os Hasmoneus lutaram em sua revolta, mas nós não deixaremos os fatos nos confundir. Seguimos. . O educador David Judelovitch, que fundou em 1888 a primeira escola hebraica do mundo (segundo ele), em Rishon leTzion, organizava bailes em Chanuka, e também introduziu um desfile com tochas pelas ruas da cidade durante a festa das luzes. Judelovitch era membro da organização de pioneiros sionistas Bilu, que em um de seus posters de 1882 diziam: “Onde estão os macabeus? Judá [o macabeu] há de se levantar!” . O desfile de tochas de Chanuka se espalhou pelos assentamentos da região, e bastante mais tarde a tradição foi adaptada a uma corrida de revezamento de tocha. A tradição olímpica do revezamento de tochas começou nas Olimpíadas de Berlim, em 1936. Como reação, o movimento juvenil Macabi haTzair (O Jovem Macabeu) introduziu em Chanuka de 1944 a tradição de fazer um revezamento de tochas desde o túmulo dos macabeus, ao lado de Modiin, com direção a diversas cidades. Em Chanuka de 1949, o Batalhão Jovem (Gadna = גדנ״ע) introduziu a corrida de oito tochas, que começavam em partes diferentes do país, e todas chegavam ao Monte Herzl, para serem recebidas pelo primeiro-ministro. . Abaixo vemos uma corredora levando a tocha de Chanuka, acesa em Modiin, a Jerusalém para o acendimento da Menorá de Chanuka. Dezembro de 1948, Central Zionist Archives. . . Em um artigo anterior, eu notei a tensão existente dentro da festa de Chanuka, entre os motivos religiosos e os nacionais. Mostrei então diversas canções dos dois lados, mas guardei para hoje uma das mais importantes. Trata-se de “Nós carregamos tochas” (Anu nos’im lapidim = אנו נושאים לפידים), de Aharon Zeev. . Nós carregamos tochas // Em noites escuras // As trilhas brilham sob nossos pés // E quem tiver coração // Quem tiver sede de luz // Levantará seus olhos e a nós // E virá à luz! . Não nos aconteceu um milagre // Uma latinha de óleo não encontramos // Ao vale andamos, subimos ao montes // As fontes de luz // Escondidas, encontramos. . Não nos aconteceu um milagre // Uma latinha de óleo não encontramos // Carvamos a pedra até sair sangue // E que haja luz! . Escutem aqui a canção. . Está claríssimo que a canção, escrita em no começo dos anos 1930, fala ao mesmo tempo da guerrilha dos macabeus e dos movimentos armados do Yishuv (população judaica da Palestina pré-1948). O autor não só tira o milagre do óleo para fora da festa, ele ainda toma para si a criação da luz do Gênesis. . O novo judeu da Terra de Israel não foi moldado segundo o judeu diaspórico, muito pelo contrário. Ele é forte e sabe o que quer, dono de seu destino, assim como os macabeus o eram. Vejamos este selo do Keren Kayemet leIsrael (Fundo Nacional Judaico), da década de 1950. Vemos um agricultor com uma arma, e a sombra de um macabeu por trás dele. Sabemos que é um macabeu porque em cima está escrito Dinheiro de Chanuka (dmei chanuka), e abaixo o valor de 25 centavos, o valor do selo. . . A tradição laica da festa de Chanuka que se formou durante as décadas que precederam a independência de Israel foi simplesmente adaptada, e transposta para outro mês do calendário. O auge da cerimônia oficial de Yom haAtzmaut, que dá início às comemorações, é o acendimento de 12 tochas, representando as tribos de Israel e a união do povo. . À esquerda um cartaz de 1951 sobre o Dia da Independência, à direita um cartaz de 1950 sobre a corrida de tochas de Chanuka. Mera coincidência? . . Hoje, a canção “Nós Carregamos Tochas” pode ser escutada tanto no inverno, durante a festa de Chanuka, quanto na primavera, quando cai o Dia da Independência. Abaixo, podemos ver o presidente da Knesset, o deputado Yuli Edelstein, na cerimônia oficial de Yom haAtzmaut de 2015 no Monte Herzl, em Jerusalém. Enquanto ele discursa antes do acendimento da primeira tocha, escutamos ao fundo a canção “nós carregamos tochas”. . Durante seus primeiros séculos, a festa de Chanuka ainda não tinha os elementos religiosos como conhecemos, principalmente o milagre do óleo. A explicação de porque a festa dura oito dias tem a ver com a festa de Sukot, uma das três peregrinações anuais a Jerusalém. Com a inauguração do templo de Jerusalém após sua reconquista em 164 AEC, os judeus puderam comemorar a festa de Sukot tardiamente, o que dá sete dias e mais um de Shmini Atzeret. . Por um lado, Chanuka tem dentro de si a comemoração tardia de Sukot. Por outro lado, durante as décadas que precederam a independência de Israel, Chanuka era uma comemoração antecipada da esperada autonomia judaica. Foi assim que neste último século estas duas festas evoluiram juntas, e são duas faces de uma mesma comemoração nacional de soberania judaica. . Feliz Chanuka! Feliz Yom haAtzmaut! . Fontes: Zeev Galili, United with Israel, My Jewish Learning, Zemereshet, Jpress, Jpress, Shalom Hartman Institute, Palestine Poster Project, Wikipedia, Rashut haShidur, Museum of Family History, Gutenberg.org, WikiSource. .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/nao-foi-milagre.html",
            "relUrl": "/markdown/2022/02/01/nao-foi-milagre.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Maoz Tzur: massacre e vingança",
            "content": ". Maoz Tzur, a canção mais conhecida de Chanuka, fala de massacre e vingança, e ainda sim é uma das favoritas das crianças. Em Israel, faz parte da sequência “oficial” do acendimento das velas: acendem-se enquanto duas bençãos são feitas, e logo após, sem perder um milionésimo de segundo, todos começam a cantar Maoz Tzur. . A melodia é linda, exaltante, e apropriada para ser cantada em coro, com toda a família. Contudo, a letra não é muito clara para a maior parte dos israelenses. Talvez isto explique o seu sucesso, não sei bem… Neste momento em que escrevo estas palavras, minha filha está assistindo um programa israelense no youtube, onde Rinat, a rainha dos baixinhos, canta Maoz Tzur para um grupo de crianças. É incrível a cara que ela faz enquanto diz as palavras “No momento em que [Deus] preparar o massacre dos inimigos que latem”. . Mordechai . Mordechai, autor do poema, era um cara modesto, e colocou as 5 letras de seu nome (מרדכי) abrindo as cinco primeiras estrofes (são 6 no total, a parte que todos cantam é a primeira estrofe, e “ninguém” conhece o resto). Quem é Mordechai? Ninguém sabe. . O que sim sabemos é que o poema data dos anos 1200, no que hoje chamamos de Alemanha. Essa era uma época difícil aos judeus europeus, com a perseguição “normal” exacerbada pelas cruzadas. . Pode ser que se trate do rabino Mordechai Ben Hillel, de Nuremberg. Ele é muito conhecido por seu livro de decisões acerca da halachá (lei judaica), e também escreveu um livro de poemas e lamentações, onde assinava suas obras como “Mordechai”. Nasceu em 1250, e morreu (juntamente com sua esposa e filhos) em primeiro de agosto de 1298, no pogrom de Rintfleisch. . Também pode ser que o autor seja o poeta Mordechai ben Yitzhak HaLevi, nascido na Itália, e que mais tarde se mudou para Mainz. Seu sogro teria sido morto durante os massacres de Rhineland, em 1096, durante a primeira cruzada. . Seja quem for que escreveu Maoz Tzur, fica claro que a perseguição aos judeus é um fator essencial para entendermos a temática do poema. . Pessach, Babilônia, Purim e Chanuka . Maoz tzur conta a história do povo judeu, e como Deus salvou seu povo escolhido em quatro momentos diferentes. . A segunda estrofe fala do êxodo do Egito. . “Minha alma se saciou de tragédias, com tristeza minha força se apagou.Minha vida eles amarguraram com dificuldades, na escravidão no reino do Egito.E com sua grande mão [Deus] tirou dali seu povo especial.Enquanto o exército do faraó desceu às profundezas como uma pedra.” . A terceira estrofe trata do final do exílio da Babilônia. . “Ele me trouxe ao seu lugar mais santo, e mesmo ali não descansei.O opressor veio e me exilou, pois eu tinha deuses estranhos,e bebia vinho venenoso. Mas eu nem havia chegado,A Babilônia caiu e Zorobabel [veio], em setenta anos fui salvo.” . A quarta estrofe reconta o milagre de Purim. . “O Agagita filho de Hamedata [Haman] queria cortar o cipreste [Mordechai].Mas acabou sendo-lhe um embuste e obstáculo, seu orgulho se silenciou.Você levantou a cabeça do benjamita [Mordechai], e riscou o nome do inimigo.Os seus vários filhos você enforcou numa árvore.” . Finalmente, na quinta estrofe chegamos a Chanuka: . “Os gregos se juntaram contra mim nos tempos dos Hasmoneus.E derrubaram os muros de minha torre, e deixaram todo o óleo impuro.E do último dos frascos, foi feito um milagre às rosas [ao povo judeu].[Então] os sábios determinaram os oito dias de canções de alegria.” . O começo e o final . Maoz Tzur não foi escrita como canção de Chanuka, acabamos de ver isto acima. Como foi então que esta poesia tornou-se um símbolo de Chanuka e não de Pessach ou de Purim? . A primeira e última estrofes são as únicas no tempo presente, e dizem o seguinte: . “Minha fortaleza, rocha de minha salvação, é agradável Te louvar.Estabeleça a minha casa de preces [o templo de Jerusalém], e ali Lhe faremos sacrifícios de agradecimento.Quando você massacrar os inimigos que latem,Então terminarei cantando um hino à inauguração [chanuka] do altar.” . Última estrofe: . “Revele o Seu santo braço e aproxime a redenção.Traga vingança ao povo mau, em nome de Seus servos.Pois [a salvação] já demorou muito para chegar, e os dias de maldade não têm fim.Empurre o vermelho [Esaú, representando o cristianismo] às sombras, e nos estabeleça sete pastores [que libertarão Israel da opressão, Miquéias 5:4].” . Antes de mais nada: não é uma temática para música infantil. Ficou claríssimo. Mas a Marselhesa também não é (Às armas, cidadãos, // Formai vossos batalhões! // marchemos, marchemos! // Que um sangue impuro // Banhe o nosso solo!), e milhões de criancinhas também a cantam… . Provavelmente porque a palavra Chanuka aparece na primeira estrofe (literalmente no sentido de inauguração e consagração!), a associação com esta festa é inevitável, e no final das contas ninguém lembra de Pessach e Purim quando se fala de Maoz Tzur. . A última estrofe só foi aparecer pela primeira vez há cerca de 200 anos, em Amsterdã. Não se sabe se ela é mais recente, ou se faz parte do poema original, e foi censurada por conta do tema da vingança, para não gerar mais perseguições. Alguns dizem que faz sentido que a estrofe tenha sido escrita junto com o resto, porque as primeiras letras de suas três primeiras palavras formam Chazak (חזק), ou seja, “forte”. Novamente, é tudo especulação. . A melodia . A melodia é uma adaptação de uma canção folclórica alemã, “So weiss ich eins, dass mich erfreut, das pluemlein auff preiter heyde”. A mesma canção parece ter sido adaptada por Martinho Lutero para seus corais, e podemos avaliar as semelhanças no vídeo abaixo (coral “Nun freut euch, lieben Christen g’mein”) com harmonia de Bach. . Antes mesmo da fundação de Israel, as crianças aprendiam Maoz Tzur no jardim de infância, e depois iam para casa e ensinavam a seus pais. Possivelmente, isto explica a sua hegemonia absoluta. É interessante notar que Maoz Tzur não aparecia em nenhum livro de poesias ou cânticos dos judeus sefaraditas. Com sua imigração massiva nos anos 1950 e 1960, os sefaraditas também adotaram Maoz Tzur dos ashkenazitas que já estavam em Israel. . . . Fontes: YNET, YNET, Simania, ZeevGalili, Wikipedia, Wikipedia. . Imagem de destaque: Mosaico de menorá, século 6 EC, de uma sinagoga na Tunísia. Fonte: ancienthistory. .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/maoz-tzur.html",
            "relUrl": "/markdown/2022/02/01/maoz-tzur.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "O israelense otário",
            "content": ". O maior medo do israelense, maior do que uma guerra nuclear com o Irã, maior que o medo da morte, é o medo de ser Frayer. Em uma palavra, frayer é o otário, mas nós já vamos entender melhor o que isso significa. O pavor de ser frayer acaba modelando a vida do indivíduo e da sociedade como um todo, e conhecer isto é indispensável para se poder entender o que é ser israelense. . Etimologia . Frayer (פראייר) vem do alemão Freier, que significa “pretendente”, um homem solteiro que procura uma mulher (Frau). De pretendente, freier ganhou o novo significado de “aquele que costuma ir a prostitutas”, e também “aquele que é fácil engana-lo, rouba-lo, a vítima de uma trambicagem”. A palavra migrou ao Leste, e entrou no polonês e no russo. Em polonês freier significa ladrão. Já no início do século XX, freier ganhou na linguagem popular russa o significado de “aquele que se deixa levar, pessoa ingênua, boba e sem experiência, no melhor dos casos apenas um cara que não é nem ladrão nem criminoso”. A palavra chegou ao hebraico pelo idish, língua dos judeus da Europa oriental, e a gíria “frayer” claramente tem um significado bastante parecido ao do russo. Em hebraico se usa frayer com o verbo sair: ser otário se diz sair frayer (latzet frayer = לצאת פראייר). . Exemplos . Antes de discutir sobre o que significa ser frayer, citarei dois exemplos para entrarmos no clima. Todos são verdadeiros, e vivenciados por mim (aproximadamente). A pergunta que o israelense sempre faz, e que guia o seu comportamento, é: Que-que é? Eu tenho cara de otário?? (Ma, ani frayer? = מה, אני פראייר ). . 1 – Domingo é o dia em que os soldados de todo o país voltam para suas bases, após o fim de semana. Jovens de 18 a 21 anos se amontoam nas rodoviárias tentando pegar o primeiro ônibus que puderem, e a cena não é nada bonita. Não existe fila para subir no ônibus, não existe respeito pelo espaço do outro. Quem tiver cotovelos mais ousados vai ganhar um lugar. Os civis que também querem subir no ônibus não tem tratamento diferenciado, eles também empurram e são empurrados. É cada um por si, e Deus por todos. A velhinha pede passagem, e o soldado com espinhas na cara não dá, senão não vai ter mais lugar na janela. “Que que é? Eu tenho cara de otário?” . 2 – Saguão de embarque de um aeroporto em uma capital européia. Destino: Tel Aviv. Aos poucos os israelenses que estão voltando para casa se reúnem em volta do portão de embarque e amigavelmente conversam com seus compatriotas sobre as agradáveis histórias das férias. Todos embarcam sem demais complicações, e o avião decola. Ao longo do curto voo, uma inquietação crescente pode ser sentida. Tão logo o avião aterrisa, os amigaveis compatriotas tornam-se feras, a cordialidade desaparece e cada um só pensa em ser o primeiro a sair do avião, o primeiro a passar pela imigração, o primeiro a pegar as malas. Dois colegas de voo, que sentaram juntos na fileira 17, agora se ignoram, e fazem a conhecida ‘marcha atlética’ em direção ao primeiro táxi livre. “Que que é? Eu tenho cara de otário?” . O que significa ser frayer? . Gadi, o personagem principal do sitcom israelense A Vida Não É Tudo (hachaim ze lo hakol = החיים זה לא הכל), explicou desta forma: . “Para ser um frayer é preciso de duas pessoas: O frayer e aquele que faz do frayer um frayer”. . . Uma pessoa não pode ser frayer apenas porque se deu mal em certa situação. O frayer surge quando alguém tem medo de ser transformado em frayer, e como estratégia preventiva, faz de outro um frayer. Esse raciocínio é conhecido como “a armadilha hobbesiana”. Em “O Leviatã”, Hobbes escreve: “Pois a natureza dos homens é tal que, embora sejam capazes de reconhecer em muitos outros maior inteligência, maior eloqüência ou maior saber, dificilmente acreditam que haja muitos tão sábios como eles próprios”. Acertou em cheio, taí uma boa caracterização do israelense médio. Hobbes continua: “E contra esta desconfiança de uns em relação aos outros, nenhuma maneira de se garantir é tão razoável como a antecipação; isto é, pela força ou pela astúcia, subjugar as pessoas de todos os homens que puder, durante o tempo necessário para chegar ao momento em que não veja qualquer outro poder suficientemente grande para ameaçá-lo.” Nota 10 para o Thomas. . O mecanismo descrito acima funciona quando o Leviatã (o Estado) não está presente, e esta é a grande diferença entre o não-frayer israelense e o jeitinho brasileiro. A grande maioria dos casos de “frayerismo” (frayeriut = פראייריות) são os de furar fila, empurrar, grosseria verbal para ganhar alguma vantagem, etc. Muitas são as vezes que um amigo israelense me conta uma história e eu a imagino acontecendo no Brasil. Uns colegas foram acampar ilegalmente numa reserva natural no deserto do Negev, e foram surpreendidos por um fiscal. Eles pagaram a multa (cara) sem dizer nada e foram levados embora. Ninguém pensou em molhar a mão de ninguém. Neste caso eles não foram frayerim, pois ninguém os fez de frayer, mas esta é exatamente a perfeita situação para o jeitinho brasileiro entrar em ação. . Os israelenses estão aprendendo a fazer fila, embora num ritmo pouco satisfatório para o meu gosto. Apenas há alguns anos atrás senhas com números foram introduzidas em farmácias e bancos para dar ordem na bagunça. Na agência de correio perto de casa não há senhas, e quem chega pergunta “quem é o último?”, essa é a regra. As pessoas não ficam de pé em fila, ficam cada um em seu canto, lendo jornal ou jogando candy crush no celular. Nos 10 ou 15 minutos que normalmente levo para ser atendido, eu tenho que ficar esperto pra ver se ninguém vai furar a fila, é uma tensão constante. Na última vez que fui à farmácia um cara sem senha queria ser atendido quando o meu número foi chamado. “Eu não sabia que tinha que pegar uma senha”. Acabamos discutindo e fazendo um mini-barraco, até que eu fui atendido. Eu estava segurando a minha filha de um ano e meio no colo, e ele estava acompanhado do filho de 10 anos. Ele não teve vergonha nenhuma de mostrar ao filho como é que se faz para não dar uma de frayer, mas eu sim fiquei com vergonha de ter caído na “armadilha hobbesiana”. . A intervenção do Estado não é a única maneira de controlar a “síndrome do frayer”. Normas sociais são tão ou mais importantes. Os pesquisadores Luis Roniger e Michael Feige publicaram em 1992 o artigo “A cultura do frayer e a identidade israelense” no periódico Alpaim, onde explicam o fenômeno do frayer como uma mudança de identidade de gerações na sociedade israelense. A primeira geração, a das primeiras aliot (primeiras ondas de imigração judaica à Palestina), se auto identificava como pioneira, a segunda geração como sabras (israelenses natos), e a terceira geração é caracterizada pela cultura do não-frayer, que surgiu como crítica interna à cultura das gerações que a antecederam. A primeira geração de pioneiros queria realizar um ideal, e por isso o sacrifício pessoal para o bem do coletivo era bem visto e esperado. Sempre houve a opção de não contribuir com o coletivo, mas não havia a mesma legitimação como há hoje. A cultura do não frayer é uma expressão profundamente anti-ideológica, seus heróis não se sacrificam pelos outros, muito pelo contrário, lutam pelos seus interesses pessoais. A cultura do não-frayer nos mostra a mudança na percepção do que é força: para os pioneiros, a força do indivíduo derivava de sua integração na narrativa de renascimento nacional e sua abdicação pessoal para o bem de todos. O frayer simboliza a queda da fonte de poder do coletivo ao indivíduo. Se o indivíduo não está disposto a se sacrificar, a força do coletivo sofre, e a longo prazo os próprios interesses do indivíduo podem ser atingidos. Esse é o paradoxo que Roniger e Feige indentificam na cultura do frayer. . O “Protesto dos Otários” (mechaat hafrayerim = מחאת הפראיירים) vem lutar exatamente contra uma crescente percepção de que aquele que faz exército e se sacrifica pelo país é frayer. Assim como as “vadias” da marcha das Vadias e os palmeirenses que se chamam orgulhosamente de “porco”, esses “otários” surgiram após os grandes protestos sociais de 2011 para exigir que a lei de serviço militar obrigatório fosse cumprida por todos, sem exceções. Se o jovem judeu ortodoxo é liberado de três anos de um duro serviço militar e pode ficar estudando Talmud no conforto de sua yeshiva, por que um jovem laico teria que carregar o fardo adicional em seus ombros, e dar uma de otário? O protesto dos otários veio tentar acabar com a crescente espiral que levaria o serviço militar a entrar na lista de coisas onde é aceitável e esperado de cada um lutar por si só, como na fila de correios e bancos, trânsito e tantos outros. . Faixa do “Protesto dos Otários” que diz “todos devem fazer serviço militar” . “Otária” . “Eu também sou otário/a, se eu fosse aluno de uma yeshiva, eu estudaria grátis.” . Toda a discussão acima trata do significado mais restrito do que significa ser frayer: uma pessoa que se dá mal porque fulano (normalmente seu par, peer em inglês) o ferrou antes que ele mesmo tivesse se dado mal. Existe também o sensu lato, ou seja, uma pessoa que apenas se deu mal, sem um agente externo que propositadamente pôs uma pedra em seu caminho. Exemplo clássico: se eu compro um produto e depois, conversando com um amigo, fico sabendo que ele pagou muito menos, eu claramente dei uma de frayer. Se eu pago altos preços por certos produtos que são sujeitos a um monopólio, ou se pago altos impostos, também posso me sentir um frayer. O famoso grupo de hip hop HaDag Nachash escreveu a música “Não Somos Otários” (Lo Frayerim = לא פראיירים), onde o refrão diz ironicamente “Faremos serviço de reserva do exército, pagaremos os impostos, Ficaremos no engarrafamento, ninguém nos fode, Nós com certeza, certeza, certeza não, Nós com certeza não somos otários”. . Para terminar, não gostaria de passar a impressão de que Israel é uma selva, e que por aqui “homo homini lupus” em toda circunstância. São relativamente poucos os que se preocupam muito em não dar uma de frayer o tempo todo, mas eles certamente fazem muito barulho e estrago. Visitar Israel e voltar dizendo que “tem muita gente mal educada” não ajuda nada, e espero ter contribuido para explicar um pouco o choque que alguns novatos (e veteranos também) sentem quando são postos à prova por aqui. A sociedade israelense não é unicamente caracterizada pela síndrome do não-frayer, e há muitos outros fatores que a caracterizam, pelo bem e pelo mal. Em futuros textos abordarei outras características da sociedade israelense, como o “espaço pessoal”, a “inter-conectividade” e outros. . . . Fontes: . Steven Pinker, The Better Angels of Our Nature: Why Violence Has Declined | Thomas Hobbes, O Leviatã | Luis Roniger e Michael Feige, Tarbut haFrayer vehaZehut haIsraelit. Para ler o artigo em hebraico, entre neste site e faça download do terceiro artigo. | Canção “Lo Frayerim”, da banda HaDag Nachash. Letra em hebraico, português e transliteração no site Shirim em Português. | .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/israelense-otario.html",
            "relUrl": "/markdown/2022/02/01/israelense-otario.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Hino dos partisans judeus",
            "content": ". Em 1943, as notícias do levante do Gueto de Varsóvia se espalharam rapidamente, chegando aos ouvidos de Hirsch Glick, jovem judeu lituano de 21 anos, que morava no Gueto de Vilna. Os mais famosos partisans judeus, liderados por Mordechaj Anielewicz, inspiraram Glick a escrever um poema em yiddish, cuja primeira estrofe de esperança dizia: . Não diga: “este é meu último caminhoO céu tenebroso escondeu a luz do dia”Este é o dia que esperávamos que chegasseE a nossa marcha ainda trovejará “estamos aqui”! . A jovem Rachel Margolis, integrante da “Organização Partisan Unida”, o grupo da resistência judaica do gueto, ouviu Hirschke (como ela o chamava carinhosamente) declamar seu poema com emoção e, imediatamente, lhe veio à cabeça uma melodia soviética para acompanhar a poesia. Trata-se de uma mar cha dos irmãos Dmitri e Daniel Pokrass, judeus da União Soviética, que a compuseram para uma poesia de Alexey Surkov, para fazer parte de um filme de 1938. . Os irmãos Pokrass contaram mais tarde que sua marcha foi baseada na melodia da famosíssima canção yiddish “Oyfn Pripetshik”, aquela que Spielberg, bastante mais tarde, usaria na inesquecível cena da menina do casaco vermelho na Lista de Schindler. Isto de certa forma fecha um ciclo, acho eu. . A canção “Zog Nit Keynmol” (são as primeiras palavras em yidish) se espalhou rapidamente pelo gueto e muito além dele, nos outros guetos, nos campos de concentração, e pelas florestas onde os partisans se escondiam. Claro que a canção também chegou ao Yishuv na Palestina, onde o poeta Avraham Shlonsky a traduziu ao hebraico, publicando-a em fevereiro de 1945 no diário HaMishmar. Eu não falo yiddish, então ofereço-lhes no final deste artigo a tradução ao português da letra em hebraico. . Até aí era a história que eu queria contar, de como surgiu o Hino dos Partisans Judeus. Fazendo a pesquisa para este texto, acabei conhecendo um pouco quem foi Rachel Margolis, e a ela eu dedico este artigo. . Rachel Margolis . Rachel Margolis tinha 20 anos quando a Lituânia foi invadida pelos nazistas. Elas encontrou refúgio em uma família de cristãos, mas acabou optando em ir ao gueto de Vilna, para se juntar à resistência judaica. . “Todos estavam ansiosos por lutar. Nossa missão era adquirir armas, completar preparações militares, tudo isto com o objetivo de fazer um levante no gueto. Se morrêssemos, seria com honra, tendo provado à humanidade que não somos ovelhas indo silenciosamente ao matadouro.” . A comparação com ovelhas é familiar, e não por acaso. Esta é uma frase famosa de Abba Kovner, comandante da Organização Partisan Unida da qual Rachel fazia parte. . O gueto de Vilna foi liquidado em junho de 1943, e apenas algumas centenas de judeus conseguiram escapar. Rachel foi às florestas lutar com a resistência, explodindo pontes e linhas de trem, essenciais para o abastecimento dos alemães. . Rachel foi a única pessoa de sua família a sobreviver o holocausto; seu pai, sua mãe, e seu irmão foram mortos somente alguns dias antes da liberação da Lituânia em julho de 1944. Depois da guerra, Rachel continuou morando na Lituânia. Ela recebeu um PhD em biologia, e lecionou até os anos 1980. Ela também fundou um museu do holocausto, chamado de Casa Verde de Vilna. . Enquanto era estudante de biologia no final dos anos 1940, Rachel foi voluntária na Universidade de Vilna em um museu judaico. Foi então que dois poetas yiddish, temporariamente responsáveis pelo museu, contaram-lhe sobre Kazimierz Sakovicz. Sakovicz era um jornalista polonês católico, que testemunhou o massacre de Ponár, e o relatou em um diário. Quando ele entendeu que talvez não sobrevivesse a guerra (ele morreu durante o levante polonês conhecido como Operação Tempestade), enterrou em seu jardim pedaços de seu diário, dentro de jarros. Depois da guerra, seus vizinhos desenterraram os jarros e os levaram ao museu judaico. Contudo, Margolis teve que esperar até o colapso da União Soviética em 1991 para finalmente ter acesso a estes documentos. Ela transcreveu e reconstituiu meticulosamente o diário de Kazimierz Sakowicz. Com a edição do historiador israelense Yitzhak Arad (ele também participou da resistência judaica e da soviética), o livro foi publicado sob o título “Diário de Ponary, 1941-1943: O relato de uma testemunha de uma assassinato em massa”. Em Ponár foram mortos cerca de 100 mil pessoas pelas mãos da SS e de colaboradores lituânos. Dentre os cerca de 70 mil judeus mortos, está a família de Margolis. . Rachel escreveu suas memórias da guerra e da resistência no livro “Uma Partisan de Vilna”. Um dos relatos do livro foi tirado de contexto por antissemitas lituanos, que acusaram a resistência judaica de cometer uma “atrocidade comunista” na batalha Kanyuki. Em um artigo de Gordon Brown, ex-premiê britânico, ele conta que diferentemente da Alemanha, a sociedade lituana nunca passou por um período de reconciliação e arrependimento por seu passado nazista, e que há um debate ideológico feroz de como descrever a colaboração de lituanos comuns com as forças de ocupação alemãs. . O novo nacionalismo dos países bálticos está reescrevendo a história, colocando a ocupação nazista em pé de igualdade com o regime soviético, misturando o que não pode ser misturado. Uma comissão lituana se propõe a investigar os crimes dos “regimes de ocupação” (nazista e comunista), porém deixam de fora os crimes de genocídio cometidos por forças locais. Sobreviventes do holocausto, como Yitzhak Arad e outros, chegaram a ser investigados por crimes de guerra, sob a alegação de terem se juntado aos soviéticos na luta contra os nazistas! Rachel Margolis não foi deixada de lado e foi chamada para testemunhar a respeito das atividades de outra partisan, Fanya Brantsovsky. . Vale a pena repetir: judeus que participaram da resistência contra os nazistas estão sendo acusados de crimes de guerra. É a história sendo reescrita sob os nossos olhos, em pleno ano de 2017. . Com medo da intimidação imposta, Rachel Margolis, que já morava em Israel, não pôde mais voltar a visitar a Lituânia durante o verão, como costumava fazer. Ela faleceu em julho de 2015. Em memória a Rachel, aos partisans, e a todos os que foram mortos no holocausto, é mais importante do que nunca seguir dizendo: estamos aqui! . Hino dos partisans judeus . Versão em hebraico. A versão em yiddish está no final do texto. . Português Transliteração Hebraico . Não diga “este é meu último caminhoO céu tenebroso escondeu a luz do dia”Este é o dia que esperávamos que chegasseE a nossa marcha ainda trovejará “estamos aqui”!Da terra da tâmara até as remotas terras congeladasEstamos aqui em dores e tormentosE se uma gota de nosso sangue ali se derramarCertamente crescerá nossa bravuraA primeira luz da manhã iluminará nosso diaCom o inimigo nosso ‘ontem’ passara como uma sombraMas se Deus-nos-livre a luz tardar em virA canção será como um hino de geração em geraçãoCom sangue e chumbo ela foi escritaEla não é a canção dos livres e desimpedidosPois entre paredes que caem todo o povo a cantouCantaram juntos com revólveres nas mãosPortanto não diga “meu último caminhoO céu tenebroso escondeu a luz do dia”Este é o dia que esperávamos que chegasseE a nossa marcha ainda trovejará “estamos aqui”! | Al na tomar “hine darki haachrona”Et or hayom histiru shmei haananaZe yom nichsafnu lo od yaal veyavoUmitz’adenu od yar’im “anachnu po”!Meeretz hatamar ad yarketei kforimAnachnu po bemach’ovot veisurimUvaasher tipat damenu sham nigraHalo yanuv od oz ruchenu bigvuraAmud hashachar al yomenu or yahelIm hatzorer yachlof tmolenu kemo tzelAch im chalila yeacher lavo haorKemo sisma yehe hashir midor ledorBichtav hadam vehaoferet hu nichtavHu lo shirat tzipor hadror vehamerchavKi bein kirot noflim sharuhu kol haamYachdav sharuhu venaganim beyadamAl ken al na tomar “darki haarchrona”Et or hayom histiru shmei haananaZe yom nichsafnu lo od yaal veyavoUmitz’adenu od yar’im “anachnu po”! | אַל נָא תֹּאמַר: הִנֵּה דַּרְכִּי הָאַחֲרוֹנָה,אֶת אוֹר הַיּוֹם הִסְתִּירוּ שְׁמֵי הָעֲנָנָה.זֶה יוֹם נִכְסַפְנוּ לוֹ עוֹד יַעַל וְיָבוֹא,וּמִצְעָדֵנוּ עוֹד יַרְעִים: אֲנַחְנוּ פֹּה!מֵאֶרֶץ הַתָּמָר עַד יַרְכְּתֵי כְּפוֹרִיםאֲנַחְנוּ פֹּה בְּמַכְאוֹבוֹת וְיִסּוּרִיםוּבַאֲשֶׁר טִפַּת דָּמֵנוּ שָׁם נִגְּרָההֲלֹא יָנוּב עוֹד עֹז רוּחֵנוּ בִּגְבוּרָה.עַמּוּד הַשַּׁחַר עַל יוֹמֵנוּ אוֹר יָהֵל.עִם הַצּוֹרֵר יַחֲלֹף תְּמוֹלֵנוּ כְּמוֹ צֵל.אַךְ אִם חָלִילָה יְאַחֵר לָבוֹא הָאוֹרכְּמוֹ סִיסְמָה יְהֵא הַשִּׁיר מִדּוֹר לְדוֹר.בִּכְתַב הַדָּם וְהָעוֹפֶרֶת הוּא נִכְתַּב;הוּא לֹא שִׁירַת צִפּוֹר הַדְּרוֹר וְהַמֶּרְחָב,כִּי בֵּין קִירוֹת נוֹפְלִים שָׁרוּהוּ כָּל הָעָם,יַחְדָּיו שָׁרוּהוּ וְנאַגאַנִים בְּיָדָם.עַל כֵּן אַל נָא תֹּאמַר: דַּרְכִּי הָאַחֲרוֹנָהאֶת אוֹר הַיּוֹם הִסְתִּירוּ שְׁמֵי הָעֲנָנָה.זֶה יוֹם נִכְסַפְנוּ לוֹ עוֹד יַעַל וְיָבוֹא,וּמִצְעָדֵנוּ עוֹד יַרְעִים: אֲנַחְנוּ פֹּה! | . Versão em yiddish, cantada por Chava Alberstein. . . Imagem de destaque: Pilar da Bravura, no museu do holocausto Yad vaShem, em Jerusalém. Crédito da imagem, Flickr de Benjamin, segundo a seguinte licença Creative Commons. . Fontes: Zemereshet, Oneg Shabbat, YouTube, keene.edu, defendinghistory.com, Amazon, Academic Studies Press, Independent, Wikipedia 1 e 2. .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/hino-dos-partisans-judeus.html",
            "relUrl": "/markdown/2022/02/01/hino-dos-partisans-judeus.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Eu vos declaro sogro e genro",
            "content": ". O sogro é quem casa com o noivo, não a noiva. Pelo menos é assim que acontecia na época bíblica. Os exemplos são fartos e não deixam dúvida alguma. . E Salomão casou-se com Faraó, rei do Egito; e tomou a filha de Faraó… וַיִּתְחַתֵּן שְׁלֹמֹה, אֶת-פַּרְעֹה מֶלֶךְ מִצְרָיִם; וַיִּקַּח אֶת-בַּת-פַּרְעֹה 1 Reis 3:1 . A mulher é tomada, levada, e os dois homens, genro e sogro, são aqueles que se casam. Outro exemplo. . Nem te casarás com eles; não darás tuas filhas a seus filhos, e não tomarás suas filhas para teus filhos. וְלֹא תִתְחַתֵּן, בָּם: בִּתְּךָ לֹא-תִתֵּן לִבְנוֹ, וּבִתּוֹ לֹא-תִקַּח לִבְנֶךָ Deuteronômio 7:3 . É assim que Deus proíbe o povo de se misturar com os povos que já viviam em Canaã antes da chegada dos hebreus. As traduções acima são adaptações minhas, hoje em dia vocês encontrarão o verbo “aparentar-se” no lugar de casar-se. Em hebraico, a forma reflexiva hitCHaTeN (הִתְחַתֵּן) é usada nos dois exemplos, e indica que o casamento era a forma como dois homens (ou duas famílias) firmavam acordos e parcerias. Os termos para sogro e genro também tem a mesma raiz (CH-T-N). Sogro é CHoTeN (חוֹתֵן), e genro é CHaTaN (חָתָן). . Com o passar do tempo, Chatan ganhou o significado de noivo, e é o par de Kalá, a noiva. Assim diz uma das 7 bençãos proferidas no casamento judaico: “Se escutará nas cidades de Judá e nas ruas de Jerusalém, vozes de alegria e vozes de felicidade, voz do noivo e voz da noiva” ( יִשָּׁמַע בְּעָרֵי יְהוּדָה וּבְחוּצוֹת יְרוּשָׁלַיִם, קוֹל שָׂשׂוֹן וְקוֹל שִׂמְחָה, קוֹל חָתָן וְקוֹל כַּלָּה, adaptação de Jeremias 33:10-11). Contudo, a mesma frase entendida segundo o hebraico bíblico diz “voz do genro e voz da nora”. . E o que significa Kalá (כַּלָּה), a noiva ou nora? Vem da raiz KLL (כלל), que significa “completo” ou perfeito, embora muitas sogras insistam em discordar desta etimologia. Outras línguas semíticas tem a mesma palavra, como na língua acádia (kallatu) e arameu (kalta). . Antes de seguirmos adiante, uma curta observação. Choten é o sogro do noivo, mas o sogro da noiva tem outro nome: Cham (חָם). Assim, os sogros do noivo são Choten e Chotenet, e os sogros da noiva são Cham e Chamot. Cham é derivado do verbo ‘Amam (עמם), com o significado de congregar, juntar. Do mesmo verbo também são derivadas as palavras ‘am (עַם = povo), ‘im (עִם = com) e Gam (גַּם = também). . O hebraico, língua machista . Pois bem, vimos que na bíblia hebraica (Tanach), a mulher não é o sujeito no casamento entre genro e sogro, e sim o “objeto”. Será que não dá pra encontrar evidências que aliviem essa visão machista? Depende… . Como se diz esposo e esposa? Simples. Esposo é Ba’al (בַּעַל), que significa literalmente “dono”, ou “senhor”, e esposa é Isha (אִשָּׁה), que é literalmente “mulher”. A coisa não está bonita para o hebraico. Felizmente, quando alguém fala ba’al em hebraico no contexto de um casamento, sempre se entende “marido”, ninguém nunca pensa em “dono”. Da mesma forma que numa indústria textil do Brasil, “manga” é quase certamente a da roupa, e não a fruta. . Quem vem salvar o dia é o Tanach (pelo menos no que diz respeito a ba’al). Ao longo de todo o Tanach, “ishi” (אִישִׁי = meu homem) é usado 83 vezes com o sentido de marido. Assim, em Gênesis 16:3, lemos que . … tomou Sarai, mulher de Abrão, a Agar egípcia, sua serva, e deu-a por mulher a Abrão seu marido, ao fim de dez anos que Abrão habitara na terra de Canaã. (וַתִּקַּח שָׂרַי אֵשֶׁת-אַבְרָם, אֶת-הָגָר הַמִּצְרִית שִׁפְחָתָהּ, מִקֵּץ עֶשֶׂר שָׁנִים, לְשֶׁבֶת אַבְרָם בְּאֶרֶץ כְּנָעַן; וַתִּתֵּן אֹתָהּ לְאַבְרָם אִישָׁהּ, לוֹ לְאִשָּׁה) . Em contra-partida, ba’al é usado apenas 10 vezes no Tanach com o sentido de marido, e todas as vezes relacionado com o coito, que em hebraico se diz be’ilá (בְּעִילָה). Apenas mais tarde, na época do Talmud, a palavra ba’al tornou-se mais comum para designar o marido. . E assim ficou até os dias de hoje. De vez em quando se lê por aí que um grupo de pessoas (sempre mulheres) querem mudar o termo marido de volta para “ishi” (meu homem). Uma história interessante é a da parlamentar Ada Maimon. Conhecida por sua atuação pela igualdade dos sexos em Israel, Maimon pediu ao então primeiro-ministro David Ben-Gurion para que tratasse do tema. O primeiro-ministro, por sua vez, escreveu uma carta oficial ao ministro das finanças (datada de 5 de maio de 1953, veja imagem abaixo), pedindo que se trocasse a palavra “baali” por “ishi” em um dos formulários do governo. Segundo Ben-Gurion, “a palavra ba’al tem significado de autoridade e paganismo [Ba’al também é o nome de um deus de vários povos da região], e não se adequa ao princípio de respeito às mulheres, que tem direitos iguais aos dos homens.” Ben-Gurion, que amava o Tanach, ainda citou um versículo de Oséias 2:18 . … tu me chamarás meu homem; e não mais me chamarás meu senhor. תִּקְרְאִי אִישִׁי; וְלֹא-תִקְרְאִי-לִי עוֹד, בַּעְלִי. . Carta de Ben-Gurion de 1953 . O noivo, o premiado, e o circuncidado . É interessante notar que Chatan, além de noivo/genro, também é usado para designar alguém que ganhou um prêmio importante. Por exemplo, Shimon Peres é “chatan prás nobel” (חתן פרס נובל), ou seja, laureado com o prêmio Nobel. Em português a honra vem do louro, e em hebraico? O que tem a ver o prêmio com o genro/noivo? . Aqui o árabe, língua-irmã do hebraico, poderá nos ajudar. O “Hebrew and English Lexicon of the Old Testament” [Gesenius, 1850] diz que originalmente a raiz CH-T-N significava apenas “circuncidar”. Em árabe menino circuncidado se diz chatin (خَتِين), e circuncisão é chitan (ختان). A partir da grande festa que se faz na ocasião da circuncisão, a raiz CH-T-N ganhou o significado de “grande festa” e outras associações com os personagens principais de uma festa. Daí pode-se entender como em hebraico a raiz evoluiu para significar casamento (chatuná = חֲתוּנָּה) e seus envolvidos, o genro (chatan = חָתָן) e o sogro (choten = חוֹתֵן). . A raiz CH-T-N também é usada em hebraico para outras grandes festas além do casamento. É assim que chegamos ao “chatan prás nobel”, ou “aquele para quem se está fazendo uma grande festa pela ocasião do recebimento do prêmio Nobel”. Há outros usos de chatan, por exemplo na festa judaica de Simchat Torá. É nesta data em que se termina o pentateuco, com o Chatan Torá lendo a porção semanal “VeZot HaBracha”, e logo depois o Chatan Bereshit começando novamente o pentateuco com a porção semanal “Bereshit”. Mais um exemplo de uma grande festa, com duas pessoas honradas chamadas de chatan. Quando a homenageada é uma mulher, usa-se “kalá” (כַּלָּה = nora, noiva). . Já em árabe, a palavra “casamento” tem outra raiz, se diz zawaj (زَوَاج), e está ligada a zug (זוג) em hebraico, que significa “par, dupla”. [Zawaj.com é o JDate muçulmano, para quem estiver interessado… enquanto que judeus querem só um “date”, os muçulmanos querem zawaj mesmo.] Entretanto, em árabe a palavra chatan (خَتَن) é usada para “relacionamentos por meio de casamento”, como o inglês “in-law”. No hebraico de hoje, pode-se dizer que os pais e mães do noivo e da noiva são “mechutanim” (מחותנים), ou ligados por um casamento, mas este tratamento não passa a cunhados e demais familiares, vale apenas para os pais. . Na bíblica hebraica, o significado de circuncisão já havia se desconectado da raiz CH-T-N, com uma excessão interessantíssima. A história é a de Moisés, que está voltando ao Egito sob ordens divinas para libertar os hebreus do faraó. No meio do caminho, por algum motivo não explicado, Deus resolve matar Moisés. Vem então Zípora, sua esposa, e faz o seguinte: . Então Zípora tomou uma pedra aguda, e circuncidou o prepúcio de seu filho, e lançou-o a seus pés, e disse: Certamente me és um noivo de sangue. E desviou-se dele. Então ela disse: Noivo de sangue, por causa da circuncisão. וַתִּקַּח צִפֹּרָה צֹר, וַתִּכְרֹת אֶת-עָרְלַת בְּנָהּ, וַתַּגַּע, לְרַגְלָיו; וַתֹּאמֶר, כִּי חֲתַן-דָּמִים אַתָּה לִי. כו וַיִּרֶף, מִמֶּנּוּ; אָז, אָמְרָה, חֲתַן דָּמִים, לַמּוּלֹת. Êxodo 4:25-26 . Esta passagem faz tanto sentido em hebraico como em português: nenhum sentido. Mas, como já somos mais inteligentes, e sabemos que noivo (chatan) pode ser aquele em que se fez a circuncisão, tudo fica mais claro. A passagem acima foi e é ainda amplamente debatida pelos estudiosos judeus, com mil e uma explicações do porque Deus queria matar Moisés e como a circuncisão de seu filho o salvou. Destaco uma lenda (midrash) que diz que o anjo Uriel virou uma serpente e engoliu Moisés da cabeça ao pênis, deixando a ponta de fora. Zípora entendeu o recado e então cortou o prepúcio de seu filho para salvar o marido. O texto já estava longo, mas eu não pude deixar de fora este lindo midrash. . O que aprendemos? . 1 – O hebraico é uma língua machista, pois as pessoas há muito tempo atrás eram machistas. Muitas ainda o são até hoje. 2 – A raiz de três letras CH-T-N tem uma história fascinante. 3 – Os sábios que explicaram a Torá são muito criativos. . Nos próximos textos continuaremos a aprender o que a língua hebraica tem a nos ensinar sobre outros parentescos, como pais, mães, filhos, netos e primos. . Fontes: Safa-ivrit.org, Ynet, IsraelPost, Hebrew and English Lexicon of the Old Testament [Gesenius, 1850], midrash da história de Moises. .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/eu-vos-declaro.html",
            "relUrl": "/markdown/2022/02/01/eu-vos-declaro.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Ayin: o último som antes de vomitar",
            "content": ". O hebraico tem um som fascinante, representado pela letra Ayin. A melhor explicação que já escutei de como pronunciar é “fazer o som logo antes de vomitar”. Como não amar esta letra?! . Ayin é olho . Literalmente, Ayin significa “olho”. Os fenícios, pioneiros na criação do alfabeto, tomaram o hieroglifo egípcio “olho”, e fizeram dele uma letra redonda, também indicando olho, ou melhor, o primeiro som desta palavra. Do alfabeto fenício, a letra Ayin ganhou outras formas nas demais linguas semíticas, vejam: . . O grego e o latim criaram seus alfabetos baseados no alfabeto fenício, mas algumas das letras ali indicavam sons que Péricles e Rômulo não reconheceriam. Foi assim que o Ayin, de formato redondo, ganhou um novo significado, o da vogal O. . Ayin é passé . No hebraico que se fala hoje em dia em Israel, a letra Ayin não tem mais o seu som tradicional. Os imigrantes judeus à Terra de Israel durante a primeira metade do século 20 eram predominantemente da Europa, e portanto não sabiam pronunciar esta letra devidamente. Assim, o hebraico mainstream ficou sem este som, apesar da letra seguir sendo usada. A situação lembra o uso da letra H no português, que não tem som algum, e só é usada para manter-se a grafia histórica das palavras. (Olha só o H em “histórica”, que ninguém pronunciou! É mais ou menos assim no hebraico de hoje) . Os judeus do Norte da África e do Oriente Médio (chamados de “orientais” em Israel, mizrachim), que sabiam pronunciar corretamente o Ayin, quando chegaram em Israel na segunda metade do século 20, acabaram por adotar muitos dos costumes já instaurados, inclusive o abandono da pronúncia do Ayin. Hoje em Israel, apenas os mais velhos destas imigrações mantêm o Ayin, e nenhuma criança aprende a falar hebraico assim, mesmo que seus pais e avós o falem. Como eu sei disso? Minha esposa é professora, e deu aula em duas escolas no sul de Israel, onde boa parte da população é descendente dos “orientais”. Nenhuma das mais de 600 crianças com as quais esteve em contato pronunciava a letra Ayin. . Apesar das novas gerações não usarem o Ayin, muitas pessoas sabem pronunciar esta consoante, e o uso é feito em diversas circunstâncias. a. Para diferenciar duas palavras parecidas. Felicidade (osher = אושר) e riqueza (osher = עושר) começam com Alef e Ayin, respectivamente. Pode-se dizer “osher com Ayin”, ou então pronunciar logo o coitado do som que ficou para trás. E como faz pra não confundir as duas palavras quando fala-se “normal”, sem o Ayin? Do mesmo jeito que se diferencia a “manga” da salada de frutas com a “manga” da camisa. Contexto. b. Em humor, o uso do Ayin é um jeito fácil e imediato de caracterizar o personagem como “oriental”, e muitas vezes alguém de classe sócio-econômica mais baixa. c. Na música “oriental”. Hoje em dia a maior parte dos cantores de música mizrachit já nasceram sem falar o Ayin, apesar de escutarem o som em casa. Para dar autenticidade, o Ayin é fundamental quando eles cantam suas canções, mas é só a música acabar que seu uso é deixado de lado. Tem outra letra bem típica, o Chet, esse sim é outra hisória, provavelmente para outro artigo. Aqui não. . É só dar uma vomitadinha . A simpática Maha Yacoub é uma israelense palestina de Kfar Yassim, perto da cidade de Akko, em Israel. Hoje, ela mora na Itália, onde ensina árabe. Em seu canal do youtube “Learn Arabic with Maha”, que tem hoje quase 250 mil assinantes (um número MUITO alto), podemos encontrar vídeos que ensinam expressões, costumes, gramática, e claro, a fonética árabe. . Eu sempre achei que o som do Ayin se parece com o último som antes de se vomitar, mas a querida Maha acha que parece mesmo com estrangulamento. Seja como for, o que há de comum entre as duas explicações é que o som tem que vir bem do fundo da garganta, como resultado da compressão da faringe. Chega de falar, vejam a própria Maha explicando como é o Ayin em árabe. O vídeo tem 10 minutos, sugiro pular logo para o minuto 3:30, é bem divertido. . Ayin é tempo . A palavra mais comum para “tempo” em hebraico moderno é Zman, que vem na verdade do persa Zaman, cuja raiz tem o significado de andar. Em português o tempo voa, mas em persa ele vai a pé mesmo. . A palavra hebraica para tempo é ET, que se soletra Ayin Tav (עֵת). Esta é uma palavra feminina, conforme indicado pelo sufixo Tav. Tirando-se o sufixo, temos a mais pura essência do tempo: apenas a letra Ayin. Há vários anos minha professora do ulpan (escola de hebraico) me revelou este fato, e desde então estou coletando palavras hebraicas relacionadas com o tempo, todas com Ayin. Procurem a seguinte letra: ע. . Et – עֵת Significado: tempo, estação; era, época, idade Frase: לַכֹּל, זְמָן; וְעֵת לְכָל-חֵפֶץ, תַּחַת הַשָּׁמָיִם. עֵת לָלֶדֶת, וְעֵת לָמוּת; עֵת לָטַעַת, וְעֵת לַעֲקוֹר נָטוּעַ . Oná – עוֹנָה Significado: estação (do ano); período Frase: האביב הוא עונה של לבלוב ופריחה . Achshav – עַכְשָׁיו Significado: agora Frase: מה השעה עכשיו . Ad – עַד Significado: até; eternidade Frases: הוא יישאר כאן עד מחר; האדם אינו חי לעד . Adain – עֲדַיִן &amp; Od – עוֹד Significado: ainda Frases: הוא עדיין לא הגיע, עוד לא אבדה תקוותנו . Moed – מוֹעֵד Significado: um tempo específico; uma festa Frase: הוחלט להקדים ככל האפשר את מועד הוועידה . Sha’a – שָׁעָה Significado: hora; época, tempo Frases: מה השעה עכשיו; בשעה קשה זו עלינו להיות מאוחדים . Olam – עוֹלָם Significado: eternidade Frases: אהבתנו היא אהבת עולם, לְעוֹלְמֵי עוֹלָמִים . LeOlam, MeOlam – לְעוֹלָם, מֵעוֹלָם Significado: sempre (futuro e passado) Frases: מאז ומעולם; לעולם אזכור את ימי ילדותי היפים . Rega – רֶגַע Significado: momento, instante Frase: לפני רגע ראיתי אותו . Não fale assim . Amigos leitores, treinem dizer o som da letra Ayin, mas por favor, não falem hebraico usando-a. É legal usar este som para aprender a ortografia correta das palavras, ou para fazer graça dizendo ga’agu’a (געגוע). Esta última palavra, aliás, representa um conceito que não é exclusivo do português, “saudade”, o que parece que os israelenses não tem mais pela letra Ayin. .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/ayin.html",
            "relUrl": "/markdown/2022/02/01/ayin.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "As moedas do Estado Judeu: ontem e hoje",
            "content": ". A ideia é genial. Uma nação milenar decide mostrar a sua ligação à terra através de suas moedas. Assim, Israel resgatou a menorá do último rei Hasmoneu, a harpa do período de Bar Kochva, e o melhor de todos, a tamareira. Esta havia sido usada pelos romanos para representar o povo judeu derrotado, e agora é representada em toda a sua glória na mais alta das moedas, “pela redenção de Sião”. Chupa Titus Flavius! . Curtíssimos esclarecimentos . A moeda de Israel é o Shekel Novo, que em 1985 substituiu o Shekel, com taxa de conversão de 1 Shekel Novo para 1000 Shekels (medida tomada contra a hiperinflação dos anos 1980). Para evitar dizer Shekel Novo o tempo todo, direi simplesmente Shekel, e quando a intenção for o de antes de 1985, direi “Shekel Velho”. “Shekel Antigo” fica para a moeda usada há milênios atrás. AEC e EC significam Antes da Era Comum e Era Comum, respectivamente. . 1 agorá . A agorá é a menor divisão do Shekel, valendo um centésimo ou, em outras palavras, centavo. A moeda tem um valor tão baixo que o Banco de Israel decidiu interromper sua produção em 1991. . . O nome “agorá” foi proposto pela Academia da Língua Hebraica, já em 1960, quando a Lira Israelense deixou de ser dividida em 1000 prutot (prutá no singular), e precisava-se de um nome para “centavo”. Encontraram “agorá” no versículo 1 Samuel 2:36, onde “agorat kesef” (אֲגוֹרַת כֶּסֶף) é entendido como “um pedaço de prata”. . O desenho do navio foi herdado da moeda de 10 Shkalim Velhos (shkalim é o plural de shekel), uma vez que a taxa de conversão era 1 para mil. Veja a moeda de 10 Shkalim Velhos: . . Esta, por sua vez, herdou seu desenho de uma moeda de Herodes Arquelau, governador da Judeia (4 AEC – 6 EC), e sucessor de Herodes. Trata-se de uma galé, ou navio impulsionado por remos. Certamente é uma escolha interessante para o desenho da moeda moderna, dada a relação conturbada entre Herodes, seus filhos, e o povo judeu. . . 5 agorot . A moeda de 5 centavos também já não é mais produzida, desde 2008. . . Esta também é uma “herdeira natural” da moeda de 50 “Shkalim Velhos”. . . O desenho é de uma moeda do quarto ano da revolta judaica contra Roma (anos 69-70 EC), onde vemos as quatro espécies da festa de Sukot: no meio estão juntos o lulav (folha de palmeira), hadas (myrtus) e aravá (salgueiro), e de ambos os lados dois etrogim (cidras amarelas = Citrus medica). . . Claramente pode-se ler “Shnat Arba” (שנת ארבע) em hebraico, que significa “ano quatro”. A inscrição é feita com a antiga escrita hebraica, aquele que o Rei David conhecia. Sim, leitor, as familiares letras do hebraico que conhecemos hoje são na verdade letras aramaicas, incorporadas ao hebraico durante o Exílio da Babilônia, após a destruição do Primeiro Templo Sagrado em 586 AEC. As duas escritas, hebraica e aramaica conviveram até o século 2 AEC, e a partir de então apenas as letras aramaicas foram usadas. Deu-se uma adaptada pequena a estas letras, para que ganhassem a familiar forma quadrada que conhecemos hoje. . De toda forma, o uso deste alfabeto antigo nas moedas da Grande Revolta provavelmente significa uma “volta às raizes”, e uma nostalgia aos bons e velhos tempos. Vejam abaixo uma tabela comparativa entre o alfabeto hebraico antigo (linha de cima) e o alfabeto hebraico moderno (embaixo). Ambos tem 22 letras, porém 4 letras do alfabeto moderno são diferentes quando usadas na última letra da palavra, portanto a aparente disparidade. . . 10 agorot . Está é a moeda de menor valor ainda em circulação em Israel. . . Ela é a última das moedas que desta lista que herdou seu desenho de uma moeda do Shekel Velho, neste caso, a de 100 Shkalim Velhos, vejam. . . Em 1990, Yasser Arafat, líder da Organização para Libertação da Palestina, disse em uma coletiva de imprensa que havia descoberto “a verdadeira cara de Israel e seus planos de expansão”. Segundo ele, a silueta que serve de fundo para a menorá é um mapa da região, incluindo Israel, Jordânia, Síria, Iraque e o norte da Arábia Saudita. Ninguém o levou a sério. . Na verdade, o desenho é de uma moeda antiga danificada, e seu contorno original foi mantido no desenho da nova moeda. Trata-se de uma moeda de prutá do ano 37 AEC, emitida durante o reinado de Antigonus II Mattathias, último rei Hasmoneu de Judá, morto por ordem de Herodes. No fim de seu reinado, quando já entendia que não resistiria à invasão romana, foram emitidas várias moedas com motivos judaicos, para dizer que ele era o rei pertencente à cultura judaica (diferentemente de Herodes, de cultura edomita-judaica-romana). A tentativa era de ganhar um pouco mais de apoio popular e atrair combatentes para ajudá-lo. Não deu certo… . A dinastia dos Hasmoneus chegou ao poder com a revolta dos Macabeus, e reinou por cerca de 100 anos. Este foi o último período (até o século 20) em que os judeus tiveram soberania prolongada de parte da Terra de Israel. . A moeda era feita de bronze, e foram encontradas apenas cerca de 40 delas. Veja abaixo. . . Como resposta a Arafat, o então embaixador de Israel na ONU, Benjamin Netanyahu, disse que o símbolo da OLP tinha o mapa do Mandato Britânico embaixo da bandeira palestina, o que significaria que a intenção deles seria criar o estado palestino no lugar de Israel. Touché. . . Com a troca de moeda em 1985, o Banco de Israel adotou para si o seguinte logo “expansionista”. . . 50 agorot . Já comecei mentindo. Não existe moeda de 50 agorot, mas sim uma moeda de meio shekel. Qual a diferença? Veja a imagem abaixo. . . Talvez na psique do israelense, a última (e hoje, única) moeda de “centavos” seja a de 10 agorot, já que “meio shekel” claramente pertence à família do “shekel”. A loucura não começou agora. Veja a moeda de meio shekel do ano 2 da grande revolta de Judá contra os romanos (anos 67-68). . . Novamente as letras antigas. Do lado esquerdo o desenho de um cálice, com as letras “שב”, representando Shnat B, ou seja, o segundo ano da revolta. Ao redor lemos “חצי השקל”, ou seja, meio shekel. Do lado direito três romãs (uma das sete espécies da Terra de Israel), e em volta se lê “ירושלים הקדושה”, Jerusalém Sagrada. (Podem verificar usando a tabela comparativa entre as letras hebraicas antigas e novas acima, é bom pra cabeça). . Meio shekel era o valor do imposto que todos os israelitas pagavam para a manutenção do antigo templo de Jerusalém. “Cada um daqueles que forem recenseados pagará a metade de um shekel como contribuição devida ao Senhor. (Êxodo 30:13)” Metade de um shekel (מַחֲצִית הַשֶּׁקֶל), e não meio shekel (חצי שקל), pois naquela época shekel era uma unidade de medida de prata, e não uma moeda. . Atenção, mostrei a moeda acima, do ano 2 da revolta, para mostrar um outro exemplo de meio shekel, mas ainda não sabemos de onde veio a harpa da moeda de hoje em dia. . A harpa é uma clara referência ao rei David, que em 1 Samuel 16:23 conta-se que tocava o instrumento para espantar o espírito ruim que baixava em Saul. A palavra usada é kinor (כִּנּוֹר), que no hebraico de hoje significa violino, e não se sabe ao certo qual instrumento era na época, e a interpretação usual é que era uma harpa mesmo. Outras moedas do passado já tiveram o desenho de uma harpa, notadamente a moeda do primeiro ano da revolta de Bar Kochva (132-133 EC). Do lado esquerdo vemos uma folha de palmeira (lulav), e do outro lado da moeda uma harpa de sete cordas, com a inscrição (novamente no script hebraico antigo) “Ano um da redenção de Israel”. Não deu certo… a redenção durou menos de 5 anos. . . Como pode-se notar, a harpa da moeda de meio shekel que se usa hoje é assimétrica, e não se parece nem um pouco com a harpa de Bar Kochva. Enrolei muito para contar que o desenho de hoje não veio de uma moeda antiga (pasmem!), mas sim de um “selo de impressão”. (Ganha um sorvete quem souber por que as imagens abaixo estão espelhadas.) . . Trata-se de um objeto usado para carimbar a cera ainda mole e assim lacrar uma carta ou documento antigo. O selo foi comprado em uma feira de antiguidades no ano 1978 por Reuben Hecht. A inscrição diz “Para Maadana, filha do rei” (למעדנה בת המלך). Agora sim o uso das letras do hebraico antigo é justificado: estima-se que o selo seja do século 7 AEC do reino de Judá, quando ainda existia o primeiro templo de Jerusalém. Tentou-se descobrir quem é Maadana, e qual rei seria seu pai, mas infelizmente é apenas isto que sabemos… Segundo o arqueólogo israelense Nahman Avigad, este desenho é a melhor estimativa que temos de como se pareceria o “kinor” bíblico. A harpa de 12 cordas é ornada por uma roseta e tem uma moldura de uma corrente de pérolas. . 1 shekel . Enquanto todas as moedas de agora (centavo!) são amarelas (meio shekel inclusive), já as de shekel são prateadas. . . O desenho é de uma flor de lis, ou em hebraico Shoshan Tzachor (שושן צחור, lírio branco). O lírio branco indica pureza e segundo o profeta Oséias (14:6) tornou-se a flor-símbolo do povo de Israel (Eu serei para Israel como o orvalho. Ele florescerá como o lírio e lançará as suas raízes como o Líbano). A moeda antiga que serviu de inspiração pode ser vista abaixo. . . A inscrição na moeda antiga (do lado do pássaro) foi copiada na moeda moderna do lado da flor de lis, e diz Yehud (יהד), usando o antigo alfabeto hebraico. Yehud Medinta (יְהֻד מְדִינְתָּא) é como se chamava em aramaico a província autônoma judaica (yehud) na época do domínio persa. Medinta tem a mesma raiz da palavra hebraica Mediná (hoje significa país, originalmente uma entidade política de qualquer tamanho, regida por uma mesma lei, Din=דין em hebraico). Um outro nome para a província autônoma é Pachavat Yehuda (פחוות יהודה), onde Pachava significa província em persa antigo, e é controlada por um Pecha (daí vem a palavra Paxá em português). Esdras e Neemias foram paxás de Yehuda. . A província judaica existiu de 538 AEC, com Ciro II permitindo aos judeus voltar da Babilônia para Sião, até o ano de 332 AEC, com a conquista de Alexandre, o Grande. Nesta época existia plena liberdade religiosa e de culto (Dario I permitiu a reconstrução do Segundo Templo), mas sem autonomia política, embora eles pudessem emitir moedas de baixo valor, como esta da flor de lis, de 1 óbolo de prata (1/20 do shekel, cerca de 0.6 gramas). A moeda foi emitida aproximadamente em 350 AEC em Jerusalém, e foi encontrada milênios depois em Jericó (uma das 6 grandes cidades da província). . 2 shkalim . A moeda de 2 shkalim é apelidada de Shnekel, um portmanteau carinhoso, que junta as palavras “Shnei Shekel” (שני שקל), ou seja, dois shekel. Ela é a mais nova de todas as moedas, tendo sido lançada no final de 2007, e não em 1985, como todas as outras. . . O desenho é de dois chifres que transbordam de comida, ou cornos da abundância (cornucópias). Vemos o trigo e uvas, e algo mais que não reconheço. No meio há uma romã, outro símbolo de abundância. O desenho é inspirado em uma moeda de João Hircano I (Yohanan Hyrcanus), filho de Simão (Shimon) e neto de Matatias (Matitiahu), da dinastia dos Hasmoneus (Chashmonaim). Ele reinou entre 134 e 104 AEC. . . Os dois chifres juntados pela base são a adaptação judaica deste símbolo helenista tão comum. Anos antes do reinado de João Hircano I, o rei selêucida Demetrius I emitiu uma moeda sua, nos anos 151-150 AEC, onde a deusa da fortuna chamada Tique segura uma cornucópia. . . Um pouco mais tarde, nos anos 126-125 AEC, a rainha selêucida Cleópatra Téia emitiu uma moeda com duas cornucópias lado a lado (e seu próprio rosto do outro lado). Certamente João Hircano I tomou para si um símbolo amplamente conhecido pelas pessoas da região (o Império Selêucida era vizinho do reino de Judá). . . A festa de Chanuka celebra a vitória dos macabeus sobre os gregos (na verdade, selêucidas), e um de seus valores centrais é a rejeição da cultura helenística pela liderança judaica. A menorá que vimos na moeda de 10 agorot foi emitida pelo último dos reis hasmoneus, para tentar retomar o pouco de cultura judaica que havia sobrado. Ao longo das gerações de hasmoneus, fica claro que a cultura helenística lhes era irresistível. A cornucópia é apenas uma das evidências. Mais claro ainda é perceber seus nomes, todos uma mistura de hebraico com grego: Yohanan (João) Hircano era pai de Yehuda Aristobulus, Matitiahu Antigonos e Alexander Yanai. . 5 shkalim . O desenho da moeda de 5 shkalim mostra um capitel de uma coluna proto-jônica, típica da época do primeiro templo. Não se trata de uma apropriação da famosa coluna jônica da cultura grega, que só viria a ser criada no século 6 AEC. Este estilo de colunas com volutas (espirais) era comum por todo o Levante, e podemos ter orgulho desta criação local da Terra de Israel. . . As volutas representam a árvore da vida. Vejamos como. Abaixo à esquerda encontramos um desenho assírio em relevo de uma tamareira. Para os assírios, esta árvore representava a abundância agricultural. A tamareira é capaz de se reproduzir assexuadamente, seus clones também sendo capazes de produzir frutos. Da base do tronco nascem ramificações que se afastam da tamareira-mãe, e separam-se uns dos outros por um broto triangular, que é o resto do fronde (folha ramificada) da estação anterior. A árvore cresce um pouco a cada estação, e com a quebra dos brotos triangulares, o tronco ganha a sua típica textura romboidal (com forma de losangos). . . Quando a árvore não é cultivada, nascem mais e mais troncos em volta do tronco inicial, todos geneticamente idênticos. Como sempre vemos imagens de tamareiras sozinhas, isto significa que são plantas cultivadas. A facilidade de se clonar uma árvore que tem propriedades desejáveis (muitos frutos de sabor doce, por exemplo) fez com que a tamareira ganhasse a simbologia de árvore da vida. Portanto, a voluta no topo das colunas representa o ciclo de nascimento e renascimento que ocorre na base do tronco, e não a copa, como seria natural de se supor. . Colunas proto-jônicas foram encontradas em escavações em Megido, Hatzor, Ramat Rachel e Jerusalém, entre outras. Nos anos 1960, a arqueóloga britânica Kathleen Kenyon encontrou o capitel abaixo em uma escavação na Cidade de David. O capitel estava quebrado em dois, no meio de outras ruínas que haviam rolado a encosta leste da Cidade de David. Ele pode ser visto no Museu de Israel, em Jerusalém. . . 10 shkalim . Esta é a moeda de Shekel de mais alto valor, e a que tem o significado mais interessante. . . Acabamos de discutir o significado de “árvore da vida” da tamareira, e ela naturalmente serviu como símbolo em várias moedas ao longo da história. No quarto ano da revolta judaica contra Roma (anos 69-70 EC), foi emitida em Jerusalém esta moeda de meio shekel. De um lado vemos a tamareira com duas cestas de tâmaras aos seus pés, e do outro lado uma variação do desenho das quatro espécies de Sukot que já vimos na moeda de 5 agorot. . . A inscrição do lado da tamareira está um pouco apagada, mas pode ser melhor identificada nesta moeda abaixo. “Pela redenção de Sião” (legeulat tzion = לגאולת ציון) é o que a liderança judaica desejava, já sabendo que não poderiam resistir à conquista romana. . . O general romano Vespasiano tornou-se imperador de Roma em 69 EC, partindo da Judéia para o Egito, e deixando o cerco de Jerusalém a cargo de seu filho Tito. Jerusalém finalmente caiu no verão de 70 EC, e o segundo templo foi destruído. Em comemoração à conquista da Judéia, a seguinte moeda romana foi emitida no ano 71. . . De um lado temos o imperador Vespasiano, e do outro lado três figuras: à esquerda vemos o imperador com armadura, à direita a Judéia é representada por uma mulher chorando, e no meio a tamareira. A incrição diz “Judéia Capturada” (ivdaea capta). Não bastava conquistar Jerusalém e destruir o templo, era também preciso jogar sal na ferida! . Eis que, 1915 anos depois, o Estado de Israel decide “devolver na mesma moeda”, literalmente. A tamareira volta em toda a sua glória, e a inscrição diz em hebraico moderno e antigo (para todos entenderem), Pela Redenção de Sião! . Chupa essa tâmara, Titus Flavius Vespasianus! . . . . Fontes: Imagens de todas as moedas de hoje no site do Banco de Israel, clique em “מעות” (moedas). 1 agorá Imagem da moeda de Herodes Arquelau: Wikipedia. 5 agorot Imagens das moedas do quarto ano da revolta: Otzar.org, antiquities.org.il, coinsmendy.com. Tabela comparativa das escritas judaicas antiga e moderna: safa-ivrit.org. 10 agorot História sobre Arafat: Ynet. Imagem da moeda antiga: danielventura.wikia.com 50 agorot Imagem da moeda do ano 2 da revolta: Wikipedia. Moeda da harpa: winners-auctions.com. Imagem do selo de Maadana: sheqel.info, echad.info (página 15). Informações sobre o selo de Maadana: books.google.com, ancientlyre.com, Wikipedia. 1 shekel Informações sobre a flor de lis: books.google.com. Imagem da moeda antiga: tsel.org. Informações sobre Yehud Medinta: Wikipedia. 2 shkalim Imagem da moeda de João Hircano I: Wikipedia. Imagem da moeda da deusa Tique: coinworld.com. Imagem da moeda de Cleópatra Téia: Wikipedia. 5 shkalim Informações e imagens sobre a tamareira: academia.edu (artigo interessante!). Imagem do capitel de pedra: cityofdavid.org.il. 10 shkalim Imagens da moeda antiga: press.khm.at, artportal.co.il. Imagens da moeda da Judéia Capturada: press.khm.at. .",
            "url": "https://yairmau.github.io/website/markdown/2022/02/01/as-moedas-do-estado-judeu.html",
            "relUrl": "/markdown/2022/02/01/as-moedas-do-estado-judeu.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Doubling Time",
            "content": "Suppose you have a process that can be described by exponential growth. It could be anything: interests on an investment, the early phases of infection in a pandemic, whatever. . It is often convenient to have an idea how fast is the growth by answering the question: . How long will it take for $x$ to double in size, given a growth of $n$% per year? . The rule of thumb I learned a while back is the following: . Doubling time = $ displaystyle frac{70}{n}$ (in years) . Of course, the time unit could be anything you like, I’ll deal here with years for simplicity’s sake. Specifically, let’s answer the question: . Israel has currently (2021) a population of 9.2 million, and a growth rate of 1.8% per year. How long will it take for the population to double, assuming a fixed growth rate? . The answer is about 39 years (70 divided by 1.8), but why?! . Let’s call $x_0$ the population size now, and the growth rate $n$%. After one year, the population will be . x1=x0∗(1+n100)(1)x_1 = x_0 * left( 1 + frac{n}{100} right) tag{1}x1​=x0​∗(1+100n​)(1) . Assume that after $k$ years the population will be double, i.e.: . xk=x0∗(1+n100)k=2x0.(2)x_k = x_0 * left( 1 + frac{n}{100} right)^k = 2x_0. tag{2}xk​=x0​∗(1+100n​)k=2x0​.(2) . Cancelling $x_0$ we get . (1+n100)k=2.(3) left( 1 + frac{n}{100} right)^k = 2. tag{3}(1+100n​)k=2.(3) . We now take the natural logarith of both sides: . kln⁡(1+n100)=ln⁡(2).(4)k ln left( 1 + frac{n}{100} right) = ln(2). tag{4}kln(1+100n​)=ln(2).(4) . Note that we took $k$ out of the exponent and it now multiplies the logarithm on the left-hand side. Multiplying both sides by 100 yields . 100kln⁡(1+n100)=100ln⁡(2)≃69.3.(5)100k ln left( 1 + frac{n}{100} right) = 100 ln(2) simeq 69.3. tag{5}100kln(1+100n​)=100ln(2)≃69.3.(5) . That surely explains the number 70 in the rule of thumb! Because of the properties of logarithms, we put the number 100 as the exponent of the parenthesis: . kln⁡(1+n100)100=100ln⁡(2).(6)k ln left( 1 + frac{n}{100} right)^{100} = 100 ln(2). tag{6}kln(1+100n​)100=100ln(2).(6) . We are very close to the end! We now remind ourselves that we learned in Calculus the definition of the exponential function: . exp⁡(x)=lim⁡m→∞(1+xm)m.(7) exp(x) = lim_{m rightarrow infty} left( 1 + frac{x}{m} right)^{m}. tag{7}exp(x)=m→∞lim​(1+mx​)m.(7) . Because the number 100 is “quite big”, we will approximate the parenthesis inside the logarithm with the exponential function, thus . kln⁡exp⁡(n)=100ln⁡(2).(8)k ln exp(n) = 100 ln(2). tag{8}klnexp(n)=100ln(2).(8) . The logarithm is the inverse function of the exponential, therefore . kn=100ln⁡(2).(9)kn = 100 ln(2). tag{9}kn=100ln(2).(9) . Finally, solving for $k$, we have . k=100ln⁡(2)n≃70n.(10)k = frac{100 ln(2)}{n} simeq frac{70}{n}. tag{10}k=n100ln(2)​≃n70​.(10) . We have thus shown that the number of years $k$ it will take for Israel to double it’s population is about $70/n = 70/1.8 = 38.88$ years!! . The exact number, without any approximations, would be . k=ln⁡(2)ln⁡(1+n/100)≃38.85.(11)k = frac{ ln(2)}{ ln(1+n/100)} simeq 38.85. tag{11}k=ln(1+n/100)ln(2)​≃38.85.(11) . Conclusion: 👍 Very impressive rule of thumb 👍 .",
            "url": "https://yairmau.github.io/website/markdown/2021/11/16/doubling-time.html",
            "relUrl": "/markdown/2021/11/16/doubling-time.html",
            "date": " • Nov 16, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Parabolic Hyperboloid",
            "content": ". Just like the hyperboloid of one sheet, the Parabolic Hyperboloid is a ruled surface. This means that it can be imagined as the surface one gets by swiping a straight line through space. In the image below, we see that each of the skewers is exactly straight, but together thay make this beautiful curved shape. . . This project is quite easy to make with skewers, see its instructions here. . The equation that defines the surface of the parabolic hyperboloid is . z=Ax2−By2,z = Ax^2 - By^2,z=Ax2−By2, . where both $A$ and $B$ are positive numbers. This website allows us to play with the parameters and see how the surface responds. . In my opinion, a static image can’t convey the beauty of this shape, so I made this gif: . In 2020, Dillon Berger noted on Twitter that the shape of Pringles is a parabolic hyperboloid: . The reason Pringles fit so nicely in a cylindrical tube is because they&#39;re hyperbolic paraboloids plotted over a circular domain pic.twitter.com/BUzjPw7e17 . &mdash; 〈 Berger | Dillon 〉 (@InertialObservr) February 18, 2020 The company took notice of this (mildly) viral tweet, and sent Dillon a box full of parabolic hyperboloids 😁. . Thanks @Pringles, for sending me some of these delicious Hyperbolic Paraboloids! pic.twitter.com/L3WMgqObPM . &mdash; 〈 Berger | Dillon 〉 (@InertialObservr) March 2, 2020 The lesson here is that it’s good to know your math 😜. . .",
            "url": "https://yairmau.github.io/website/markdown/2021/11/13/parabolic-hyperboloid.html",
            "relUrl": "/markdown/2021/11/13/parabolic-hyperboloid.html",
            "date": " • Nov 13, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Skewer Hyperboloid",
            "content": ". George Hart is again the hero of this project. Go check out his webpage to see how to build this beautiful shape. All you need to make the skewer hyperboloid is a bunch of skewers and thin elastic bands. . This is an easy project, and the end result is so fun to play with! It is surprising how smoothly this shape morphes when you pull and push the skewers to change the angle, it’s hard to explain, so you should definitely try it yourself 😁. See Annie Perkins’s video to get a better idea: . The one thing I can add to George Hart’s page is that after many weeks and months the elastic bands will dry out and break! I gave a skewer hyperboloid to a friend, and one day he arrived at his office and found out that the whole thing had disintegrated overnight, and the skewers were all over the place. I’m still looking for a suitable substitute to the elastic bands. It must be something flexible that enables us to play with the construction, and at the same time something durable… I have not found yet the perfect material, if you have a suggestion please write to me. . I wanted my hyperboloid to last for a long time, so after the construction was done, I used super glue to fix the skewers in a particular angle. Now I can’t play with it, but at least it will not disintegrate overnight in a few months time (hopefully!). . . The mathematical name of this shape is “hyperboloid of one sheet”, and its equation is . x2A2+y2B2−z2C2=0. frac{x^2}{A^2} + frac{y^2}{B^2} - frac{z^2}{C^2} = 0.A2x2​+B2y2​−C2z2​=0. . When $A=B$ the horizontal cross-sections are circles, just like in our construction. The elastic bands effectively allow us to play with the parameter $C$, which controls how fast the hyperboloid grows sideways. There is a wonderful widget in the Interactive Gallery of Quadric Surfaces, its quite fun to play with. . To see how this curved surface can be made entirely out of straight lines, one can define the surface as the set of all parametric curves of the kind . x=A(cos⁡θ−vsin⁡θ)y=B(sin⁡θ+vcos⁡θ)z=Cεv. begin{align} x &amp;= A ( cos theta - v sin theta) y &amp;= B ( sin theta + v cos theta) z &amp;= C varepsilon v. end{align}xyz​=A(cosθ−vsinθ)=B(sinθ+vcosθ)=Cεv.​​ . Substitute the parametric equations above into the equation of the paraboloid and see that they satisfy it. . There are actually two families of curves, for $ epsilon= pm 1$. I made a Mathematica plot of the two families of lines, in red ($ varepsilon=1$) and in blue ($ varepsilon=-1$), for ten $ theta$ values between 0 and $2 pi$. It’s easy to see that each family of lines swirls in a different direction. . . The Mathematica code I wrote is . a = 1; b = 1; c = 1; h = 4; n = 10; p1 = ContourPlot3D[ (*hyperboloid*) x^2/a^2 + y^2/b^2 - z^2/c^2 == 1, {x, -h, h}, {y, -h, h}, {z, -h, h}, Mesh -&gt; None, ContourStyle -&gt; Opacity[0.4], AxesLabel -&gt; {x, y, z}, LabelStyle -&gt; Large ]; p2 = ParametricPlot3D[ (*red lines*) Table[{ a (Cos[theta] - v Sin[theta]), b (Sin[theta] + v Cos[theta]), c v }, {theta, 0, 2 Pi, 2 Pi/n}], {v, -20, 20}, PlotStyle -&gt; {Red} ]; p3 = ParametricPlot3D[ (*blue lines*) Table[{ a (Cos[theta] - v Sin[theta]), b (Sin[theta] + v Cos[theta]), - c v }, {theta, 0, 2 Pi, 2 Pi/n}], {v, -20, 20}, PlotStyle -&gt; {Blue} ]; Show[{p1, p2, p3}] . .",
            "url": "https://yairmau.github.io/website/markdown/2021/11/12/skewer-hyperboloid.html",
            "relUrl": "/markdown/2021/11/12/skewer-hyperboloid.html",
            "date": " • Nov 12, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Tomoko Fuse Unit Origami",
            "content": ". This structure has the general shape of a dodecahedron, with 12 beautiful pentagonal stars embeded in it. I found a while back a scan of the book Tomoko Fuse Unit Origami Fantasy. The book is all written in japanese, but I could make sense of the diagrams. . Tomoko Fuse is a master of modular origami, just google her name and you’ll find tons of fun projects. . I used craft paper to give the structure a muted tones and a rustic feel. I think it turned out pretty good 😊. . .",
            "url": "https://yairmau.github.io/website/markdown/2021/11/08/tomoko-fuse.html",
            "relUrl": "/markdown/2021/11/08/tomoko-fuse.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "George Hart's Card Constructions",
            "content": ". George Hart is a sculptor and geometer, and his webpage has the best projects for the artistically-minded nerd! . The image above shows the 30-cards construction, but it is not identical to what George Hart shows on his card constructions page. I actually used Francesco De Comité’s version, also credited by Hart. The idea is that you strategically cut the cards in very specific places, so that they can be slided together. . Figuring out how to cut the cards was quite hard to me, I had to experiment a lot! George Hart provides printable templates, but their dimensions are different from the cards I used. Finally besides cutting the cards, the task of putting everything together was a nightmare. It’s been a while since I built this, but I think that I used clothes pegs to hold the cards together before the whole thing is ready. Once you finish building the structure, it should be much more stable (but not enough to throw it in the air!!). . Because there is a 5-fold symmetry, naturally the golden ratio . φ=1+52 varphi = frac{1+ sqrt{5}}{2}φ=21+5 . ​​ . figures quite prominently in there. Francesco De Comité provides in his Flickr page a plan for how to cut the cards: . . I put the plan above for the future me to understand what it means, because I myself didn’t use this… I found in one of my “projects” folders my own calculations of how to cut the cards. It shows only the cuts on the top side. One should rotate the card 180 degrees and do the same cuts on the other side. For a card of height H and length L, my cutting plan is the following. . . The cuts are the thick blue lines, and the red arrows show the length $L/ varphi$ of one of the cuts and of the uncut (dashed) part. From this I hope you can imagine that when the cards are slided together, the two cuts amount to the length of the whole “diagonal”, such that the two card ends are flush. I wish I could explain why the plan is what it is, but some time has passed and I have no idea any more 🤷‍♂️… . .",
            "url": "https://yairmau.github.io/website/markdown/2021/11/08/george-hart-card-constructions.html",
            "relUrl": "/markdown/2021/11/08/george-hart-card-constructions.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "The Sonobe Module",
            "content": "All these modular origami constructions are made of a single basic module, the Sonobe unit. . The basic unit has flaps and pockets. . The actual folding of the Sonobe module is quite easy, see the instructions below, taken from Michael Naughton’s excellent diagram. . . This is an incredibly flexible unit, allowing us to combine it in many ways. This pdf shows how to combine different numbers of Sonobe modules to produce the shapes above, and many others. If all meeting points of the basic unit contain 3 modules, one gets a cube. If all meeting points contain 4 modules, then we produce a octahedron (with pyramids on each of its faces). . . The results can be very impressive! Above is a Truncated Icosahedron, made of pentagons surrounded by hexagons (like a soccer ball). This one is made of 90 Sonobe units, see detailed instructions. .",
            "url": "https://yairmau.github.io/website/markdown/2021/11/03/sonobe.html",
            "relUrl": "/markdown/2021/11/03/sonobe.html",
            "date": " • Nov 3, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "Pythagorean theorem",
            "content": "I’ve been interested lately in the Pythagorean theorem, and the myriad of ways one can prove it. . . An excellent resource is the website Cut The Knot. . Another great source is John C. Sparks’ The Pythagorean Theorem: Crown Jewel of Mathematics. . I used my tablet to write down my own version of some of the nicest proofs, see below. .",
            "url": "https://yairmau.github.io/website/markdown/2021/10/28/pythagoras.html",
            "relUrl": "/markdown/2021/10/28/pythagoras.html",
            "date": " • Oct 28, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "Hexastix",
            "content": "I’m very proud of this construction I made about 4 years ago. . . It sits prominently on my office shelf, it has never failed to impress the occasional visitor :) Although it looks complicated, this 72-pencil construction is not very hard to build! I followed Matt Parker’s youtube tutorial, it took me about 1.5 hours to make it, and another hour or so to glue it. . Materials: . 72 pencils | a few elastic bands | super glue | . Here in Israel, I couldn’t find non-sharpened pencils. There is some risk of (small) injury if you don’t take care 😬. . Without the elastic bands, this construction would not be stable. The problem is that with time the elastic bands get dry and disintegrate, so if you want to have this construction standing for a long time, you have to glue it. I put tiny drops of super glue in most of the touching points between the pencils, and it worked great! . Enjoy making your own! . . PS: I’m in my office at the university writing these words, and exactly now a student passed in the corridor and asked me about the Hexastix 😄 .",
            "url": "https://yairmau.github.io/website/markdown/2021/10/28/hexastix.html",
            "relUrl": "/markdown/2021/10/28/hexastix.html",
            "date": " • Oct 28, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "The can problem",
            "content": "watch this space .",
            "url": "https://yairmau.github.io/website/markdown/2021/10/27/can-problem.html",
            "relUrl": "/markdown/2021/10/27/can-problem.html",
            "date": " • Oct 27, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "Spatial distribution - lecture",
            "content": "The problem . Let&#39;s say we want to calculate the average rainfall on a watershed, and we have data available for 7 stations, as shown in the figure below [Dingman, figure 4.26]: . There are a number of methods for calculating the average precipitation. . Thiessen method [Voronoi diagram] . Brutsaert, Figure 3.11 . How to compute the areas: . Average areal precipitation is a weighted sum: . $$ langle P rangle = frac{ sum_i A_i P_i}{ sum_i A_i} $$A nice way to understand the Thiessen method is depicted in the gif below (from Wikipedia): . . Inverse distance method . Brutsaert, Figure 3.12 . The precipitation for square 17 is . $$ P_{17} = displaystyle frac { displaystyle sum_ text{$i$ = all stations} frac{P_i}{d_{i,17}^2}} { displaystyle sum_ text{$i$ = all stations} frac{1}{d_{i,17}^2}} $$The average precipitation for the whole watershed is the weighted average of all squares, where the weight is their area: . $$ langle P rangle = displaystyle frac { displaystyle sum_ text{$j$ = all squares} A_j P_j} { displaystyle sum_ text{$j$ = all squares} A_j} $$Brutsaert, page 93: . Dean and Snyder (1977) found that the exponent (for the distance $d^{-b}$) b = 2 yielded the best results in the Piedmont region of the southeastern United States, whereas Simanton and Osborn (1980) concluded from measurements in Arizona that b can range between 1 and 3 without significantly affecting the results. . Isohyetal method . Brutsaert, Figure 3.12 . The same equation of the Thiessen method can be used: . $$ langle P rangle = frac{ sum_i A_i P_i}{ sum_i A_i} $$ How it is actually done . Most often, Geographic Information System (GIS) software is used to analyze spatial data. Two of the most used programs are ArcGIS (proprietary) and QGIS (free). . A good discussion of the different methods can be found on Manuel Gimond&#39;s website, Intro to GIS and Spatial Analysis. . Attention, Don&#39;t mix precision with accuracy. There are many ways of interpolating, just because a result seems detailed, it does not imply that it is accurate! See below three interpolation methods. . . Below you can find a simple Python code that exemplifies some of the methods, producing the following figure: . . %matplotlib notebook import matplotlib.pyplot as plt import numpy as np from scipy.interpolate import griddata from scipy.spatial import Voronoi, voronoi_plot_2d, ConvexHull fig, ax = plt.subplots(1, 3, figsize=(10,7)) fig.subplots_adjust(left=0.0, right=1.0, top=0.96, bottom=0.05, hspace=0.02, wspace=0.02) N = 6 PI = &#39;3141592653589793&#39; points = np.random.rand(N, 2) points = np.vstack([points,[0,0], [0,1], [1,0], [1,1]]) values = np.array([int(x) for x in list(PI)])[:(N+4)] # values = np.array([3, 1, 4, 1, 5, 9, 2, 6, 5, 3]) grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j] grid_z_nearest = griddata(points, values, (grid_x, grid_y), method=&#39;nearest&#39;) grid_z_cubic = griddata(points, values, (grid_x, grid_y), method=&#39;cubic&#39;) ax[0].plot(points[:,0], points[:,1], &#39;o&#39;, ms=3, markerfacecolor=&quot;red&quot;, markeredgecolor=&quot;red&quot;) ax[0].set_aspect(&#39;equal&#39;, &#39;box&#39;) ax[0].set(xlim=[0,1], ylim=[0,1]) ax[0].set_title(&quot;the stations&quot;) for i, v in enumerate(values): ax[0].text(points[i,0], points[i,1], str(v)) ax[1].imshow(grid_z_nearest.T, extent=(0,1,0,1), origin=&#39;lower&#39;) ax[1].plot(points[:,0], points[:,1], &#39;o&#39;, ms=3, markerfacecolor=&quot;red&quot;, markeredgecolor=&quot;red&quot;) vor = Voronoi(points) voronoi_plot_2d(vor, show_vertices=False, line_colors=&#39;cyan&#39;, line_width=3, line_alpha=1, point_size=0, ax=ax[1]) ax[1].set_title(&quot;Thiessen Method&quot;) ax[2].plot(points[:,0], points[:,1], &#39;o&#39;, ms=3, markerfacecolor=&quot;red&quot;, markeredgecolor=&quot;red&quot;) nlines = int((values.max()-values.min()+1)/2) ax[2].contourf(grid_x, grid_y, grid_z_cubic, nlines) cont = ax[2].contour(grid_x, grid_y, grid_z_cubic, nlines, colors=&quot;black&quot;) ax[2].clabel(cont, inline=1, colors=&#39;white&#39;, fmt=&#39;%.0f&#39;) ax[2].set_title(&quot;Isohyetal Method&quot;) for i, a in enumerate(ax): a.set(xlim=[-0.2,1.2], ylim=[-0.2,1.2]) a.axis(&#39;off&#39;) a.set_aspect(&#39;equal&#39;, &#39;box&#39;) fig.savefig(&quot;spatial-distribution.png&quot;, dpi=500) .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/07/spatial-distribution.html",
            "relUrl": "/jupyter/2020/02/07/spatial-distribution.html",
            "date": " • Feb 7, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "Budyko framework - lecture",
            "content": "Sources used: . (Daly et al., 2019), (Sposito, 2017), (Jones et al., 2012), (Krajewski et al., 2021), (Berghuijs et al., 2020), (Creed and Spargo, 2012) . Water and surface energy balances . For long-term averages: . $$ P = ET+Q $$$$ R_n = lambda_w cdot ET + H $$ $P$: precipitation (L T$^{-1}$, e.g.: mm/day) | $ET$: evapotranspiration (L T$^{-1}$) | $Q$: streamflow (L T$^{-1}$) | $R_n$: net energy available at soil surface (M T$^{-3}$, e.g.: W m$^{-2}$) | $ lambda_w$: latent heat of vaporization of water (M L$^{-1}$T$^{-2}$, as defined here, the units will be weird) | $H$: sensible heat flux from the surface into the atmosphere (M T$^{-3}$) | $ lambda_w cdot ET$: latent heat flux (M T$^{-3}$) | . Assumptions . because we are dealing with long-term averages, there are negligible changes of watershed stored water. | negligible energy is stored at the soil surface, and heat transfer from soil surface to deeper soil layers ($G$) averages zero. | Question . Given measurements of rainfall and meteorological conditions, can we predict the partitioning of $P$ between $ET$ and $Q$? . Limits . For very dry watersheds (deserts, for example), almost all precipitation ($P$) is lost via evapotranspiration ($ET$). These watersheds are called water limited. . In wet watersheds, at the annual scale, the sensible heat ($H$) is directed from the surface to the atmosphere in almost all climatic zones on Earth (meaning: soil heats air). Therefore, $H$ cannot supply much energy to the soil surface, and it is assumed that $R_n$ provides entirely the energy required for evapotranspiration. Dividing the second equation by $ lambda_w$, we get $R_n/ lambda_w = ET + H/ lambda_w$. It is clear that the maximum possible $ET$ occurs when all incoming radiation energy $R_n$ is consumed by evapotranspiration $ET$, and there is negligible sensible heat flux $H$. As a result, the upper limit of $ lambda_w E$ is $R_n$, in wet watersheds. In these watersheds, called energy limited, $ET$ tends to the potential evapotranspiration ($ET_0$). . Summary: . For energy-limited watersheds . (1) As precipitation $P rightarrow infty$, evapotranspiration $ET rightarrow ET_0$ . For water-limited watersheds . (2) As potential evapotranspiration $ET_0 rightarrow infty$, actual evaporation $ET rightarrow P$ . In general, we can write . $$ ET = f(P,ET_0) $$The variables $P$ and $ET$ have the same dimenstions (L T$^{-1}$), and we can divide the equation above by $P$:$$ frac{ET}{P} = f(D_I), $$ . where $$ D_I = displaystyle frac{ET_0}{P} $$ is called the dryness index. A useful classification is . Dryness Index Classification . $D_I &lt; 1.54$ | Humid | . $1.54 &lt; D_I &lt; 2$ | Dry Subhumid | . $2 &lt; D_I &lt; 5$ | Semi-arid | . $5 &lt; D_I &lt; 20$ | Arid | . $20 &lt; D_I$ | Hyper-arid | . ATTENTION. The dryness index can also be called the &quot;Aridity Index&quot; ($AI$), however sometimes the $AI$ means the inverse of $D_I$: $$AI = 1/D_I$$ Be careful to check the definitions. . The summary (1) and (2) above can be now represented as: . (1) As $D_I rightarrow 0$, $ displaystyle frac{ET}{P} rightarrow D_I$ . (2) As $D_I rightarrow infty$, $ displaystyle frac{ET}{P} rightarrow 1$ . . . Budyko (1974), proposed the following equation: . $$ frac{ET}{P} = left[ D_I tanh left( frac{1}{D_I} right) left( 1-e^{-D_I} right) right]^{1/2} $$ . Source: (Jones et al., 2012) . Source: (Krajewski et al., 2021) . There are many alternatives to Budyko&#39;s equation. Many equations have adjustable parameters, such as Fu&#39;s equation: . $$ frac{ET}{P} = 1 + D_I - (1 + D_I^w)^{1/w}, $$where $w&gt;1$. Each catchment has its own specific parameter $w$, that may represent biophysical/landscape features. There is no concensus regarding the interpretation of $w$, ranging from an effective empirical parameter, whose relationship to biophysical features can be discerned, to an arbitrary empirical constant with no a priori physical meaning. Source: (Reaver et al., 2020) . Source: (Zhang et al., 2004) . Hypotheses for why dryness index controls so much the partitioning of P into ET and Q . Source: (Berghuijs et al., 2020) . The first is that the Budyko curve is accurate because landscape features (e.g., soils and vegetation) coevolve with the local climate in such a manner that precipitation partitioning into streamflow and evapotranspiration converges towards the Budyko curve | A second hypothesis is that catchments over time evolve towards the supply and demand limits (rather than towards a curve), because landscapes and their vegetation are unaware of the Budyko curve but do evolve to maximize their use of available resources (including water). However, because limiting factors such as climatic variability exist (which will reduce a catchment&#39;s ability to use all water because it cannot fully buffer the highly variable precipitation input), catchments will tend to not reach these limits. This may lead to an (apparent) existence of the Budyko curve which falls relatively close to the demand and supply limits. | A third hypothesis is that the existence of a strong universal relationship between aridity and catchment water balances might be explained by an underlying organizing principle such as maximum entropy production because the Budyko curve may be consistent with how hydrologic systems optimally partition water and energy | A fourth hypothesis is that virtually any landscape and climate combination (also those in heavily disturbed landscapes: e.g., a city, agricultural lands, etc.) will fall near the Budyko curve because climate aridity will dominate precipitation partitioning largely independent of the climate-landscape configuration or any optimization principle. | Hypotheses for deviations from Budyko curve . Source: (Creed and Spargo, 2012) . Under stationary conditions (naturally occurring oscillations), catchments will fall on the Budyko Curve | Under non-stationary conditions (anthropogenic climate change), catchments will deviate from the Budyko Curve in a predictable manner | Reasons for falling off the Budyko Curve . Inadequate representation of P and T (Loch Vale) | Inadequate representation of ET (Andrews) | Inadequate representation of Q (Marcell) | Forest conversion (Coweeta) | Forest disturbance (Luquillo) | Critique . Source: (Berghuijs et al., 2020) . The (mathematical) specifics of such studies vary, but all approaches are founded on the assumption that catchments follow a (parametric) Budyko curve when aridity changes, and that consequently all other movements in the Budyko space are caused by other factors. The validity of this assumption remains mostly untested, which seems surprising given it underpins all of these studies&#39; findings. . References . Daly, E., Calabrese, S., Yin, J., Porporato, A., 2019. Linking parametric and water-balance models of the Budyko and Turc spaces. Advances in Water Resources 134, 103435. | Sposito, G., 2017. Understanding the Budyko equation. Water 9, 236. | Jones, J.A., Creed, I.F., Hatcher, K.L., Warren, R.J., Adams, M.B., Benson, M.H., Boose, E., Brown, W.A., Campbell, J.L., Covich, A., others, 2012. Ecosystem processes and human influences regulate streamflow response to climate change at long-term ecological research sites. BioScience 62, 390–404. | Krajewski, A., Sikorska-Senoner, A.E., Hejduk, L., Banasik, K., 2021. An Attempt to Decompose the Impact of Land Use and Climate Change on Annual Runoff in a Small Agricultural Catchment. Water Resources Management 35, 881–896. | Berghuijs, W.R., Gnann, S.J., Woods, R.A., 2020. Unanswered questions on the Budyko framework. Hydrological Processes 34, 5699–5703. | Creed, I., Spargo, A., 2012. Budyko guide to exploring sustainability of water yields from catchments under changing environmental conditions. London, Ontario. | Reaver, N.G.F., Kaplan, D.A., Klammler, H., Jawitz, J.W., 2020. Reinterpreting the Budyko Framework. Hydrology and Earth System Sciences Discussions 1–31. | Zhang, L., Hickel, K., Dawes, W.R., Chiew, F.H.S., Western, A.W., Briggs, P.R., 2004. A rational function approach for estimating mean annual evapotranspiration. Water resources research 40. | .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/06/budyko-framework-lecture.html",
            "relUrl": "/jupyter/2020/02/06/budyko-framework-lecture.html",
            "date": " • Feb 6, 2020"
        }
        
    
  
    
        ,"post19": {
            "title": "Unit Hydrograph - lecture",
            "content": "Linear reservoir model . . . . . Rainfall-Runoff Models . The Rational Method . The rational method postulates a simple pro- portionality between peak discharge, $q_{pk}$, and rainfall intensity, $p^*$: . $$ q_{pk} = varepsilon_R cdot C_R cdot A_D cdot p^* $$ $q_{pk}$: peak discharge (m$^3$/s) | $ varepsilon_R=0.278$: unit-conversion factor | $C_R$: dimensionless runoff coefficient | $A_D$: drainage area (km$^2$) | $p^*$: rainfall intensity (mm/h) | . Obviously the results obtained with the method are highly sensitive to the value chosen for CR; values range from 0.05 for gently sloping lawns up to 0.95 for highly urbanized areas of roofs and pavement. The rational method is widely used in urban drainage design, but Pilgrim and Cordery (1992) caution that there are typically few data available to guide the selection of CR, and that CR for a given watershed may vary widely from storm to storm due to differing antecedent conditions. . The Soil Conservation Service Curve-Number Method (SCS-CN) . Also called NRCS curve number procedure. NRCS = Natural Resources Conservation Service - USDA . $$ Q^* = P^* = frac{ left( P-S_{I} right)^2}{P-S_I+S_{max}} $$The initial abstraction $S_I$ is usually approximated as $0.2 cdot S_{max}$, therefore: . $$ Q^* = P^* = frac{ left( P-0.2 cdot S_{max} right)^2}{P+0.8 cdot S_{max}} $$$$ S_{max} = 25.4 left( frac{1000}{CN}-10 right) $$The number 25.4 is a conversion factor from inches to millimeters. . . . The curve number (CN) is a function of the ability of soils to infiltrate water, land use, and the soil water conditions at the start of a rainfall event (antecedent soil water condition). To account for the infiltration character- istics of soils, the NRCS has divided soils into four hydrologic soil groups, which are defined as follows (NRCS, 1984): . Group A (low runoff potential): Soils with high infiltration rates even when thoroughly wetted. These consist chiefly of deep, well-drained sands and gravels. These soils have a high rate of water transmission (final infiltration rate greater than 0.3 in./h). | Group B: Soils with moderate infiltration rates when thoroughly wetted. These consist chiefly of soils that are moderately deep to deep, moderately well drained to well drained with moderately fine to moderately coarse textures. These soils have a moderate rate of water transmission (final infil- tration rate 0.15 to 0.30 in./h). | Group C: Soils with slow infiltration rates when thoroughly wetted. These consist chiefly of soils with a layer that impedes downward movement of water or soils with moderately fine to fine texture. These soils have a slow rate of water transmission (final infiltration rate 0.05 to 0.15 in./h). | Group D (high runoff potential): Soils with very slow infiltration rates when thoroughly wetted. These consist chiefly of clay soils with a high swelling potential, soils with a permanent high water table, soils with a claypan or clay layer at or near the surface, and shallow soils over nearly impervious materials. These soils have a very slow rate of water transmission (final infiltration rate less than 0.05 in./h). | . There are also three categories for Antecedent Soil Moisture Condition (AMC): . AMC I: Dormant season antecedent soil moisture less than 0.5 in. Growing season antecedent soil moisture less than 1.4 in. | AMC II: Dormant season antecedent soil moisture between 0.5 and 1.1 in. Growing season anteced- ent soil moisture between 1.4 and 2.1 in. | AMC III: Dormant season antecedent soil mois- ture greater than 1.1 in. Growing season anteced- ent soil moisture greater than 2.1 in. | . See the table below to find curve numbers for AMC II: . P=21 ratio = 4.17e4/2.61e5 CN=86 Smax = 25.4 * (1000/CN - 10) Pmin = 0.2 * Smax Qstar = 0.0 if P &gt; Pmin: Qstar = (P - 0.2*Smax)**2 / (P+0.8*Smax) Qstar/P . 0.14270006393832066 . ratio . 0.15977011494252874 . Qstar / P . 0.9148811393863234 . %matplotlib notebook import numpy as np import matplotlib.pyplot as plt def Qstar_f(pe, CN): # Smax = 25.4*(1000/CN - 10) Smax = (1000/CN - 10) # Smax = (1000/CN - 10) / 25.4 Qstar = (pe - 0.2*Smax)**2 / (pe+0.8*Smax) return Qstar pe = np.linspace(0,8,101) # plt.plot(pe, Qstar_f(pe, 35)) plt.plot(pe, Qstar_f(pe, 50)) # plt.plot(pe, Qstar_f(pe, 85)) . [&lt;matplotlib.lines.Line2D at 0x7fd8b0e66610&gt;] . 8*25.4 . 203.2 .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/05/unit-hydrograph-lecture.html",
            "relUrl": "/jupyter/2020/02/05/unit-hydrograph-lecture.html",
            "date": " • Feb 5, 2020"
        }
        
    
  
    
        ,"post20": {
            "title": "Streamflow - lecture",
            "content": "Watershed - &#1488;&#1490;&#1503; &#1492;&#1497;&#1511;&#1493;&#1493;&#1514; . . Watershed response: . The volume of water appearing in the appar- ent response hydrograph for a given event is usually only a fraction (often a very small frac- tion) of the total input. The remainder of the water input ultimately leaves the watershed as: (1) evapotranspiration; (2) streamflow that oc- curs so long after the event that it cannot be associated with that event; or (3) ground-water outflow from the watershed. | The water identified as the response to a given event may originate on only a fraction of the watershed; this fraction is called the contrib- uting area. | The extent of the contributing area may vary from event to event and during an event. | At least some of the water identified as the re- sponse to a given event may be “old water” that entered the watershed in a previous event. | . base flow separation . Base flow . Base flow is the portion of streamflow that is presumed to have entered the watershed in previous events and to be derived from persistent, slowly varying sources. (Ground water is usually assumed to be the main, if not the only, such source.) . Event flow . Event flow (also called direct runoff, storm runoff, quick flow, or storm flow) is considered to be the direct response to a given water-input event. . Total flow . Total flow rate at any instant $q(t)$ is the sum of event-flow rate $q^*(t)$ and base-flow rate $q_{BF}$(t): . $$ q(t) = q^*(t) + q_{BF}(t) $$Attention! . Graphical flow separation techniques are heuristic and have no direct scientific basis. . Urbana, IL . hyetograph, hydrograph . notation . base flow separation . effective precipitation = effective discharge . $$ P^* = Q^* $$ . time lags . . It is commonly assumed that $T_{LPC} simeq 0.60 cdot T_c$, where $T_c$ is the time of concentration, i.e., the time it takes water to travel from the hydraulically most distant part of the contributing area to the outlet. . The centroid is a weighted-average time, each time instant is multiplied by the amount of flow in that instant. . Time of precipitation centroid: . $$ t_{pc} = frac{ displaystyle sum_{i=1}^n p_i^* cdot t_i}{P^*} $$Time of streamflow centroid: . $$ t_{qc} = frac{ displaystyle sum_{i=1}^n q_i^* cdot t_i}{Q^*} $$",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/05/streamflow-lecture.html",
            "relUrl": "/jupyter/2020/02/05/streamflow-lecture.html",
            "date": " • Feb 5, 2020"
        }
        
    
  
    
        ,"post21": {
            "title": "Streamflow - exercises",
            "content": "Import relevant packages . import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib.dates as mdates import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) from ipywidgets import * . . Import streamflow data from USGS&#39;s National Water Information System. We will be using data from Urbana, IL. . # Drainage area: 4.78 square miles data_file = &quot;USGS 03337100 BONEYARD CREEK AT LINCOLN AVE AT URBANA, IL.dat&quot; df_q_2020 = pd.read_csv(data_file, header=31, # no headers needed, we&#39;ll do that later delim_whitespace=True, # blank spaces separate between columns na_values=[&quot;Bkw&quot;] # substitute these values for missing (NaN) values ) df_q_2020.columns = [&#39;agency_cd&#39;, &#39;site_no&#39;,&#39;datetime&#39;,&#39;tz_cd&#39;,&#39;EDT&#39;,&#39;discharge&#39;,&#39;code&#39;] # rename df columns with headers columns df_q_2020[&#39;date_and_time&#39;] = df_q_2020[&#39;datetime&#39;] + &#39; &#39; + df_q_2020[&#39;tz_cd&#39;] # combine date+time into datetime df_q_2020[&#39;date_and_time&#39;] = pd.to_datetime(df_q_2020[&#39;date_and_time&#39;]) # interpret datetime df_q_2020 = df_q_2020.set_index(&#39;date_and_time&#39;) # make datetime the index df_q_2020[&#39;discharge&#39;] = df_q_2020[&#39;discharge&#39;].astype(float) df_q_2020[&#39;discharge&#39;] = df_q_2020[&#39;discharge&#39;] * 0.0283168 # convert cubic feet to m3 fig, ax = plt.subplots(figsize=(10,7)) ax.plot(df_q_2020[&#39;discharge&#39;], &#39;-o&#39;) plt.gcf().autofmt_xdate() ax.set(xlabel=&quot;date&quot;, ylabel=r&quot;discharge (m$^3$/5min)&quot;); . . Import sub-hourly (5-min) rainfall data from NOAA&#39;s Climate Reference Network Data website . data_file = &quot;Champaign - IL.txt&quot; df_p_2020 = pd.read_csv(data_file, header=None, # no headers needed, we&#39;ll do that later delim_whitespace=True, # blank spaces separate between columns na_values=[&quot;-99.000&quot;, &quot;-9999.0&quot;] # substitute these values for missing (NaN) values ) headers = pd.read_csv(&quot;HEADERS_sub_hourly.txt&quot;, # load headers file header=1, # skip the first [0] line delim_whitespace=True ) df_p_2020.columns = headers.columns # rename df columns with headers columns # LST = local standard time df_p_2020[&quot;LST_TIME&quot;] = [f&quot;{x:04d}&quot; for x in df_p_2020[&quot;LST_TIME&quot;]] # time needs padding of zeros, then convert to string df_p_2020[&#39;LST_DATE&#39;] = df_p_2020[&#39;LST_DATE&#39;].astype(str) # convert date into string df_p_2020[&#39;datetime&#39;] = df_p_2020[&#39;LST_DATE&#39;] + &#39; &#39; + df_p_2020[&#39;LST_TIME&#39;] # combine date+time into datetime df_p_2020[&#39;datetime&#39;] = pd.to_datetime(df_p_2020[&#39;datetime&#39;]) # interpret datetime df_p_2020 = df_p_2020.set_index(&#39;datetime&#39;) # make datetime the index . . Plot rainfall and streamflow. Does this makes sense? . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7)) fig.subplots_adjust(hspace=0.05) start = &quot;2020-10-18&quot; end = &quot;2020-10-25&quot; ax1.plot(df_p_2020[start:end][&#39;PRECIPITATION&#39;]) ax2.plot(df_q_2020[start:end][&#39;discharge&#39;], color=&quot;tab:blue&quot;, lw=2) ax1.set(xticks=[], ylabel=r&quot;precipitation (mm)&quot;) ax2.set(xlabel=&quot;date&quot;, ylabel=r&quot;discharge (m$^3$/5min)&quot;) plt.gcf().autofmt_xdate() # makes slated dates . . Define smaller dataframes for $p(t)$ and $q(t)$, between the dates: . start = &quot;2020-10-20 14:00:00&quot; end = &quot;2020-10-21 04:00:00&quot; . Don&#39;t forget to convert the units to SI! . Calculate total rainfall $P^*$ and total discharge $Q^*$, in m$^3$. . # Drainage area: 4.78 square miles area = 4.78 / 0.00000038610 # squared miles to squared meters start = &quot;2020-10-20 14:00:00&quot; end = &quot;2020-10-21 04:00:00&quot; df_p = df_p_2020.loc[start:end][&#39;PRECIPITATION&#39;].to_frame() df_p_mm = df_p_2020.loc[start:end][&#39;PRECIPITATION&#39;].to_frame() df_q = df_q_2020.loc[start:end][&#39;discharge&#39;].to_frame() df_p[&#39;PRECIPITATION&#39;] = df_p[&#39;PRECIPITATION&#39;].values * area / 1000 # mm to m3 in the whole watershed df_p[&#39;PRECIPITATION&#39;] = df_p[&#39;PRECIPITATION&#39;] / 60 / 5 # convert m3 per 5 min to m3/s P = df_p[&#39;PRECIPITATION&#39;].sum() * 60 * 5 Q = df_q[&#39;discharge&#39;].sum() * 60 * 5 print(&quot;total precipitation during event: Pstar = {:.1e} m3&quot;.format(P.sum())) print(&quot;total streamflow during event: Qstar = {:.1e} m3&quot;.format(Q.sum())) . . total precipitation during event: Pstar = 2.6e+05 m3 total streamflow during event: Qstar = 5.2e+04 m3 . Make another graph of $p(t)$ and $q(t)$, now with SI units. . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7)) fig.subplots_adjust(hspace=0.05) start = &quot;2020-10-18&quot; end = &quot;2020-10-25&quot; ax1.plot(df_p[&#39;PRECIPITATION&#39;]) ax2.plot(df_q[&#39;discharge&#39;], color=&quot;tab:blue&quot;, lw=2) ax1.set(xticks=[], ylabel=r&quot;precipitation (m$^3$/s)&quot;, title=&quot;Precipitation and discharge, Boneyard Creek at Urbana, IL n 20-21 October 2020, 5-minute data&quot;) ax2.set(xlabel=&quot;date&quot;, ylabel=r&quot;discharge (m$^3$/s)&quot;) plt.gcf().autofmt_xdate() # makes slated dates . . It&#39;s time for base flow separation! Convert q(t) into q*(t) . from matplotlib.dates import HourLocator, DateFormatter import matplotlib.dates as mdates import matplotlib.ticker as ticker fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7)) fig.subplots_adjust(wspace=0.05) ax1.plot(df_q[&#39;discharge&#39;], color=&quot;black&quot;, lw=2) point1 = pd.to_datetime(&quot;2020-10-20 16:40:00&quot;) point2 = pd.to_datetime(&quot;2020-10-21 00:00:00&quot;) two_points = df_q.loc[[point1, point2]][&#39;discharge&#39;] ax1.plot(two_points, &#39;o&#39;, color=&quot;tab:red&quot;) new = pd.DataFrame(data=two_points, index=two_points.index) df_linear = (new.resample(&quot;5min&quot;) #resample .interpolate(method=&#39;time&#39;) #interpolate by time ) ax1.plot(df_linear, color=&quot;tab:blue&quot;) df_between_2_points = df_q.loc[df_linear.index] ax1.fill_between(df_between_2_points.index, df_between_2_points[&#39;discharge&#39;], y2=df_linear[&#39;discharge&#39;], color=&quot;tab:blue&quot;, alpha=0.3) qstar = df_q.loc[df_linear.index][&#39;discharge&#39;] - df_linear[&#39;discharge&#39;] Qstar = qstar.sum() * 60 * 5 ax2.plot(qstar, color=&quot;black&quot;, lw=2) ax2.fill_between(qstar.index, qstar, y2=0.0, color=&quot;tab:blue&quot;, alpha=0.3) ax1.set(xlim=[df_q.index[0], df_q.index[-1]], ylabel=r&quot;discharge (m$^3$/s)&quot;, ylim=[0, 5.5], yticks=[0,1,2,3,4], title=&quot;total discharge, q(t)&quot;) ax2.set(yticks=[], ylim=[0, 5.5], xlim=[df_q.index[0], df_q.index[-1]], title=&quot;effective discharge, q*(t)&quot; ) plt.gcf().autofmt_xdate() # makes slated dates . . We can calculate p* now, using . $$ P^* = Q^* $$One of the simplest methods is to multiply $p(t)$ by a fixed constant (&lt;1) to obtain $p^*$, so that the equation above holds true. . ratio = Qstar/ P pstar = df_p[&#39;PRECIPITATION&#39;] * ratio Pstar = pstar.sum() * 5 * 60 print(f&quot;Qstar / P = {ratio:.2f}&quot;) . . Qstar / P = 0.16 . Calculate now the centroid ($t_pc$) for effective precipitation p and centroid ($t_{qc}$) of effective discharge q. Calculate also the time of peak discharge ($t_{pk}$). Then, calculate the centroid lag ($T_{LC}$), the centroid lag-to-peak ($T_{LPC}$), and the time of concentration ($T_c$). Use the equations below: . $T_{LPC} simeq 0.60 cdot T_c$ . Time of precipitation centroid: . $$ t_{pc} = frac{ displaystyle sum_{i=1}^n p_i^* cdot t_i}{P^*} $$Time of streamflow centroid: . $$ t_{qc} = frac{ displaystyle sum_{i=1}^n q_i^* cdot t_i}{Q^*} $$Centroid lag: . $$ T_{LC} = t_{qc} - t_{pc} $$Centroid lag-to-peak: $$ T_{LPC} = t_{pk} - t_{pc} $$ . Time of concentration: $$ T_{LPC} simeq 0.60 cdot T_c $$ . # pstar centroid # time of the first (nonzero) rainfall data point t0 = pstar[pstar != 0.0].index[0] # time of the last (nonzero) rainfall data point tf = pstar[pstar != 0.0].index[-1] # duration of the rainfall event, in minutes td = (tf-t0) / pd.Timedelta(&#39;1 min&#39;) # make time array, add 2.5 minutes (half of dt) time = np.arange(0, td+1, 5) + 2.5 # create pi array, only with relevant data (during rainfall duration) pi = pstar.loc[(pstar.index &gt;= t0) &amp; (pstar.index &lt;= tf)] # convert from m3/5min to m3/s pi = pi.values * 60 * 5 # time of precipitation centroid t_pc = (pi * time).sum() / pi.sum() # add initial time t_pc = t0 + pd.Timedelta(minutes=t_pc) t_pc # qstar centroid # time of the first (nonzero) discharge data point t0 = qstar[qstar != 0.0].index[0] # time of the last (nonzero) discharge data point tf = qstar[pstar != 0.0].index[-1] # duration of the discharge event, in minutes td = (tf-t0) / pd.Timedelta(&#39;1 min&#39;) # make time array, add 2.5 minutes (half of dt) time = np.arange(0, td+1, 5) + 2.5 # create qi array, only with relevant data (during discharge duration) qi = qstar.loc[(qstar.index &gt;= t0) &amp; (qstar.index &lt;= tf)] # convert from m3/5min to m3/s qi = qi.values * 60 * 5 # time of discharge centroid t_qc = (qi * time).sum() / qi.sum() # add initial time t_qc = t0 + pd.Timedelta(minutes=t_qc) t_qc # time of peak discharge max_discharge = qstar.max() t_pk = qstar[qstar == max_discharge].index[0] # centroid lag T_LC = t_qc - t_pc # centroid lag-to-peak T_LPC = t_pk - t_pc # time of concentration T_c = T_LPC / 0.60 print(f&quot;T_LC = {T_LC}&quot;) print(f&quot;T_LPC = {T_LPC}&quot;) print(f&quot;T_c = {T_c}&quot;) . . T_LC = 0 days 00:53:03.186594 T_LPC = 0 days 01:22:59.857820 T_c = 0 days 02:18:19.763033333 .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/05/streamflow-exercises.html",
            "relUrl": "/jupyter/2020/02/05/streamflow-exercises.html",
            "date": " • Feb 5, 2020"
        }
        
    
  
    
        ,"post22": {
            "title": "Assignment 3 - Streamflow",
            "content": "&#128210; instructions . This is where learning happens, not during a lecture. You&#39;ll learn a ton of things by doing them yourself. Much success! 😄 . Create a Jupyter Notebook called assignment-03-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check. . &#128204; locations and data . Choose one location in the US. . Import streamflow data from USGS&#39;s National Water Information System. Choose on the map any measuring station you see fit. Make sure there is available discharge data (usually given in cubic feet per second) in small time intervals, e.g., every 15 minutes. . | Go to NOAA&#39;s Climate Reference Network Data website. The sub-hourly (5-min) data contains information on many variables, we are interested in precipitation. . | Attention! Some os the USGS stations provide precipitation data. If you find one such station, step 2 above is unnecessary. If you only find discharge data in the USGS website, then make sure you choose two stations in very close proximity (USGS and NOAA). Because there are only a few high-resolution NOAA stations, you might want to start from there and then find discharge data for a stream near the NOAA station. . Bottom line: you are looking for precipitation and stream discharge data, for stations in close proximity, with a high temporal resolution (5 min, 15 min, etc). . &#128736; tasks . Choose a rain event of a few hours in your data set. Find the rate of effective water input (p) and the event flow rate (q). Analyze the data in a similar was as done during class (various graphs explaining what you see). Find also the characteristic times of the event (centroid lag $T_{LC}$, and centroid lag-to-peak $T_{LPC}$). . Try to find information on the climate, geography, soil, and land use of the watershed. Begin the assignment by explaining about the watershed you chose and characterizing it. When presenting the data and your analyses, discuss what you see based on the concepts learned in class (infiltration, runoff generation, and the factors that affect them). Does the information you found match what you see? What makes sense, and what doesn&#39;t? . Discussion is important! . You will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, I&#39;m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Don&#39;t forget to put labels on your plot axes, title, legend, etc. . Your Jupyter Notebook should be fully functional: if we press Kernel &gt; Restart &amp; Run All, all the code must work without any errors. . &#127749; presentation . All the assignment must be in one single Jupyter Notebook. Use markdown cells to discuss the analysis and results, and in code cells show all the code you used to produce the figures and data analysis. Leave only the code necessary for your analysis, delete unnecessary lines your wrote while analyzing your data. Don&#39;t forget to comment your code, just like we did during exercise sessions. . You can write in English or in Hebrew, but the text in the figures must be in English. If you choose to write the discussion in Hebrew, be aware that Jupyter Notebooks don&#39;t have native right-to-left language support: . ניתן לכתוב בעברית, למרות שזה לא נראה כ״כ טוב... . You can use some HTML code to achieve best results in Hebrew. Type the following . &lt;p dir=&quot;rtl&quot; style=&quot;text-align: right;&quot;&gt; עכשיו הרבה יותר טוב! &lt;/p&gt; . to get . עכשיו הרבה יותר טוב! . If you have many paragraphs in hebrew, do the following: . פסקה מספר 1. . פסקה מספר 2. . אם יש לכם כמה פסקאות, כל אחת מהן תהיה בתוך &quot;dir&quot; משלה . In my opinion it is too complicated to write in Hebrew in Jupyter Notebooks, just write in English, your grade will not be affected by typos nor less-than-perfect English proficiency. . &#128175; evaluation . Your assignment will be evaluated according to the following criteria: . 40% Presentation. How the graphs look, labels, general organization, markdown, clean code. | 30% Discussion. This is where you explain what you did, what you found out, etc. | 15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration. | 10% Replicability: Your code runs flawlessly. | 5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself! | . &#128666; importing the data . You can use the code from previous assignments and from the exercise lectures. .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/05/assignment-03-streamflow.html",
            "relUrl": "/jupyter/2020/02/05/assignment-03-streamflow.html",
            "date": " • Feb 5, 2020"
        }
        
    
  
    
        ,"post23": {
            "title": "Infiltration - lecture",
            "content": "Sources . Sources used: . (Hillel, 1998) (Dingman, 2015) (Ward and Trimble, 2003) . Definitions . (Hillel, 1998), figure 14.6, page 400 . (Dingman, 2015), figure 8.13, page 360 . (Dingman, 2015), figure 8.14, page 360 . (Hillel, 1998), figure 14.3, page 390 . (Dingman, 2015), page 355 . The water-input rate, $w(t)$ [L T$^{-1}$], is the rate at which water arrives at the surface due to rain, snowmelt, or irrigation. A water-input event begins at time $t=0$ and ends at $t=T_w$. | The infiltration rate, $f(t)$ [L T$^{-1}$], is the rate at which water enters the soil from the surface. | The infiltrability, also called infiltration capacity, $f^*(t)$ [L T$^{-1}$], is the maximum rate at which infiltration could occur at any time; note that this changes during the infiltration event. | The depth of ponding, $H(t)$ [L], is the depth of water standing on the surface. | . (Ward and Trimble, 2003), page 63, 64 . Infiltration capacity of absorbent paper is low, there is much runoff . Infiltration capacity of sponge is high, there is little runoff . Infiltration capacity of the sponge is limited by the overlying layer with low permeability . Infiltration capacity of the sponge is limited by the underlying layer . (Ward and Trimble, 2003), page 65 . . . Darcy . Darcy’s equation for vertical flow . q=−K∂Htotal∂zq = -K frac{ partial H_ text{total}}{ partial z}q=−K∂z∂Htotal​​ . where the total head $H_ text{total}=-H_ text{suction}-z_ text{depth}$, and . $H_ text{suction}$ is the suction head (negative pressure head) | $z_ text{depth}$ is the depth, points downward. | . Substituting: . q=K∂Hsuction∂z+Kq = K frac{ partial H_ text{suction}}{ partial z} + Kq=K∂z∂Hsuction​​+K . Substituting the above into the continuity equation . ∂θ∂t=∂q∂z frac{ partial theta}{ partial t} = frac{ partial q}{ partial z}∂t∂θ​=∂z∂q​ . yields the Richards equation. . . . Richards . Richards equation: . ∂θ∂t=∂∂z[K(θ)∂Htotal∂z] frac{ partial theta}{ partial t} = frac{ partial}{ partial z} left[ K( theta) frac{ partial H_ text{total}}{ partial z} right]∂t∂θ​=∂z∂​[K(θ)∂z∂Htotal​​] . Substituting $H_ text{total}=-H_ text{suction}-z_ text{depth}$ yields: . ∂θ∂t=∂∂z[K(θ)(∂(−Hsuction−z)∂z)] frac{ partial theta}{ partial t} = frac{ partial}{ partial z} left[ K( theta) left( frac{ partial(-H_ text{suction} - z)}{ partial z} right) right]∂t∂θ​=∂z∂​[K(θ)(∂z∂(−Hsuction​−z)​)] . ∂θ∂t=−∂∂z(K(θ)∂Hsuction∂z)undefinedmatric−∂K(θ)∂zundefinedgravitational frac{ partial theta}{ partial t} = . underbrace{ frac{ partial}{ partial z} left( K( theta) frac{ partial H_ text{suction}}{ partial z} right) } _{ text{matric}} - underbrace{ frac{ partial K( theta)}{ partial z} } _{ text{gravitational}}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;∂t∂θ​=−matric . ∂z∂​(K(θ)∂z∂Hsuction​​)​​−gravitational . ∂z∂K(θ)​​​&lt;/span&gt;&lt;/span&gt; . Short times . As the water starts to enter the relatively dry soil, the pressure differences in the water at the surface and in the soil are quite large and, as a result, the second term on the right is practically negligible compared to the first one. . ∂θ∂t=−∂∂z(K(θ)∂H∂z) frac{ partial theta}{ partial t} = . frac{ partial}{ partial z} left( K( theta) frac{ partial H}{ partial z} right)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;∂t∂θ​=−∂z∂​(K(θ)∂z∂H​)&lt;/span&gt;&lt;/span&gt; . Long times . As illustrated in the figure below (Davidson et al., 1963), after longer times of infiltration, the water content profile near the surface gradually becomes more uniform and it eventually assumes the satiation value, or $ theta rightarrow theta_0$; similarly, the pressure in the upper layers of the soil becomes gradually atmospheric, or $H rightarrow 0$. Hence, their vertical gradients . ∂θ∂z and ∂Hsuction∂z⟶0 frac{ partial theta}{ partial z} text{ and } frac{ partial H_ text{suction}}{ partial z} longrightarrow 0∂z∂θ​ and ∂z∂Hsuction​​⟶0 . From Darcy’s equation we have that . q=K(θ0)=Ksatq = K( theta_0) = K_ text{sat}q=K(θ0​)=Ksat​ . . . . Rainfall infiltration . Infiltration rate is equal to rainfal rate, at least at first. If rainfall rate $w$ is lower than $K_ text{sat}$, than everything enters the soil, i.e., $f=K_ text{sat}$. However, if $w&gt;K_ text{sat}$, water content $ theta$ will increase at the surface, until it reaches $ theta_0$, and at that moment, called ponding time $t_p$, water will begin to accumulate at the surface. . (Hillel, 1998), figure 14.1, page 386 . (Hillel, 1998), figure 14.2, page 388 . . . Horton equation . One of the most widely used models, developed by R.E. Horton (1939), considered to be the father of modern hydrology. . f=fc+(f0−fc)e−βtf = f_c+(f_0-f_c)e^{- beta t}f=fc​+(f0​−fc​)e−βt . $f$: infiltration rate | $f_c$: infiltration capacity at large $t$ | $f_0$: initial infiltration capacity | $ beta$: best fit empirical parameter | . Advantages . Simple equation | Usually gives good fit to measured data because it is dependent on three parameters | . Disadvantages . This method has no physical significance, it is not based on any water transport mechanism | Does not describe infiltration prior to ponding | . . . Green &amp; Ampt . (Dingman, 2015), figure 8.11, page 357 . Assumptions: . homogeneous soil, infinite depth (no water table) | horizontal surface | constant water head equal to zero is maintained at the surface | uniform water content prior to wetting, $ theta(t=0,z)= theta_0$ | moving front is characterized by a constant matric suction, $ psi_f$ | . (Dingman, 2015), page 370 . This equation was developed under the scenario of constant rainfall or irrigation on an initially dry soil as a sharp wetting front (such as piston flow). Water penetrates a dry soil with a certain initial moisture content, and wets the layer to a saturated moisture content as it traverses deeper. The connection between soil moisture and infiltration rate is modeled in the Green-Ampt equation: . f(t)=Ksat[1+∣ψf∣⋅(ϕ−θ0)F(t)]f(t) = K_ text{sat} left[ 1 + frac{| psi_f| cdot left( phi - theta_0 right)}{F(t)} right]f(t)=Ksat​[1+F(t)∣ψf​∣⋅(ϕ−θ0​)​] . $f(t)$: infiltration rate | $F(t)$: cumulative infiltration rate, $F= int f text{ d}t$ | $ psi_f$: effective wetting-front suction | $ phi$: soil porosity | $ theta_0$: initial soil water content | . The same equation can be simply be rewritten as . f=AF+Bf = frac{A}{F} + Bf=FA​+B . where . A=Ksat⋅∣ψf∣⋅(ϕ−θ0)B=Ksat begin{align} A &amp;= K_ text{sat} cdot| psi_f| cdot left( phi - theta_0 right) B &amp;= K_ text{sat} end{align}AB​=Ksat​⋅∣ψf​∣⋅(ϕ−θ0​)=Ksat​​​ . The porosity $ phi$ and the saturated hydraulic conductivity $K_ text{sat}$ can be estimated from the soil texture. The wetting-front suction $ psi_f$ can be estimated using the Brooks-Corey parameters: . ∣ψf∣=2b+32b+6⋅∣ψae∣,| psi_f| = frac{2b+3}{2b+6} cdot | psi_{ae}|,∣ψf​∣=2b+62b+3​⋅∣ψae​∣, . where $ psi_{ae}$ is the air-entry pressure head. Values for the parameters above can be found in this table: . . . . Best Fit, Least Squares Method . . References . Hillel, D., 1998. Environmental Soil Physics. Academic Press. | Dingman, S.L., 2015. Physical Hydrology. Waveland Press. | Ward, A.D., Trimble, S.W., 2003. Environmental Hydrology. CRC Press. |",
            "url": "https://yairmau.github.io/website/markdown/2020/02/04/infiltration-lecture.html",
            "relUrl": "/markdown/2020/02/04/infiltration-lecture.html",
            "date": " • Feb 4, 2020"
        }
        
    
  
    
        ,"post24": {
            "title": "Infiltration - exercises",
            "content": "Tasks . Google the following: web plot digitizer | Load image &quot;nassif-16percent-slope.png&quot; (see below) | Create four csv files, one for each data set. Call them whatever you want. Legend: white circle = 312 mm/h, triangle = 234 mm/h, x = 156 mm/h, black circle = 78 mm/h. | The image is the second panel of Fig. 8, from . Nassif, S. H., and E. M. Wilson, 1975, &quot;THE INFLUENCE OF SLOPE AND RAIN INTENSITY ON RUNOFF AND INFILTRATION&quot;, Hydrological Sciences Journal. download here . Import relevant packages . import numpy as np import matplotlib.pyplot as plt import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) from scipy.optimize import curve_fit import matplotlib.patches as patches . . Load all four files you created. Use numpy&#39;s function loadtxt. Make sure that the first point in each table corresponds to the appropriate rainfall rate. You can normalize the data if it is not. . d1 = np.loadtxt(&quot;input_rate_078mm_per_h_16percent_slope.csv&quot;, delimiter=&#39;,&#39;) d2 = np.loadtxt(&quot;input_rate_156mm_per_h_16percent_slope.csv&quot;, delimiter=&#39;,&#39;) d3 = np.loadtxt(&quot;input_rate_234mm_per_h_16percent_slope.csv&quot;, delimiter=&#39;,&#39;) d4 = np.loadtxt(&quot;input_rate_312mm_per_h_16percent_slope.csv&quot;, delimiter=&#39;,&#39;) d1[:,1] = 78 * d1[:,1] / d1[:,1].max() d2[:,1] = 156 * d2[:,1] / d2[:,1].max() d3[:,1] = 234 * d3[:,1] / d3[:,1].max() d4[:,1] = 312 * d4[:,1] / d4[:,1].max() . . Reproduce the original figure, make it look good, something like this: . fig, ax = plt.subplots(figsize=(10,7)) ax.plot(d4[:,0], d4[:,1], &#39;o&#39;, markerfacecolor=&quot;None&quot;, label=r&quot;water input = 312 mm h$^{-1}$&quot;) ax.plot(d3[:,0], d3[:,1], &#39;^&#39;, label=r&quot;water input = 234 mm h$^{-1}$&quot;) ax.plot(d2[:,0], d2[:,1], &#39;x&#39;, label=r&quot;water input = 156 mm h$^{-1}$&quot;) ax.plot(d1[:,0], d1[:,1], &#39;o&#39;, label=r&quot;water input = 78 mm h$^{-1}$&quot;) ax.set(xlabel=&quot;Time (min)&quot;, ylabel=r&quot;Infiltration rate (mm h$^{-1}$)&quot;) ax.legend(loc=&quot;upper right&quot;); . . Horton&#39;s equation . $$ f = f_c+(f_0-f_c)e^{- beta t} $$ $f$: infiltration rate | $f_c$: infiltration capacity at large $t$ | $f_0$: initial infiltration capacity | $ beta$: best fit empirical parameter | . Write a function called horton, that receives time t and the three parameters, and returns the right-hand side of the equation above. Plot one of the data sets, together with a guess of the parameters that should roughly fit the data. . def horton(t, fc, f0, beta): return fc + (f0 - fc)*np.exp(-beta*t) fig, ax = plt.subplots(figsize=(10,7)) t = d1[:,0] t = t - t[0] f = d1[:,1] ax.plot(t, f, &#39;o&#39;, label=&quot;data&quot;) ax.plot(t, horton(t, 35, 80, 0.5), &#39;-&#39;, label=&quot;horton&quot;) ax.set(xlabel=&quot;time (min)&quot;, ylabel=&quot;infiltration rate (mm/h)&quot;) ax.legend(loc=&quot;upper right&quot;); . . Find the best fit for the parameters $f_c, f_0, beta$. Calculate the $R^2$ for each data set. . For the best fit, use scipy&#39;s curve_fit. Write a function to compute the R-squared of your fit. . def horton(t, fc, f0, beta): return fc + (f0 - fc)*np.exp(-beta*t) def best_fit(data): t = data[:,0] t0 = t[0] t = t - t0 f = data[:,1] # best fit popt, pcov = curve_fit(f=horton, # model function xdata=t, # x data ydata=f, # y data p0=(130, 800, 0.5), # initial guess of the parameters ) return [popt, pcov] def calculate_r_squared(data, popt): t = data[:,0] t = t - t[0] f = data[:,1] # Calculate residuals residuals = f - horton(t, *popt) # You can get the residual sum of squares (ss_res) with ss_res = np.sum(residuals**2) # You can get the total sum of squares (ss_tot) with ss_tot = np.sum((f - np.mean(f))**2) # And finally, the r_squared-value with, r_squared = 1 - (ss_res / ss_tot) return r_squared def plot_best_fit(data, axis, marker, markercolor): # calculate best fit parameters popt, pcov = best_fit(data) t = data[:,0] f = data[:,1] # plot data points ax.plot(t, f, marker, markerfacecolor=markercolor, markeredgecolor=&quot;black&quot;) # plot best fit line r_squared = calculate_r_squared(data, popt) labeltext = r&quot;$f_c=$ {:.2f}, $f_0=$ {:.2f}, $ beta=$ {:.2f}, $R^2=$ {:.2f}&quot;.format(popt[0],popt[1],popt[2], r_squared) ax.plot(t, horton(t-t[0], *popt), color=markercolor, label=labeltext) fig, ax = plt.subplots(figsize=(10,7)) plot_best_fit(d1, ax, &#39;o&#39;, &quot;tab:red&quot;) plot_best_fit(d2, ax, &#39;x&#39;, &quot;tab:blue&quot;) plot_best_fit(d3, ax, &#39;^&#39;, &quot;tab:orange&quot;) plot_best_fit(d4, ax, &#39;d&#39;, &quot;tab:green&quot;) ax.set(xlabel=&quot;time (min)&quot;, ylabel=&quot;infiltration rate (mm/h)&quot;) ax.legend(); . . Make a graph of the infiltration rate and of the runoff, as a function of time. Use any of the four data sets you have. . fig, ax = plt.subplots(figsize=(10,7)) data = d4 t = data[:, 0] f = data[:, 1] t = np.concatenate([ [0], t]) f = np.concatenate([ [f[0]], f]) runoff = f[0] - f ax.plot(t, f*0 + f[0], ls=&quot;--&quot;, color=&quot;black&quot;, label=&quot;rainfall&quot;) ax.plot(t, f, color=&quot;tab:blue&quot;, lw=3, label=r&quot;infiltration&quot;) ax.plot(t, runoff, color=&quot;tab:orange&quot;, lw=3, label=r&quot;runoff&quot;) ax.set(xlabel=&quot;Time (min)&quot;, ylabel=r&quot;Rate (mm h$^{-1}$)&quot;) ax.legend(loc=&quot;lower right&quot;); . . Green &amp; Ampt . $$f = frac{A}{F} + B$$ . where . $A = K_ text{sat} cdot| psi_f| cdot left( phi - theta_0 right)$ | $B= K_ text{sat}$ | . Write a function that calculates the cumulative of the infiltration rate. . $$ F(t) = int_0^t f(t) text{ d}t $$Use numpy&#39;s trapz function, that implements the &quot;trapezoidal rule&quot; . . def cumulative_F(t, f): F = np.array([0]) t = t/60 # convert minute to hour for i in np.arange(2,len(t)+1): area = np.trapz(f[:i], t[:i]) F = np.concatenate([F, [area]]) return F fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7)) t, f = d1[:,0], d1[:,1] F = cumulative_F(t, f) ax1.plot(t, f, label=&quot;f, rate&quot;) ax2.plot(t, F, label=&quot;F, cumulative&quot;) ax1.set(xlabel=&quot;t (min)&quot;, ylabel=&quot;f (mm/h)&quot;) ax2.set(xlabel=&quot;t (min)&quot;, ylabel=&quot;F (mm)&quot;) ax2.yaxis.set_label_position(&quot;right&quot;) . . Plot $f$ as a function of $F$. Try to guess $A$ and $B$ that give reasonable results. . fig, ax = plt.subplots(figsize=(10,7)) t, f = d1[:,0], d1[:,1] F = cumulative_F(t, f) ax.plot(F, f) A=50; B=30; ax.plot(F, A/F + B, &#39;o&#39;) ax.set(xlabel=&quot;F&quot;, ylabel=&quot;f&quot;) . . /Users/yairmau/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide . [Text(0.5, 0, &#39;F&#39;), Text(0, 0.5, &#39;f&#39;)] . Use the curve_fit to find the optimal values for $A$ and $B$. . def G_and_A(F, A, B): return A/F + B popt, pcov = curve_fit(f=G_and_A, # model function xdata=F[1:], # x data ydata=f[1:], # y data p0=(50, 30), # initial guess of the parameters ) # popt, pcov = curve_fit(G_and_A, F[1:], f[1:], p0=(50, 30)) # p0 = initial guess print(popt) fig, ax = plt.subplots(figsize=(10,7)) ax.plot(F, f) ax.plot(F[1:], popt[0]/F[1:] + popt[1], &#39;o&#39;) ax.set(xlabel=&quot;F&quot;, ylabel=&quot;f&quot;) . . [24.12368526 36.34242813] . [Text(0.5, 0, &#39;F&#39;), Text(0, 0.5, &#39;f&#39;)] . Homework . Go to Soil Texture Calculator, estimate the texture of &quot;standard soil&quot; in Nassif &amp; Wilson, 1975. .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/04/infiltration-exercises.html",
            "relUrl": "/jupyter/2020/02/04/infiltration-exercises.html",
            "date": " • Feb 4, 2020"
        }
        
    
  
    
        ,"post25": {
            "title": "Evapotranspiration - lecture",
            "content": "Dingman, &quot;Physical Hydrology&quot;, chapter 6. . Globally, about 62% of the precipitation that falls on the continents is evapotranspirated, amounting to 73 thousand km$^3$/yr. Of this, about 42% (29 thousand km$^3$/yr) is transpiration, and about 3% is open-water evaporation. Most of the remainder is interception loss; soil evaporation is a minor component of the total. . . . Potential Evapotranspiration . Potential Evapotranspiration (PET) is the rate at which evapotranspiration would occur from a large area completely and uniformly covered with growing vegetation with access to an unlimited supply of soil water and without advection or heat-storage effects. . Several characteristics of a vegetative surface have a strong influence on ET rate. a) the albedo of the surface, which determines the net radiation; b) the maximum leaf conductance; c) the atmospheric conductance, largely determined by vegetation height; d) presence or absence of intercepted water. . Reference-Crop Evapotranspiration . Reference-crop evapotranspiration (RET) is the amount of water transpired by a short green crop, completely shading the ground, of uniform height, and never short of water. . The magnitude of PET is often calculated from meteorological data collected under conditions in which the actual ET rate is less than the potential rate. If ET had been occurring at the potential rate, the latent- and sensible-heat exchanges between air and the surface, and hence the air temperature and humidity, would have been considerably different. (Brutsaert 1982) . . Review of methods . There are a variety of ways to estimate evaporative flux in nature. The following table categorizes each method based on the data that must be acquired to apply it: . . These methods also vary in the timescales in which they are relevant, typically in correlation with the variety of data needed: . Thornthwaite and SCS Blaney-Criddle: monthly or seasonal estimations (minimal data) | Jensen-Haise: 5-day estimates (good enough timescale and data for irrigation scheduling) | Penman: daily estimates | Penman-Monteith: hourly estimates (requires a lot of data) | . . Thornthwaite . Source: Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, pages 107-108. . Thornthwaite (1948) developed an equation to predict monthly evapotranspiration from mean monthly tempera- ture and latitude data (Equation 4.27). The small amount of data needed is attractive because often ET needs to be predicted for sites where few weather data are available. Based on what we know about ET, we should be skeptical about the general applicability of such a simple equation. Thornthwaite (1948) was not satisfied with the proposed approach: “The mathematical development is far from satisfactory. It is empirical. ... The chief obstacle at present to the development of a rational equation is the lack of understanding of why potential ET corresponding to a given temperature is not the same everywhere.” Taylor and Ashcroft (1972), as cited in Skaggs (1980), provided insight into the answer to Thornthwaite’s ques- tion. They said: . This equation, being based entirely upon a temperature relationship, has the disadvantage of a rather flimsy phys- ical basis and has only weak theoretical justification. Since temperature and vapor pressure gradients are mod- ified by the movement of air and by the heating of the soil and surroundings, the formula is not generally valid, but must be tested empirically whenever the climate is appreciably different from areas in which it has been tested. ... In spite of these shortcomings, the method has been widely used. Because it is based entirely on temper- ature data that are available in a large number of localities, it can be applied in situations where the basic data of the Penman method are not available. . M.E. Jensen et al. (1990) warn that Thornthwaite’s method is generally only applicable to areas that have climates similar to that of the east central U.S., and it is not applicable to arid and semiarid regions. . Thornthwaite (1948) found that evapotranspiration could be predicted from an equation of the form . $$ begin{equation} E = 16 left[ frac{10 ,T^ text{monthly mean}}{I} right]^a, end{equation} $$where $$ begin{equation} I = sum_{i=1}^{12} left[ frac{T_i^ text{monthly mean}}{5} right]^{1.514}, end{equation} $$ and $$ begin{align} a &amp;= 6.75 times 10^{-7}I^3 &amp;- 7.71 times 10^{-5}I^2 nonumber &amp;+ 1.792 times 10^{-2}I nonumber &amp;+ 0.49239 nonumber end{align} $$ . $E$ is the monthly potential ET (mm) | $T_ text{monthly mean}$ is the mean monthly temperature in °C | $I$ is a heat index | $a$ is a location-dependent coefficient | . . Penman . Sources: Brutsaert, &quot;Hydrology: An Introduction&quot;, pages 123-127. Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, subsections 4.5.2, 4.5.3, 4.5.5, 4.6.6. Allen et al. (1998), &quot;Crop evapotranspiration - Guidelines for computing crop water requirements - FAO Irrigation and drainage paper 56&quot; . The Penman model is almost entirely a theory-based formula for predicting evaporative flux. It can run on a much finer timescale, and requires a much wider variety of data than most models. In addition to temperature, the Penman functions on measurements of radiation, wind speed, elevation above sea level, vapor-pressure deficit, and heat flux density to the ground. The potential ET (in mm d$^{-1}$) is given by: . $$ begin{equation} E = frac{1}{ lambda} left[ frac{ Delta}{ Delta+ gamma}Q_{ne}+ frac{ gamma}{ Delta+ gamma}E_A right], end{equation} $$where $Q_n$ is the available energy flux density . $$ begin{equation} Q_n = R_n - G, end{equation} $$and $E_A$ is the drying power of the air . $$ begin{equation} E_A = 6.43 cdot f(u) cdot text{VPD}. end{equation} $$The constituents of the equations above are . $E$: potential evapotranspiration (mm d$^{-1}$) | $ Delta$: slope of the saturation water vapor pressure curve (kPa °C$^{-1}$) | $ gamma$: psychrometric constant (kPA °C$^{-1}$) | $ lambda$: latent heat of vaporization (MJ kg$^{-1}$) | $R_n$: net radiation (MJ m$^{-2} d^{-1}$) | $G$: heat flux density to the ground (MJ m$^{-2} d^{-1}$) | $f(u)$: wind function (dimensionless) | VPD: vapor pressure deficit (kPa) | . and the number 6.43 adjusts the units of $E_A$ so it is in MJ m$^{-2} d^{-1}$. In what follows, we will further discuss these constituents. . Psychrometric Constant . The psychrometric constant $ gamma$ (kPA °C$^{-1}$) relates the partial pressure of water in air to the air temperature: . $$ begin{equation} gamma = frac{c_p , P}{ lambda cdot MW_ text{ratio}} end{equation} $$$$ begin{equation} P = 101.3-0.01055 H end{equation} $$ . $$ begin{equation} lambda = 2.501 - 2.361 times 10^{-3} ,T end{equation} $$ . $MW_ text{ratio}=0.622$: ratio molecular weight of water vapor/dry air | $P$: atmospheric pressure (kPa). Can be either measured or inferred from station height above sea level (m). | $ lambda$: latent heat of water vaporization (MJ kg$^{-1}$) | $c_p=0.001013$: specific heat capacity of moist air (MJ kg$^{-1}$ °C$^{-1}$) | . Net Radiation . Source: Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, page 99. . $R_n$ (MJ m$^{-2} d^{-1}$) is net radiation, the balance between net short wave $R_s$ and the long wave $R_b$ components of the radiation: . $$R_n = (1- alpha)R_s ! ! downarrow -R_b ! ! uparrow,$$ . where $ alpha$ (dimensionless) is the albedo. The net outgoing thermal radiation $R_b$ is given by . $$R_b = left( a frac{R_s}{R_{so}+b} right)R_{bo},$$ . where $R_{so}$ is the solar radiation on a cloudless day, and it depends on latitude and day of the year. $R_{bo}$ is given by . $$R_{bo} = epsilon , sigma , T^4_{Kelvin},$$ . where $ sigma=4.903 times 10^{-9}$ MJ m$^{-2}$ d$^{-1}$ K$^{-4}$, and $ epsilon$ is net net emissivity: . $$ epsilon=-0.02+0.261 exp left(-7.77 times10^{-4}T_{Celcius}^2 right).$$ . The parameters $a$ and $b$ are determined for the climate of the area: . $a=1.0$, $b=0.0$ for humid areas, | $a=1.2$, $b=-0.2$ for arid areas, | $a=1.1$, $b=-0.1$ for semihumid areas. | . We can find below a table for $R_{so}$, from Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, page 100. . Heat Flux Density to the Ground . The heat flux density to the ground $G$ (MJ m$^{-2} d^{-1}$) can be calculated using . $$ begin{equation} G = 4.2 frac{T_{i+1}-T_{i-1}}{ Delta t}, end{equation} $$where $ Delta t$ is the time in days between midpoints of time periods $i+1$ and $i−1$, and $T$ is the air temperature (°C). This expression is really a finite differences implementation of a time derivative: . $$ displaystyle frac{ text{d}T}{ text{d}t} = lim_{ Delta t rightarrow 0} frac{T(t+ Delta t) - T(t- Delta t)}{2 Delta t}. $$Later on, we will take advantage of numpy&#39;s gradient function to calculate $G$. . Vapor Pressure . from: Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, page 95. . The Vapor Pressure Deficit (VPD, in kPa) is the difference between saturation vapor pressure $e_s$ and actual vapor pressure $e_d$: . $$ text{VPD} = e_s - e_d.$$ . For temperatures ranging from 0 to 50 °C, the saturation vapor pressure can be calculated with . $$ begin{equation} e_s = exp left[ frac{16.78 , T -116.9}{T+237.3} right], end{equation} $$and the actual vapor pressure is given by . $$ begin{equation} e_d = e_s frac{RH}{100}, end{equation} $$where $RH$ is the relative humidity (%), and the temperature $T$ in the equations above is in degrees Celcius. . We can see below a graph of $e_s(T)$ (Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, page 96) . . The factor $ Delta$ is the slope of $e_s(T)$. See the figure below from Brutsaert, where the saturation vapor pressure is called $e^*$ (Brutsaert, &quot;Hydrology: An Introduction&quot;, page 28)): . . There are a few ways of defining the function for $ Delta(T)$ (kPa °C$^{-1}$). Ward &amp; Trimble give the following: . $$ begin{equation} Delta = 0.200 cdot (0.00738 ,T + 0.8072)^7 - 0.000116, end{equation} $$while differentiating the exponential expression given before yields: . $$ begin{equation} Delta = frac{ text{d} e_s}{ text{d}T} = e_s(T) cdot frac{4098.79}{(T+237.3)^2}. end{equation} $$ Wind Function . Source: (Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, page 108) . $$ begin{equation} f(u) = 0.26(1.0 + 0.54 , u_2) end{equation} $$ Meaning of &quot;potential&quot; evapotranspiration . Crop Coefficient . $$ E_{t} = k_c E_{tr, , tp} $$ . $E_{t}=$ actual ET $k_c=$ crop coefficient $E_{tr}=$ reference crop ET $E_{tp}=$ potential ET . . Pitfalls . Different books and papers will present slightly different versions of the Penman equation. Basically, they differ in the units they use for the various components, and one should be vary aware of what inputs any given equation is expecting to get. .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/03/evapotranspiration-lecture.html",
            "relUrl": "/jupyter/2020/02/03/evapotranspiration-lecture.html",
            "date": " • Feb 3, 2020"
        }
        
    
  
    
        ,"post26": {
            "title": "Evapotranspiration - exercises",
            "content": "We will calculate the evapotranspiration using two methods: Thornthwaite and Penman. . Download data from the IMS . Go to the Israel Meteorological Service website, and download the following data: . hourly data on the first page, choose all options and press continue. | on the next page, choose the following date range: 01/01/2020 to 01/01/2021, then press continue. | Choose station Bet Dagan (בית דגן 2523), then select (בחר), then continue. | Choose option &quot;by station&quot; (לפי תחנות), then produce report. | Download report as csv, call it &quot;bet-dagan-3h.csv&quot;. | . | daily data on the first page, choose all options and press continue. | on the next page, choose the following date range: 01/01/2020 to 01/01/2021, then press continue. | Choose station Bet Dagan Meuyeshet (בית דגן מאוישת 2520), then select (בחר), then continue. | Choose option &quot;by station&quot; (לפי תחנות), then produce report. | Download report as csv, call it &quot;bet-dagan-day-pan.csv&quot;. | . | radiation data on the first page, choose all options, then on the bottom right option &quot;radiation&quot; (קרינה), choose kJ/m2, and then press continue. | on the next page, choose the following date range: 01/01/2020 to 01/01/2021, then press continue. | Choose station Bet Dagan Krina (בית דגן קרינה 2524), then select (בחר), then continue. | Choose option &quot;by station&quot; (לפי תחנות), then produce report. | Download report as csv, call it &quot;bet-dagan-radiation.csv&quot;. | . | Import relevant packages . import matplotlib.pyplot as plt import matplotlib import numpy as np import pandas as pd from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() # datetime converter for a matplotlib import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) . . import hourly data . df = pd.read_csv(&#39;bet-dagan-3h.csv&#39;, encoding = &#39;unicode_escape&#39;, na_values=[&quot;-&quot;]) # find out what hebrew gibberish means: http://www.pixiesoft.com/flip/ name_conversion_dictionary = {&quot;ùí úçðä&quot;: &quot;station name&quot;, &quot;îñôø úçðä&quot;: &quot;station number&quot;, &quot;úàøéê&quot;: &quot;Date&quot;, &quot;ùòä-LST&quot;: &quot;LST time&quot;, &quot;èîôøèåøä(C°)&quot;: &quot;T&quot;, &quot;èîôøèåøä ìçä(C°)&quot;: &quot;wet-bulb temperature (°C)&quot;, &quot;èîôøèåøú ð÷åãú äèì(C°)&quot;: &quot;dew_point_T&quot;, &quot;ìçåú éçñéú(%)&quot;: &quot;relative humidity (%)&quot;, &quot;îäéøåú äøåç(m/s)&quot;: &quot;wind_speed&quot;, &quot;ëéååï äøåç(îòìåú)&quot;: &quot;wind direction (degrees)&quot;, &quot;ìçõ áâåáä äúçðä(hPa)&quot;: &quot;Pressure&quot;, &quot;ìçõ áâåáä ôðé äéí(hPa)&quot;: &quot;pressure at sea level (hPa)&quot;, &quot;&quot;&quot;äúàãåú éåîéú îâéâéú ñåâ à&#39;(î&quot;î)&quot;&quot;&quot;: &quot;pan evaporation (mm)&quot;, &quot;ñåâ ÷øéðä()&quot;: &quot;radiation type&quot;, } # units # T = temperature (°C) # dew_point_T = dew point temperature (°C) # wind_speed = wind speed (m/s) # Pressure = pressure at station height (hPa = 0.1 kPa) df = df.rename(columns=name_conversion_dictionary) df[&#39;timestamp&#39;] = df[&#39;Date&#39;] + &#39; &#39; + df[&#39;LST time&#39;] df[&#39;timestamp&#39;] = pd.to_datetime(df[&#39;timestamp&#39;], dayfirst=True) df = df.set_index(&#39;timestamp&#39;) df . . station name station number Date LST time T wet-bulb temperature (°C) dew_point_T relative humidity (%) wind_speed wind direction (degrees) ... pressure at sea level (hPa) ëîåú òððéí ëåììú(÷åã) ëîåú òððéí ðîåëéí(÷åã) âåáä áñéñ òððéí ðîåëéí(÷åã) ñåâ äòððéí äðîåëéí(÷åã) ñåâ äòððéí äáéðåðééí(÷åã) ñåâ äòððéí äâáåäéí(÷åã) îæâ àååéø ðåëçé(÷åã) îæâ àååéø ùçìó(÷åã) øàåú àô÷éú(÷åã) . timestamp . 2020-01-01 02:00:00 áéú ãâï ... | 2523 | 01-01-2020 | 02:00 | 7.9 | 7.2 | 6.4 | 90 | 1.7 | 117.0 | ... | 1018.8 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-01 05:00:00 áéú ãâï ... | 2523 | 01-01-2020 | 05:00 | 7.5 | 7.0 | 6.4 | 93 | 1.2 | 116.0 | ... | 1018.1 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-01 08:00:00 áéú ãâï ... | 2523 | 01-01-2020 | 08:00 | 8.6 | 8.3 | 8.0 | 96 | 1.1 | 107.0 | ... | 1018.2 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-01 11:00:00 áéú ãâï ... | 2523 | 01-01-2020 | 11:00 | 15.9 | 13.1 | 10.6 | 71 | 2.4 | 196.0 | ... | 1017.4 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-01 14:00:00 áéú ãâï ... | 2523 | 01-01-2020 | 14:00 | 18.1 | 14.0 | 10.4 | 61 | 2.8 | 264.0 | ... | 1015.3 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-31 11:00:00 áéú ãâï ... | 2523 | 31-01-2021 | 11:00 | 19.0 | 13.7 | 8.9 | 52 | 5.6 | 235.0 | ... | 1017.3 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2021-01-31 14:00:00 áéú ãâï ... | 2523 | 31-01-2021 | 14:00 | 19.2 | 14.7 | 11.0 | 59 | 4.6 | 252.0 | ... | 1016.7 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2021-01-31 17:00:00 áéú ãâï ... | 2523 | 31-01-2021 | 17:00 | 18.2 | 14.8 | 12.2 | 68 | 0.8 | 203.0 | ... | 1017.0 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2021-01-31 20:00:00 áéú ãâï ... | 2523 | 31-01-2021 | 20:00 | 13.1 | 12.3 | 11.7 | 91 | 1.2 | 79.0 | ... | 1018.2 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2021-01-31 23:00:00 áéú ãâï ... | 2523 | 31-01-2021 | 23:00 | 10.8 | 10.6 | 10.3 | 97 | 1.7 | 111.0 | ... | 1018.9 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3172 rows × 21 columns . import daily data with pan evaporation . df2 = pd.read_csv(&#39;bet-dagan-day-pan.csv&#39;, encoding = &#39;unicode_escape&#39;, na_values=[&quot;-&quot;]) df2 = df2.rename(columns=name_conversion_dictionary) df2[&#39;Date&#39;] = pd.to_datetime(df2[&#39;Date&#39;], dayfirst=True) df2 = df2.set_index(&#39;Date&#39;) df2 . . station name station number èîôøèåøú î÷ñéîåí(C°) èîôøèåøú îéðéîåí(C°) èîôøèåøú îéðéîåí ìéã ä÷ø÷ò(C°) îùê æäéøú ùîù(ã÷åú) pan evaporation (mm) ÷åã äúàãåú éåîéú() . Date . 2020-01-01 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | 0.8 | 0.0 | . 2020-01-02 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-03 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-04 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | NaN | NaN | . 2020-01-05 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | 2.4 | 0.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-27 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | 2.5 | 0.0 | . 2021-01-28 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | 1.2 | 0.0 | . 2021-01-29 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | NaN | NaN | . 2021-01-30 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | NaN | NaN | . 2021-01-31 áéú ãâï îàåéùú ... | 2520 | NaN | NaN | NaN | NaN | 2.6 | 0.0 | . 397 rows × 8 columns . import daily data with radiation . df3 = pd.read_csv(&#39;bet-dagan-radiation.csv&#39;, encoding = &#39;unicode_escape&#39;, na_values=[&quot;-&quot;]) df3 = df3.rename(columns=name_conversion_dictionary) df3[&#39;Date&#39;] = pd.to_datetime(df3[&#39;Date&#39;], dayfirst=True) df3 = df3.set_index(&#39;Date&#39;) df3 = df3.replace({&quot;éùéøä&quot;: &quot;direct&quot;, &quot;îôåæøú&quot;: &quot;diffuse&quot;, &quot;âìåáàìéú&quot;: &quot;global&quot;}) df3[&#39;daily_radiation_MJ_per_m2_per_day&#39;] = df3.iloc[:, 3:].sum(axis=1)/1000 df_radiation = df3.loc[df3[&quot;radiation type&quot;] == &quot;global&quot;, &quot;daily_radiation_MJ_per_m2_per_day&quot;].to_frame() df_radiation . . daily_radiation_MJ_per_m2_per_day . Date . 2020-01-01 10.0296 | . 2020-01-02 4.3128 | . 2020-01-03 11.6748 | . 2020-01-04 1.6452 | . 2020-01-05 6.8544 | . ... ... | . 2021-01-27 12.2652 | . 2021-01-28 7.1640 | . 2021-01-29 7.2936 | . 2021-01-30 9.3276 | . 2021-01-31 13.5468 | . 396 rows × 1 columns . Part 1: Thornthwaite estimation . $$ begin{equation} E = 16 left[ frac{10 ,T^ text{monthly mean}}{I} right]^a, end{equation} $$where $$ begin{equation} I = sum_{i=1}^{12} left[ frac{T_i^ text{monthly mean}}{5} right]^{1.514}, end{equation} $$ and $$ begin{align} a &amp;= 6.75 times 10^{-7}I^3 &amp;- 7.71 times 10^{-5}I^2 nonumber &amp;+ 1.792 times 10^{-2}I nonumber &amp;+ 0.49239 nonumber end{align} $$ . $E$ is the monthly potential ET (mm) | $T_ text{monthly mean}$ is the mean monthly temperature in °C | $I$ is a heat index | $a$ is a location-dependent coefficient | . From df, make a new dataframe, df_th, that stores monthly temperatures means. Use resample function. . # monthly data df_th = (df[&#39;T&#39;].resample(&#39;MS&#39;) # MS assigns mean to first day in the month .mean() .to_frame() ) # we now add 14 days to the index, so that all monthly data is in the middle of the month # not really necessary, makes plot look better df_th.index = df_th.index + pd.DateOffset(days=14) df_th . . T . timestamp . 2020-01-15 12.484274 | . 2020-02-15 14.046983 | . 2020-03-15 16.439113 | . 2020-04-15 18.512500 | . 2020-05-15 23.166532 | . 2020-06-15 24.600000 | . 2020-07-15 27.353226 | . 2020-08-15 28.090323 | . 2020-09-15 28.462500 | . 2020-10-15 25.120161 | . 2020-11-15 19.308475 | . 2020-12-15 15.916129 | . 2021-01-15 14.123790 | . Calculate $I$, then $a$, and finally $E_p$. Add $E_p$ as a new column in df_th. . # Preparing &quot;I&quot; for the Thornthwaite equation I = np.sum( (df_th[&#39;T&#39;]/5)**(1.514) ) # Preparing &quot;a&quot; for the Thornthwaite equation a = (+6.75e-7 * I**3 -7.71e-5 * I**2 +1.792e-2 * I + 0.49239) # The final Thornthwaite model for monthly potential ET (mm) df_th[&#39;Ep&#39;] = 16*((10*df_th[&#39;T&#39;]/I)**a) df_th . . T Ep . timestamp . 2020-01-15 12.484274 | 20.163427 | . 2020-02-15 14.046983 | 27.179636 | . 2020-03-15 16.439113 | 40.472053 | . 2020-04-15 18.512500 | 54.671821 | . 2020-05-15 23.166532 | 96.461219 | . 2020-06-15 24.600000 | 112.296873 | . 2020-07-15 27.353226 | 146.898516 | . 2020-08-15 28.090323 | 157.128632 | . 2020-09-15 28.462500 | 162.453109 | . 2020-10-15 25.120161 | 118.406386 | . 2020-11-15 19.308475 | 60.820862 | . 2020-12-15 15.916129 | 37.291178 | . 2021-01-15 14.123790 | 27.557481 | . Plot the Thornthwaite ET that you calculated. . fig, ax = plt.subplots(1, figsize=(10,7)) ax.plot(df_th[&#39;Ep&#39;]) ax.set(xlabel=&quot;date&quot;, ylabel=r&quot;$E_p$ (mm)&quot;, title=&quot;Thornthwaite potential evapotranspiration&quot;); . . Part 2: Penman . The Penman model is almost entirely a theory based formula for predicting evaporative flux. It can run on a much finer timescale, and requires a much wider variety of data than most models. In addition to temperature, the Penman functions on measurements of radiation, wind speed, elevation above sea level, vapour-pressure deficit, and heat flux density to the ground. . $$ begin{equation} E = frac{1}{ lambda} left[ frac{ Delta}{ Delta+ gamma}Q_{ne}+ frac{ gamma}{ Delta+ gamma}E_A right], end{equation} $$where $Q_n$ is the available energy flux density . $$ begin{equation} Q_n = R_n - G, end{equation} $$and $E_A$ is the drying power of the air . $$ begin{equation} E_A = 6.43 cdot f(u) cdot text{VPD}. end{equation} $$$$ begin{equation} gamma = frac{c_p , P}{ lambda cdot MW_ text{ratio}} end{equation} $$$$ begin{equation} P = 101.3-0.01055 H end{equation} $$ . $$ begin{equation} lambda = 2.501 - 2.361 times 10^{-3} ,T end{equation} $$ . $MW_ text{ratio}=0.622$: ratio molecular weight of water vapor/dry air | $P$: atmospheric pressure (kPa). Can be either measured or inferred from station height above sea level (m). | $ lambda$: latent heat of water vaporization (MJ kg$^{-1}$) | . $$R_n = (1- alpha)R_s ! ! downarrow -R_b ! ! uparrow,$$ . where $ alpha$ (dimensionless) is the albedo. The net outgoing thermal radiation $R_b$ is given by . $$R_b = left( a frac{R_s}{R_{so}+b} right)R_{bo},$$ . where $R_{so}$ is the solar radiation on a cloudless day, and it depends on latitude and day of the year. $R_{bo}$ is given by . $$R_{bo} = epsilon , sigma , T^4_{Kelvin},$$ . where $ sigma=4.903 times 10^{-9}$ MJ m$^{-2}$ d$^{-1}$ K$^{-4}$, and $ epsilon$ is net net emissivity: . $$ epsilon=-0.02+0.261 exp left(-7.77 times10^{-4}T_{Celcius}^2 right).$$ . The parameters $a$ and $b$ are determined for the climate of the area: . $a=1.0$, $b=0.0$ for humid areas, | $a=1.2$, $b=-0.2$ for arid areas, | $a=1.1$, $b=-0.1$ for semihumid areas. . $$ begin{equation} G = 4.2 frac{T_{i+1}-T_{i-1}}{ Delta t} end{equation} $$ . | . $$ text{VPD} = e_s - e_d.$$ . For temperatures ranging from 0 to 50 °C, the saturation vapor pressure can be calculated with . $$ begin{equation} e_s = exp left[ frac{16.78 , T -116.9}{T+237.3} right], end{equation} $$and the actual vapor pressure is given by . $$ begin{equation} e_d = e_s frac{RH}{100}, end{equation} $$$$ begin{equation} Delta = frac{ text{d} e_s}{ text{d}T} = e_s(T) cdot frac{4098.79}{(T+237.3)^2}. end{equation} $$$$ begin{equation} f(u) = 0.26(1.0 + 0.54 , u_2) end{equation} $$The various components of the equations above are: . $$ begin{equation} Delta = 0.200 cdot (0.00738 ,T + 0.8072)^7 - 0.000116 end{equation} $$ . $$ begin{equation} gamma = frac{c_p , P}{0.622 lambda} end{equation} $$ . $$ begin{equation} P = 101.3-0.01055 H end{equation} $$ . $$ begin{equation} lambda = 2.501 - 2.361 times 10^{-3} ,T end{equation} $$ . $$ begin{equation} f_e(u) = 1.0 + 0.53 , u_2 end{equation} $$ . $$ begin{equation} G = 4.2 frac{T_{i+1}-T_{i-1}}{ Delta t} end{equation} $$ . $$ begin{equation} e_s = exp left[ frac{16.78 , T -116.9}{T+237.3} right] end{equation} $$ . $$ begin{equation} e_d = e_s frac{RH}{100} end{equation} $$ where $ Delta t$ is the time in days between midpoints of time periods $i+1$ and $i−1$, and $T$ is the air temperature (°C). . $ Delta$: slope of the saturation water vapor pressure curve (kPa °C$^{-1}$) | $ gamma$: psychrometric constant (kPA °C$^{-1}$) | $c_p=0.001013$: specific heat of water at constant pressure (MJ kg$^{-1}$ °C$^{-1}$) | $P$: atmospheric pressure (kPa) | $H$: elevation above sea level (m) | $ lambda$: latent heat of vaporization (MJ kg$^{-1}$) | $R_n$: net radiation (MJ m$^{-2} d^{-1}$) | $G$: heat flux density to the ground (MJ m$^{-2} d^{-1}$) | $u_{2}$: wind speed measured 2 m above ground (m s$^{-1}$) | $e_{s} - e_{d}$: vapor pressure deficit (kPa) | $e_{s}$: saturation vapor pressure (kPa) | $e_{d}$: actual vapor pressure (kPa) | . Calculate daily means for the following columns: temperature T, wind speed wind_speed, atmospheric pressure Pressure, and relative humidity relative humidity (%). Remember that pressure data was given in hectopascal, 1 hPa = 0.1 kPa. Store all the calculated values in a new dataframe, called df_pen. . # Resampling hourly data over same day and taking mean, to obtain daily averages df_pen = (df[&#39;T&#39;].resample(&#39;D&#39;) .mean() .to_frame() ) df_pen[&#39;dew_point&#39;] = (df[&#39;dew_point_T&#39;].resample(&#39;D&#39;) .mean() ) df_pen[&#39;u&#39;] = (df[&#39;wind_speed&#39;].resample(&#39;D&#39;) .mean() ) df_pen[&#39;P&#39;] = (df[&#39;Pressure&#39;].resample(&#39;D&#39;) .mean() )/10 df_pen[&#39;RH&#39;] = (df[&#39;relative humidity (%)&#39;].resample(&#39;D&#39;) .mean() ) df_pen . . T dew_point u P RH . timestamp . 2020-01-01 12.3625 | 9.0625 | 1.5250 | 101.30875 | 81.500 | . 2020-01-02 11.9750 | 9.8250 | 1.9250 | 101.20125 | 87.000 | . 2020-01-03 13.0500 | 4.9750 | 5.1750 | 101.37125 | 58.500 | . 2020-01-04 10.8625 | 6.6875 | 5.5625 | 101.15500 | 78.375 | . 2020-01-05 12.9375 | 9.2125 | 4.5625 | 101.23625 | 79.125 | . ... ... | ... | ... | ... | ... | . 2021-01-27 13.8125 | 8.2375 | 1.8875 | 100.83750 | 72.375 | . 2021-01-28 14.4000 | 10.2250 | 3.5250 | 101.12750 | 76.750 | . 2021-01-29 12.3500 | 7.9125 | 5.0250 | 101.22125 | 75.250 | . 2021-01-30 12.9625 | 7.6500 | 4.4250 | 101.49500 | 71.375 | . 2021-01-31 15.0625 | 8.3125 | 3.7500 | 101.32500 | 66.000 | . 397 rows × 5 columns . With average $T$ for every day of the year, we can now calculate daily latent heat of vaporization $ lambda$, the slope of the saturation-vapor pressure-temperature curve $ Delta$, and the heat flux density to the ground $G$. Add each of these to dataframe df_pen. . Calculate also the wind function using the data for wind speed, and add this to df_pen. . def lambda_latent_heat(T): &quot;&quot;&quot;daily latent heat of vaporization (MJ/kg)&quot;&quot;&quot; return 2.501 - 2.361e-3*T def Delta(T): &quot;&quot;&quot;slope of saturation-vapor curve (kPa/°C)&quot;&quot;&quot; return 0.2000*(0.00738*T + 0.8072)**7 - 0.000116 def G(T): &quot;&quot;&quot;heat flux density to the ground, G (MJ/m2/d)&quot;&quot;&quot; return 4.2*np.gradient(T.values) cp = 0.001013 # (MJ kg−1 °C−1) df_pen[&#39;lambda&#39;] = lambda_latent_heat(df_pen[&#39;T&#39;]) df_pen[&#39;Delta&#39;] = Delta(df_pen[&#39;T&#39;]) df_pen[&#39;G&#39;] = G(df_pen[&#39;T&#39;]) df_pen[&#39;gamma&#39;] = (cp*df_pen[&#39;P&#39;])/(0.622*df_pen[&#39;lambda&#39;]) df_pen[&#39;f_wind&#39;] = 1.0 + 0.53 * df_pen[&#39;u&#39;] df_pen . . T dew_point u P RH lambda Delta G gamma f_wind . timestamp . 2020-01-01 12.3625 | 9.0625 | 1.5250 | 101.30875 | 81.500 | 2.471812 | 0.094385 | -1.62750 | 0.066750 | 1.808250 | . 2020-01-02 11.9750 | 9.8250 | 1.9250 | 101.20125 | 87.000 | 2.472727 | 0.092300 | 1.44375 | 0.066654 | 2.020250 | . 2020-01-03 13.0500 | 4.9750 | 5.1750 | 101.37125 | 58.500 | 2.470189 | 0.098185 | -2.33625 | 0.066835 | 3.742750 | . 2020-01-04 10.8625 | 6.6875 | 5.5625 | 101.15500 | 78.375 | 2.475354 | 0.086530 | -0.23625 | 0.066553 | 3.948125 | . 2020-01-05 12.9375 | 9.2125 | 4.5625 | 101.23625 | 79.125 | 2.470455 | 0.097554 | 4.25250 | 0.066739 | 3.418125 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-27 13.8125 | 8.2375 | 1.8875 | 100.83750 | 72.375 | 2.468389 | 0.102551 | 4.77750 | 0.066532 | 2.000375 | . 2021-01-28 14.4000 | 10.2250 | 3.5250 | 101.12750 | 76.750 | 2.467002 | 0.106028 | -3.07125 | 0.066760 | 2.868250 | . 2021-01-29 12.3500 | 7.9125 | 5.0250 | 101.22125 | 75.250 | 2.471842 | 0.094317 | -3.01875 | 0.066691 | 3.663250 | . 2021-01-30 12.9625 | 7.6500 | 4.4250 | 101.49500 | 71.375 | 2.470396 | 0.097694 | 5.69625 | 0.066911 | 3.345250 | . 2021-01-31 15.0625 | 8.3125 | 3.7500 | 101.32500 | 66.000 | 2.465437 | 0.110070 | 8.82000 | 0.066933 | 2.987500 | . 397 rows × 10 columns . It&#39;s time to calculate net radiation $R_n$. The monthly mean solar radiation $R_{so}$ for latitude 30 degrees is [17.46, 21.65, 25.96, 29.85, 32.11, 33.20, 32.66, 30.44, 26.67, 22.48, 18.30, 16.04] (MJ m$^{-2}$ d$^{-1}$) (Israel&#39;s latitude is ~ 31 degrees). . Add a new column Rso_monthly to df_pen, where each day has the appropriate $R_{so}$ given by the data above. | Add a new columns Rs with the global radiation data imported in the 3rd file. | . # Rso: mean solar radiation from a cloudless sky (based on latitude) # MJ/m2/d Rso_monthly = np.array([17.46, 21.65, 25.96, 29.85, 32.11, 33.20, 32.66, 30.44, 26.67, 22.48, 18.30, 16.04]) # create empty columns df_pen[&quot;Rso_monthly&quot;] = &quot;&quot; # every day in the month will have the same values for Rso for i in range(12): df_pen.loc[df_pen.index.month==(i+1), &quot;Rso_monthly&quot;] = Rso_monthly[i] df_pen[&quot;Rs&quot;] = df_radiation[&quot;daily_radiation_MJ_per_m2_per_day&quot;] fig, ax = plt.subplots(1, figsize=(10,7)) ax.plot(df_pen[&#39;Rso_monthly&#39;]) plt.gcf().autofmt_xdate() ax.set_ylabel(r&quot;$R_{so}$ (MJ m$^{-2} d^{-1}$)&quot;) . . Text(0, 0.5, &#39;$R_{so}$ (MJ m$^{-2} d^{-1}$)&#39;) . middle = pd.date_range(start=&#39;1/1/2020&#39;, periods=13, freq=&#39;MS&#39;) + pd.DateOffset(days=14) new = df_pen.loc[middle, &#39;Rso_monthly&#39;].astype(&#39;float&#39;) new df_i = (pd.DataFrame(data=new, index=new.index) #create the dataframe .resample(&quot;D&quot;) #resample daily .interpolate(method=&#39;time&#39;) #interpolate by time ) fig, ax = plt.subplots(1, figsize=(10,7)) ax.plot(df_i, &#39;o&#39;) ax.plot(df_pen[&#39;Rso_monthly&#39;]) plt.gcf().autofmt_xdate() ax.set_title(&quot;time interpolation&quot;) ax.set_ylabel(r&quot;$R_{so}$ (MJ m$^{-2} d^{-1}$)&quot;) . . Text(0, 0.5, &#39;$R_{so}$ (MJ m$^{-2} d^{-1}$)&#39;) . from: Ward &amp; Trimble, &quot;Environmental Hydrology&quot;, 2nd Edition, page 99. . Calculate $$R_{bo} = epsilon , sigma , T^4_{Kelvin},$$ where $$ epsilon=-0.02+0.261 exp left(-7.77 times10^{-4}T_{Celcius}^2 right),$$ $$ sigma=4.903 times 10^{-9} text{ MJ m$^{-2}$ d$^{-1}$ K$^{-4}$},$$ and $$T_{Kelvin}=T_{Celcius}+273.15$$ | Calculate $$R_b = left( a frac{R_s}{R_{so}+b} right)R_{bo},$$ where for humid areas, $a=1.0$ and $b=0$, | for arid areas, $a=1.2$ and $b=-0.2$, | for semihumid areas, $a=1.1$ and $b=-0.1$ | . | Finally, calculate $$R_n = (1- alpha)R_s ! ! downarrow -R_b ! ! uparrow,$$ where $ alpha= 0.23$ for most green crops with a full cover | $ alpha= 0.04$ for fresh asphalt | $ alpha= 0.12$ for worn-out asphalt | $ alpha= 0.55$ for fresh concrete | . | . Add a new column Rn to df_pen dataframe. . # Stefan-Boltzmann constant sigma = 4.903e-9 emissivity = -0.02 + 0.261 * np.exp(-7.77e-4 * df_pen[&#39;T&#39;]**2) # Rbo: net longwave radiation for clear skies, otherwise known as diffuse radiation or emitted radiation from the # atmosphere - &#39;how hot is it?&#39; Rbo = emissivity*sigma*((df_pen[&#39;T&#39;]+273.15)**4) # net outgoing long-wave radiation (note: Rs/Rso = proportion of how clear the day is) # for humid areas, a=1.0 and b=0 # for arid areas, a=1.2 and b=-0.2 # for semihumid areas, a=1.1 and b=-0.1 a = 1.2 b = -0.2 Rb = (a*df_pen[&#39;Rs&#39;]/df_pen[&#39;Rso_monthly&#39;] + b)*Rbo # α is the albedo, or short-wave reflectance (dimensionless) alpha = 0.23 # net radiation Rn = (1 - alpha) * df_pen[&#39;Rs&#39;] - Rb # (MJ/m2/d) df_pen[&#39;Rn&#39;] = Rn df_pen . . T dew_point u P RH lambda Delta G gamma f_wind Rso_monthly Rs Rn . timestamp . 2020-01-01 12.3625 | 9.0625 | 1.5250 | 101.30875 | 81.500 | 2.471812 | 0.094385 | -1.62750 | 0.066750 | 1.808250 | 17.46 | 10.0296 | 4.346568 | . 2020-01-02 11.9750 | 9.8250 | 1.9250 | 101.20125 | 87.000 | 2.472727 | 0.092300 | 1.44375 | 0.066654 | 2.020250 | 17.46 | 4.3128 | 2.653905 | . 2020-01-03 13.0500 | 4.9750 | 5.1750 | 101.37125 | 58.500 | 2.470189 | 0.098185 | -2.33625 | 0.066835 | 3.742750 | 17.46 | 11.6748 | 4.854942 | . 2020-01-04 10.8625 | 6.6875 | 5.5625 | 101.15500 | 78.375 | 2.475354 | 0.086530 | -0.23625 | 0.066553 | 3.948125 | 17.46 | 1.6452 | 1.871722 | . 2020-01-05 12.9375 | 9.2125 | 4.5625 | 101.23625 | 79.125 | 2.470455 | 0.097554 | 4.25250 | 0.066739 | 3.418125 | 17.46 | 6.8544 | 3.415474 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-27 13.8125 | 8.2375 | 1.8875 | 100.83750 | 72.375 | 2.468389 | 0.102551 | 4.77750 | 0.066532 | 2.000375 | 17.46 | 12.2652 | 5.060995 | . 2021-01-28 14.4000 | 10.2250 | 3.5250 | 101.12750 | 76.750 | 2.467002 | 0.106028 | -3.07125 | 0.066760 | 2.868250 | 17.46 | 7.1640 | 3.534995 | . 2021-01-29 12.3500 | 7.9125 | 5.0250 | 101.22125 | 75.250 | 2.471842 | 0.094317 | -3.01875 | 0.066691 | 3.663250 | 17.46 | 7.2936 | 3.537119 | . 2021-01-30 12.9625 | 7.6500 | 4.4250 | 101.49500 | 71.375 | 2.470396 | 0.097694 | 5.69625 | 0.066911 | 3.345250 | 17.46 | 9.3276 | 4.152687 | . 2021-01-31 15.0625 | 8.3125 | 3.7500 | 101.32500 | 66.000 | 2.465437 | 0.110070 | 8.82000 | 0.066933 | 2.987500 | 17.46 | 13.5468 | 5.513874 | . 397 rows × 13 columns . Calculate the vapor pressure deficit, VPD, add a new column to df_pen. . $$e_d = e_s cdot frac{RH}{100}$$ . $$e_s = exp left( frac{16.78 ,T-116.9}{T+237.3} right)$$ . # vapor pressure deficit = VPD def vp_sat(T): return np.exp((16.78*T - 116.9)/(T + 237.3)) df_pen[&#39;es&#39;] = vp_sat(df_pen[&#39;T&#39;]) df_pen[&#39;ed&#39;] = df_pen[&#39;es&#39;] * df_pen[&#39;RH&#39;] / 100 df_pen[&#39;VPD&#39;] = df_pen[&#39;es&#39;] - df_pen[&#39;ed&#39;] df_pen . . T dew_point u P RH lambda Delta G gamma f_wind Rso_monthly Rs Rn es ed VPD . timestamp . 2020-01-01 12.3625 | 9.0625 | 1.5250 | 101.30875 | 81.500 | 2.471812 | 0.094385 | -1.62750 | 0.066750 | 1.808250 | 17.46 | 10.0296 | 4.346568 | 1.437148 | 1.171276 | 0.265872 | . 2020-01-02 11.9750 | 9.8250 | 1.9250 | 101.20125 | 87.000 | 2.472727 | 0.092300 | 1.44375 | 0.066654 | 2.020250 | 17.46 | 4.3128 | 2.653905 | 1.400935 | 1.218813 | 0.182122 | . 2020-01-03 13.0500 | 4.9750 | 5.1750 | 101.37125 | 58.500 | 2.470189 | 0.098185 | -2.33625 | 0.066835 | 3.742750 | 17.46 | 11.6748 | 4.854942 | 1.503424 | 0.879503 | 0.623921 | . 2020-01-04 10.8625 | 6.6875 | 5.5625 | 101.15500 | 78.375 | 2.475354 | 0.086530 | -0.23625 | 0.066553 | 3.948125 | 17.46 | 1.6452 | 1.871722 | 1.301383 | 1.019959 | 0.281424 | . 2020-01-05 12.9375 | 9.2125 | 4.5625 | 101.23625 | 79.125 | 2.470455 | 0.097554 | 4.25250 | 0.066739 | 3.418125 | 17.46 | 6.8544 | 3.415474 | 1.492399 | 1.180860 | 0.311538 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-01-27 13.8125 | 8.2375 | 1.8875 | 100.83750 | 72.375 | 2.468389 | 0.102551 | 4.77750 | 0.066532 | 2.000375 | 17.46 | 12.2652 | 5.060995 | 1.580054 | 1.143564 | 0.436490 | . 2021-01-28 14.4000 | 10.2250 | 3.5250 | 101.12750 | 76.750 | 2.467002 | 0.106028 | -3.07125 | 0.066760 | 2.868250 | 17.46 | 7.1640 | 3.534995 | 1.641414 | 1.259785 | 0.381629 | . 2021-01-29 12.3500 | 7.9125 | 5.0250 | 101.22125 | 75.250 | 2.471842 | 0.094317 | -3.01875 | 0.066691 | 3.663250 | 17.46 | 7.2936 | 3.537119 | 1.435967 | 1.080565 | 0.355402 | . 2021-01-30 12.9625 | 7.6500 | 4.4250 | 101.49500 | 71.375 | 2.470396 | 0.097694 | 5.69625 | 0.066911 | 3.345250 | 17.46 | 9.3276 | 4.152687 | 1.494843 | 1.066944 | 0.427899 | . 2021-01-31 15.0625 | 8.3125 | 3.7500 | 101.32500 | 66.000 | 2.465437 | 0.110070 | 8.82000 | 0.066933 | 2.987500 | 17.46 | 13.5468 | 5.513874 | 1.713106 | 1.130650 | 0.582456 | . 397 rows × 16 columns . Now that all variables have been defined, daily E_penman can be calculated. . $$ begin{equation} E_{tp} = frac{ Delta}{ Delta+ gamma}Q_{ne}+ frac{ gamma}{ Delta+ gamma}E_A end{equation} $$$Q_n$ is the available energy flux density: . $$ begin{equation} Q_n = R_n - G, end{equation} $$and $E_A$ is the drying power of the air: . $$ begin{equation} E_A = f_e(u) cdot text{VPD} end{equation} $$Add a new column E_penman to df_pen. . def E_penman(df): T = df[&#39;T&#39;] Delta = df[&#39;Delta&#39;] gamma = df[&#39;gamma&#39;] Rn = df[&#39;Rn&#39;] G = df[&#39;G&#39;] EA = 6.43*df[&#39;f_wind&#39;] * df[&#39;VPD&#39;] lambd = df[&#39;lambda&#39;] return ((Delta / (Delta + gamma))*(Rn - G) + ((gamma / (Delta + gamma))*EA)) / lambd # daily_data df_pen[&#39;E_penman&#39;] = E_penman(df_pen) fig, ax = plt.subplots(1, figsize=(10,7)) ax.plot(df_pen[&#39;E_penman&#39;]) plt.gcf().autofmt_xdate() ax.set_ylabel(r&quot;$ET_{penman}$ (mm d$^{-1}$)&quot;) . . Text(0, 0.5, &#39;$ET_{penman}$ (mm d$^{-1}$)&#39;) . Make a plot with the following: . the Penman (daily) estimate of the potential evapotranspiration. | the Thornthwaite (monthly) estimate of the potential ET. | daily evaporation pan data. | fig, ax = plt.subplots(1, 1, figsize=(10,7)) ax.plot(df_pen[&#39;E_penman&#39;], color=&quot;tab:red&quot;, label=&quot;Penman&quot;, linewidth=2) ax.plot(df_th[&#39;Ep&#39;]/30, color=&quot;tab:blue&quot;, label=&quot;Thornthwaite&quot;, linewidth=2) ax.plot(1*df2[&#39;pan evaporation (mm)&#39;], color=&quot;black&quot;, label=&quot;pan&quot;, linewidth=2) ax.set(xlabel=&quot;date&quot;, ylabel=&quot;evaporation (mm)&quot;) ax.legend(); . . Plot the mean temperatures used in the Penman calculation (daily mean) and in the Thornthwaite calculation (monthly mean). . fig, ax = plt.subplots(1, 1, figsize=(10,7)) ax.plot(df_pen[&#39;T&#39;], color=&quot;tab:blue&quot;, label=&quot;Penman&quot;, linewidth=2) ax.plot(df_th[&#39;T&#39;], color=&quot;tab:orange&quot;, label=&quot;Thornthwaite&quot;, linewidth=2) ax.set(xlabel=&quot;date&quot;, ylabel=&quot;temperature (°C)&quot;) ax.legend(); . .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/03/evapotranspiration-exercises.html",
            "relUrl": "/jupyter/2020/02/03/evapotranspiration-exercises.html",
            "date": " • Feb 3, 2020"
        }
        
    
  
    
        ,"post27": {
            "title": "Assignment 2 - Evapotranspiration",
            "content": "&#128210; instructions . This is where learning happens, not during a lecture. You&#39;ll learn a ton of things by doing them yourself. Much success! 😄 . Create a Jupyter Notebook called assignment-02-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check. . &#128204; locations and data . Choose two stations with different climates. . Go to NOAA&#39;s Climate Reference Network Data website. The sub-hourly (5-min) data contains information on . air temperature, | precipitation, | global solar radiation, | surface infrared temperature, | relative humidity, | soil moisture and temperature, | wetness, and | 1.5 meter wind speed. | . There is no data on air pressure, so one needs to use the stations coordinates (lat, lon) to find its height above sea level, and from that infer the air pressure. You can use Google Earth or any other means to find the station&#39;s height. . In the Data Access link, choose a year and a station you would like to analyze. If you are not sure where the stations are, find them using the 2-letter state abbreviation and the station name. . Download the following files: . One full year of data for each station. Make sure important data we need to calculate Penman&#39;s ET estimation is available. | The headers file | The documentation file | Make sure you understand what are the units provided for each measurement (see documentation). . &#128736; tasks . Produce potential ET estimates using Thornthwaite&#39;s equation and Penman&#39;s equation. Produce plots of ET as a function of time for each station, comparing the two methods you used. Also, using Penman&#39;s ET estimates, compare the two stations and discuss about their differences/similarities. . You might find interesting things in the data, such as periods of unusually high/low temperatures, radiation, etc. Discuss how these factors might have affected the ET estimates that you calculated. . You will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, I&#39;m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Don&#39;t forget to put labels on your plot axes, title, legend, etc. . Your Jupyter Notebook should be fully functional: if we press Kernel &gt; Restart &amp; Run All, all the code must work without any errors. . &#127749; presentation . All the assignment must be in one single Jupyter Notebook. Use markdown cells to discuss the analysis and results, and in code cells show all the code you used to produce the figures and data analysis. Leave only the code necessary for your analysis, delete unnecessary lines your wrote while analyzing your data. Don&#39;t forget to comment your code, just like we did during exercise sessions. . You can write in English or in Hebrew, but the text in the figures must be in English. If you choose to write the discussion in Hebrew, be aware that Jupyter Notebooks don&#39;t have native right-to-left language support: . ניתן לכתוב בעברית, למרות שזה לא נראה כ״כ טוב... . You can use some HTML code to achieve best results in Hebrew. Type the following . &lt;p dir=&quot;rtl&quot; style=&quot;text-align: right;&quot;&gt; עכשיו הרבה יותר טוב! &lt;/p&gt; . to get . עכשיו הרבה יותר טוב! . If you have many paragraphs in hebrew, do the following: . פסקה מספר 1. . פסקה מספר 2. . אם יש לכם כמה פסקאות, כל אחת מהן תהיה בתוך &quot;dir&quot; משלה . In my opinion it is too complicated to write in Hebrew in Jupyter Notebooks, just write in English, your grade will not be affected by typos nor less-than-perfect English proficiency. . &#128175; evaluation . Your assignment will be evaluated according to the following criteria: . 40% Presentation. How the graphs look, labels, general organization, markdown, clean code. | 30% Discussion. This is where you explain what you did, what you found out, etc. | 15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration. | 10% Replicability: Your code runs flawlessly. | 5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself! | . &#128666; importing the data . Below you can find an example of how to import the data file provided by NOAA&#39;s Climate Reference Network Data website. You might have to make some adjustments to it. . data_file = &quot;CRNS0101-05-2020-CO_Boulder_14_W.txt&quot; df = pd.read_csv(data_file, header=None, # no headers needed, we&#39;ll do that later delim_whitespace=True, # blank spaces separate between columns na_values=[&quot;-99.000&quot;, &quot;-9999.0&quot;] # substitute these values for missing (NaN) values ) headers = pd.read_csv(&quot;HEADERS_sub_hourly.txt&quot;, # load headers file header=1, # skip the first [0] line delim_whitespace=True ) df.columns = headers.columns # rename df columns with headers columns # LST = local standard time df[&quot;LST_TIME&quot;] = [f&quot;{x:04d}&quot; for x in df[&quot;LST_TIME&quot;]] # time needs padding of zeros, then convert to string df[&#39;LST_DATE&#39;] = df[&#39;LST_DATE&#39;].astype(str) # convert date into string df[&#39;datetime&#39;] = df[&#39;LST_DATE&#39;] + &#39; &#39; + df[&#39;LST_TIME&#39;] # combine date+time into datetime df[&#39;datetime&#39;] = pd.to_datetime(df[&#39;datetime&#39;]) # interpret datetime df = df.set_index(&#39;datetime&#39;) # make datetime the index df .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/03/assignment-02-ET.html",
            "relUrl": "/jupyter/2020/02/03/assignment-02-ET.html",
            "date": " • Feb 3, 2020"
        }
        
    
  
    
        ,"post28": {
            "title": "Exercises, inter- and intra-annual variability of precipitation",
            "content": "Import relevant packages . import matplotlib.pyplot as plt import numpy as np import pandas as pd from calendar import month_abbr import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) import urllib.request . . intra-annual variability . Go to NOAA&#39;s National Centers for Environmental Information (NCEI) Climate Data Online: Dataset Discovery . Find station codes in this map. On the left, click on the little wrench next to &quot;Global Summary of the Month&quot;, then click on &quot;identify&quot; on the panel that just opened, and click on a station (purple circle). You will see the station&#39;s name, it&#39;s ID, and the period of record. For example, for Ben-Gurion&#39;s Airport in Israel: BEN GURION, IS STATION ID: ISM00040180 Period of Record: 1951-01-01 to 2020-03-01 . You can download daily or monthly data for each station. Use the function below to download this data to your computer. . def download_data(station_name, station_code): url_daily = &#39;https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/&#39; url_monthly = &#39;https://www.ncei.noaa.gov/data/gsom/access/&#39; # download daily data - uncomment the next 2 lines to make this work # urllib.request.urlretrieve(url_daily + station_code + &#39;.csv&#39;, # station_name + &#39;_daily.csv&#39;) # download monthly data urllib.request.urlretrieve(url_monthly + station_code + &#39;.csv&#39;, station_name + &#39;_monthly.csv&#39;) . . Now, choose any station with a period of record longer than 30 years, and download its data: . download_data(&#39;BEN_GURION&#39;, &#39;ISM00040180&#39;) . Load the data into a datafram, and before you continue with the analysis, plot the rainfall data, to see how it looks like. . download_data(&#39;BEN_GURION&#39;, &#39;ISM00040180&#39;) df = pd.read_csv(&#39;BEN_GURION_monthly.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) plt.plot(df[&#39;PRCP&#39;]) . . [&lt;matplotlib.lines.Line2D at 0x7fb600c72150&gt;] . It doesn&#39;t look great for Ben-Gurion airport, lots of missing data! You might need to choose another station... Download data for Beer Sheva, ID IS000051690. . download_data(&#39;BEER_SHEVA&#39;, &#39;IS000051690&#39;) df = pd.read_csv(&#39;BEER_SHEVA_monthly.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) plt.plot(df[&#39;PRCP&#39;]) . . [&lt;matplotlib.lines.Line2D at 0x7fb6404ce150&gt;] . That&#39;s much better! We need to aggregate all data from each month, so we can calculate monthly averages. How to do that? . # choose only the precipitation column df_month = df[&#39;PRCP&#39;] # calculate monthly mean monthly_mean = np.array([]) # empty array month_numbers = np.arange(1,13) month_names = [month_abbr[i] for i in month_numbers] for m in month_numbers: # cycle over months (1, 2, 3, etc) this_month_all_indices = (df_month.index.month == m) # indices in df_month belonging to month m this_month_mean = df_month[this_month_all_indices].mean() # this is the monthly mean monthly_mean = np.append(monthly_mean, this_month_mean) # append . . Now it is time to create a new dataframe with the monthly means. . df_beersheva = pd.DataFrame({&#39;monthly rainfall (mm)&#39;:monthly_mean, &#39;month names&#39;:month_names, &#39;month number&#39;:month_numbers }) df_beersheva . . monthly rainfall (mm) month names month number . 0 48.743158 | Jan | 1 | . 1 37.347368 | Feb | 2 | . 2 26.551579 | Mar | 3 | . 3 9.038947 | Apr | 4 | . 4 2.735789 | May | 5 | . 5 0.013830 | Jun | 6 | . 6 0.000000 | Jul | 7 | . 7 0.002128 | Aug | 8 | . 8 0.271277 | Sep | 9 | . 9 6.669474 | Oct | 10 | . 10 21.850526 | Nov | 11 | . 11 41.786316 | Dec | 12 | . Plot the data and see if it makes sense. Try to get a figure like this one. . fig, ax = plt.subplots(figsize=(10,7)) ax.bar(df_beersheva[&#39;month number&#39;], df_beersheva[&#39;monthly rainfall (mm)&#39;]) ax.set(xlabel=&quot;months&quot;, ylabel=&quot;monthly average (mm)&quot;, title=&quot;Beer Sheva&quot;, xticks=df_beersheva[&#39;month number&#39;], xticklabels=df_beersheva[&#39;month names&#39;]); plt.savefig(&quot;hydrology_figures/beersheva_monthly_average.png&quot;) . . Let&#39;s calculate now the Walsh and Lawler Seasonality Index. Write a function that receives a dataframe like the one we have just created, and returns the seasonality index. http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability . $R=$ mean annual precipitation $m_i$ precipitation mean for month $i$ . $$ SI = displaystyle frac{1}{R} sum_{n=1}^{n=12} left| m_i - frac{R}{12} right| $$ . SI Precipitation Regime . &lt;0.19 | Precipitation spread throughout the year | . 0.20-0.39 | Precipitation spread throughout the year, but with a definite wetter season | . 0.40-0.59 | Rather seasonal with a short dry season | . 0.60-0.79 | Seasonal | . 0.80-0.99 | Marked seasonal with a long dry season | . 1.00-1.19 | Most precipitation in &lt; 3 months | . def walsh_index(df): mi = df[&quot;monthly rainfall (mm)&quot;] R = df[&quot;monthly rainfall (mm)&quot;].sum() SI = np.sum(np.abs(mi - R/12)) / R return SI beersheva_SI = walsh_index(df_beersheva) print(f&quot;Beer Sheva, SI = {beersheva_SI:.2f}&quot;) . . Beer Sheva, SI = 0.97 . interannual variability . Plot monthly rainfall for your station. . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7)) ax1.plot(df[&#39;PRCP&#39;]) ax2.plot(df[&#39;PRCP&#39;][&#39;2010-07-01&#39;:&#39;2015-07-01&#39;]) . . [&lt;matplotlib.lines.Line2D at 0x7fb620dd45d0&gt;] . How to aggregate rainfall accoding to the hydrological year? We use the function resample. . read more about resampling options: https://pandas.pydata.org/pandas-docs/version/0.12.0/timeseries.html#offset-aliases . also, annual resampling can be anchored to the end of specific months: https://pandas.pydata.org/pandas-docs/version/0.12.0/timeseries.html#anchored-offsets . # annual frequency, anchored 31 December df_year_all = df[&#39;PRCP&#39;].resample(&#39;A&#39;).sum().to_frame() # annual frequency, anchored 01 January df_year_all = df[&#39;PRCP&#39;].resample(&#39;AS&#39;).sum().to_frame() # annual frequency, anchored end of September df_year_all = df[&#39;PRCP&#39;].resample(&#39;A-SEP&#39;).sum().to_frame() # rename &#39;PRCP&#39; column to &#39;rain (mm)&#39; df_year_all.columns = [&#39;rain (mm)&#39;] df_year_all . . rain (mm) . DATE . 1922-09-30 136.6 | . 1923-09-30 144.5 | . 1924-09-30 130.4 | . 1925-09-30 165.3 | . 1926-09-30 188.7 | . ... ... | . 2012-09-30 145.7 | . 2013-09-30 175.3 | . 2014-09-30 259.2 | . 2015-09-30 249.3 | . 2016-09-30 257.6 | . 95 rows × 1 columns . You might need to exclude the first or the last line, since their data might have less that 12 months. For example: . # exclude 1st row df_year = df_year_all.iloc[1:] # exclude last row df_year = df_year_all.iloc[:-1] # exclude both 1st and last rows df_year = df_year_all.iloc[1:-1] df_year . . rain (mm) . DATE . 1923-09-30 144.5 | . 1924-09-30 130.4 | . 1925-09-30 165.3 | . 1926-09-30 188.7 | . 1927-09-30 130.2 | . ... ... | . 2011-09-30 151.6 | . 2012-09-30 145.7 | . 2013-09-30 175.3 | . 2014-09-30 259.2 | . 2015-09-30 249.3 | . 93 rows × 1 columns . Calculate the average annual rainfall. Plot annual rainfall for the whole range, together with the average. You should get something like this: . fig, ax = plt.subplots(figsize=(10,7)) # plot YEARLY precipitation ax.bar(df_year.index, df_year[&#39;rain (mm)&#39;], width=365, align=&#39;edge&#39;, color=&quot;tab:blue&quot;) # plot mean rain_mean = df_year[&#39;rain (mm)&#39;].mean() ax.plot(ax.get_xlim(), [rain_mean]*2, linewidth=3, color=&quot;tab:orange&quot;) ax.set(xlabel=&quot;date&quot;, ylabel=&quot;yearly rainfall (mm)&quot;, title=f&quot;Beer Sheva, mean = {rain_mean:.0f} mm&quot;); # save figure plt.savefig(&quot;hydrology_figures/beersheva_yearly_rainfall_1923_2016.png&quot;) . . Plot a histogram of annual rainfall, with the mean and standard deviation. Calculate the coefficient of variation. Try to plot something like this: . fig, ax = plt.subplots(figsize=(10,7)) # calculate mean and standard deviation rain_mean = df_year[&#39;rain (mm)&#39;].mean() rain_std = df_year[&#39;rain (mm)&#39;].std() # plot histogram b = np.arange(0, 401, 50) # bins from 0 to 400, width = 50 ax.hist(df_year[&#39;rain (mm)&#39;], bins=b) # plot vertical lines with mean, std, etc ylim = np.array(ax.get_ylim()) ylim[1] = ylim[1]*1.1 ax.plot([rain_mean]*2, ylim, linewidth=3, color=&quot;tab:orange&quot;) ax.plot([rain_mean+rain_std]*2, ylim, linewidth=3, linestyle=&quot;--&quot;, color=&quot;tab:olive&quot;) ax.plot([rain_mean-rain_std]*2, ylim, linewidth=3, linestyle=&quot;--&quot;, color=&quot;tab:olive&quot;) ax.set(ylim=ylim, xlabel=&quot;annual rainfall (mm)&quot;, ylabel=&quot;number of years&quot;, title=f&quot;Beer Sheva, 1922–2016. Mean={rain_mean:.0f} mm, STD={rain_std:.0f} mm&quot;) ax.text(300, 25, f&quot;CV = {rain_std/rain_mean:.2f}&quot;) plt.savefig(&quot;histogram_beersheva.png&quot;) . . Calculate the mean annual rainfall for various 30-year intervals . ####### the hard way ####### # fig, ax = plt.subplots(figsize=(10,7)) # mean_30_59 = df_year.loc[&#39;1930-09-30&#39;:&#39;1959-09-01&#39;,&#39;rain (mm)&#39;].mean() # mean_40_69 = df_year.loc[&#39;1940-09-30&#39;:&#39;1969-09-01&#39;,&#39;rain (mm)&#39;].mean() # mean_50_79 = df_year.loc[&#39;1950-09-30&#39;:&#39;1979-09-01&#39;,&#39;rain (mm)&#39;].mean() # mean_60_89 = df_year.loc[&#39;1960-09-30&#39;:&#39;1989-09-01&#39;,&#39;rain (mm)&#39;].mean() # mean_70_99 = df_year.loc[&#39;1970-09-30&#39;:&#39;1999-09-01&#39;,&#39;rain (mm)&#39;].mean() # mean_80_09 = df_year.loc[&#39;1980-09-30&#39;:&#39;2009-09-01&#39;,&#39;rain (mm)&#39;].mean() # ax.plot([mean_30_59, # mean_40_69, # mean_50_79, # mean_60_89, # mean_70_99, # mean_80_09]) ####### the easy way ####### fig, ax = plt.subplots(figsize=(10,7)) # use list comprehension windows = [[x, x+29] for x in [1930,1940,1950,1960,1970,1980]] mean = [df_year.loc[f&#39;{w[0]:d}-09-30&#39;:f&#39;{w[1]:d}-09-01&#39;,&#39;rain (mm)&#39;].mean() for w in windows] ax.plot(mean) ax.set(xticks=np.arange(len(mean)), xticklabels=[str(w) for w in windows], ylabel=&quot;window average (mm)&quot; ); . . homework . Download both daily and monthly data for London (LONDON HEATHROW, ID: UKM00003772). You should be aware that &#39;PRCP&#39; for monthly data is in millimeters, while &#39;PRCP&#39; for daily data is in tens of millimiters. | Aggregate daily data into monthly intervals using resample(&#39;MS&#39;).sum(). &#39;MS&#39; means that the sum of all days in the month will be stored in the first day of the month. Supposedly both datasets are equal now. | Calculate the average annual rainfall, using each of these datasets. | Why is there such a big difference? |",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/variability-of-precipitation-exercises.html",
            "relUrl": "/jupyter/2020/02/02/variability-of-precipitation-exercises.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post29": {
            "title": "Return period",
            "content": "Bilbao, Spain . Today . August 1983 . more photos . On Friday, August 26, 1983, Bilbao was celebrating its Aste Nagusia or Great Week, the main annual festivity in the city, when it and other municipalities of the Basque Country, Burgos, and Cantabria suffered devastating flooding due to heavy rains. In 24 hours, the volume of water registered 600 liters per square meter. Across all the affected areas, the weather service recorded 1.5 billion tons of water. In areas of Bilbao, the water reached a height of 5 meters (15 feet). Transportation, electricity and gas services, drinking water, food, telephone, and many other basic services were severely affected. 32 people died in Biscay, 4 people died in Cantabria, 2 people died in Alava, and 2 people died Burgos. 5 more people went missing. . How often will such rainfall happen? . How often does it rain 50 mm in 1 day? What about 100 mm in 1 day? How big is a &quot;once-in-a-century event&quot;? . Let&#39;s examine Bilbao&#39;s daily rainfall (mm), between 1947 to 2021 . . On the week of 22-28 August 1983, Bilbao&#39;s weather station measured 4.5 m of rainfall! . . Let&#39;s analyze this data and find out how rare such events are. First we need to find the annual maximum for each hydrological year. . import matplotlib.pyplot as plt import numpy as np import pandas as pd df = pd.read_csv(&#39;BILBAO_daily.csv&#39;, sep=&quot;,&quot;) df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) # IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm. df[&#39;PRCP&#39;] = df[&#39;PRCP&#39;] / 10 import altair as alt alt.data_transformers.disable_max_rows() # Altair only recognizes column data; it ignores index values. # You can plot the index data by first resetting the index # I know that I&#39;ve just made &#39;DATE&#39; the index, but I want to have this here nonetheless so I can refer to this in the future df_new = df.reset_index()#.replace({0.0:np.nan}) source = df_new[[&#39;DATE&#39;, &#39;PRCP&#39;]] brush = alt.selection(type=&#39;interval&#39;, encodings=[&#39;x&#39;]) base = alt.Chart(source).mark_line().encode( x = &#39;DATE:T&#39;, y = &#39;PRCP:Q&#39; ).properties( width=600, height=200 ) upper = base.encode( alt.X(&#39;DATE:T&#39;, scale=alt.Scale(domain=brush)), alt.Y(&#39;PRCP:Q&#39;, scale=alt.Scale(domain=(0,100))) ) lower = base.properties( height=60 ).add_selection(brush) alt.vconcat(upper, lower) . . We will consider a hydrological year starting on 1 August. . Histogram of annual maximum events . . How many years, on average, do we have to wait to get an annual maximum above a given threshold? . . . . . . Now everything together in one gif: . . Return Period . We will follow Brutsaert&#39;s derivation (&quot;Hydrology, an introduction&quot;, page 513). It defines quantities is a little different from what we did above. . $F(x)$ is the CDF of the PDF $f(x)$. $F(x)$ indicates the non-exceedance probability, i.e., the probability that a certain event above $x$ has not occurred (or that an event below $x$ has occurred, same thing). Modifying the graph shown above, we have . . $1-F(x)$ is the probability that a certain event above $x$ has occurred. It&#39;s reciprocal is the return period: . $$ T_r(x) = frac{1}{1-F(x)} $$This return period is the expected number of observations required until $x$ is exceeded once. In our case, we can ask the question: how many years will pass (on average) until we see a rainfall event greater that that of 26 August 1983? . Let&#39;s call $p=F(x)$ the probability that we measured once and that an event greater than $x$ has not occurred. What is the probability that a rainfall above $x$ will occur only on year number $k$? . it hasn&#39;t occurred on year 1 (probability p) | it hasn&#39;t occurred on year 2 (probability p) | it hasn&#39;t occurred on year 3 (probability p) | ... | it has occurred on year k (probability 1-p) | . $P {k text{ trials until }X&gt;x } = p^{k-1}(1-p)$ . Every time the number $k$ will be different. What will be $k$ on average? . $$ bar{k} = displaystyle sum_{k=1}^{ infty} k P(k) = displaystyle sum_{k=1}^{ infty} k p^{k-1}(1-p)$$ . Let&#39;s open that up: . $$ begin{align} bar{k} &amp;= 1-p + 2p(1-p) + 3p^2(1-p) + 4p^3(1-p)+ cdots bar{k} &amp;= 1-p + 2p - 2p^2 + 3p^2 - 3p^4 + 4p^3 - 4p^4+ cdots bar{k} &amp;= 1 + p + p^2 + p^3 + p^4 + cdots end{align} $$For $p&lt;1$, the series converges to $$ 1 + p + p^2 + p^3 + p^4 + cdots = frac{1}{1-p}, $$ therefore $$ bar{k} = frac{1}{1-p}. $$ . We conclude that if we know the exceedance probability, we immediately can say what the return times are. We now need a way of estimating this exceedance probability. . Plotting Position . Source: Brutsaert, Hydrology, pages 514-516 . The Plotting Position is used as an estimate of the exceedance probability. Many formulas have been suggested (see source above), we will use the Weibull plotting position: . $P_m=$ plotting position, or probability of occurence for each event $n=$ total number of events $m=$ rank of each event, where $m=1$ is the lowest value, and $m=n$ is the highest . Return period: . $$ text{Return period} = T_r = frac{1}{1-P_m} $$Weibull plotting position: . $$ P_m = frac{m}{n+1} $$Now let&#39;s calculate that for Bilbao: . # resample daily data into yearly data (maximum yearly value) max_annual = df[&#39;PRCP&#39;].resample(&#39;A-JUL&#39;).max().to_frame() # sort yearly max from lowest to highest max_annual = max_annual.sort_values(by=[&#39;PRCP&#39;], ascending=True) max_annual[&#39;m&#39;] = np.arange(1, len(max_annual) + 1) n = len(max_annual[&#39;m&#39;]) max_annual[&#39;Pm&#39;] = max_annual[&#39;m&#39;] / (n+1) max_annual[&#39;Tr&#39;] = 1 / (1 - max_annual[&#39;Pm&#39;]) max_annual . . PRCP m Pm Tr . DATE . 2011-07-31 27.0 | 1 | 0.013158 | 1.013333 | . 2002-07-31 28.5 | 2 | 0.026316 | 1.027027 | . 2021-07-31 35.8 | 3 | 0.039474 | 1.041096 | . 2001-07-31 38.6 | 4 | 0.052632 | 1.055556 | . 2004-07-31 41.1 | 5 | 0.065789 | 1.070423 | . ... ... | ... | ... | ... | . 2010-07-31 108.1 | 71 | 0.934211 | 15.200000 | . 1960-07-31 137.2 | 72 | 0.947368 | 19.000000 | . 1964-07-31 143.5 | 73 | 0.960526 | 25.333333 | . 1954-07-31 172.6 | 74 | 0.973684 | 38.000000 | . 1984-07-31 252.6 | 75 | 0.986842 | 76.000000 | . 75 rows × 4 columns . How well does $P_m$ approximate $F(x)$? . . We can now see in this graph how long it takes, on average, for an annual maximum event above any threshold. . . For times longer than $n$, we need to extrapolate from the curve above. . . . . .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/return-period-lecture.html",
            "relUrl": "/jupyter/2020/02/02/return-period-lecture.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post30": {
            "title": "Return period - exercises",
            "content": "Import relevant packages . import matplotlib.pyplot as plt import numpy as np import pandas as pd from functools import reduce import re import probscale import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() import urllib.request . . Go to NOAA&#39;s National Centers for Environmental Information (NCEI) Climate Data Online: Dataset Discovery . Find station codes in this map. On the left, click on the little wrench next to &quot;Global Summary of the Month&quot;, then click on &quot;identify&quot; on the panel that just opened, and click on a station (purple circle). You will see the station&#39;s name, it&#39;s ID, and the period of record. For example, for Ben-Gurion&#39;s Airport in Israel: BEN GURION, IS STATION ID: ISM00040180 Period of Record: 1951-01-01 to 2020-03-01 . You can download daily or monthly data for each station. Use the function below to download this data to your computer. station_name can be whatever you want, station_code is the station ID. . def download_data(station_name, station_code): url_daily = &#39;https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/&#39; url_monthly = &#39;https://www.ncei.noaa.gov/data/gsom/access/&#39; # download daily data - uncomment the following 2 lines to make this work # urllib.request.urlretrieve(url_daily + station_code + &#39;.csv&#39;, # station_name + &#39;_daily.csv&#39;) # download monthly data urllib.request.urlretrieve(url_monthly + station_code + &#39;.csv&#39;, station_name + &#39;_monthly.csv&#39;) . . Download daily rainfall data for Eilat, Israel. ID: IS000009972 . download_data(&#39;Eilat&#39;, &#39;IS000009972&#39;) . . Then load the data into a dataframe. IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm. . df = pd.read_csv(&#39;Eilat_daily.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) # IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm. df[&#39;PRCP&#39;] = df[&#39;PRCP&#39;] / 10 df . . STATION LATITUDE LONGITUDE ELEVATION NAME PRCP PRCP_ATTRIBUTES TMAX TMAX_ATTRIBUTES TMIN TMIN_ATTRIBUTES TAVG TAVG_ATTRIBUTES . DATE . 1949-11-30 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1949-12-01 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1949-12-02 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1949-12-03 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1949-12-04 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2021-03-24 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,S | 287.0 | ,,S | NaN | NaN | 227.0 | H,,S | . 2021-03-25 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | NaN | NaN | 253.0 | ,,S | 154.0 | ,,S | 202.0 | H,,S | . 2021-03-26 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | NaN | NaN | 251.0 | ,,S | 134.0 | ,,S | 186.0 | H,,S | . 2021-03-27 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | NaN | NaN | 222.0 | ,,S | 119.0 | ,,S | 173.0 | H,,S | . 2021-03-28 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | NaN | NaN | 238.0 | ,,S | 119.0 | ,,S | 188.0 | H,,S | . 26045 rows × 13 columns . Plot precipitation data (&#39;PRCP&#39; column) and see if everything is all right. . fig, ax = plt.subplots(figsize=(10,7)) ax.plot(df[&#39;PRCP&#39;]) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;daily rainfall (mm)&quot;) ax.set_title(&quot;Eilat, 1949–2021&quot;) . . Text(0.5, 1.0, &#39;Eilat, 1949–2021&#39;) . Based on what you see, you might want to exclude certain periods, e.g.: . last_date = &#39;2018-08-01&#39; first_date = &#39;1950-08-01&#39; df = df[((df.index &lt; last_date) &amp; (df.index &gt; first_date))] df . . STATION LATITUDE LONGITUDE ELEVATION NAME PRCP PRCP_ATTRIBUTES TMAX TMAX_ATTRIBUTES TMIN TMIN_ATTRIBUTES TAVG TAVG_ATTRIBUTES . DATE . 1950-08-02 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | 400.0 | ,,G | 240.0 | ,,G | NaN | NaN | . 1950-08-03 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | 410.0 | ,,G | 260.0 | ,,G | NaN | NaN | . 1950-08-04 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | 400.0 | ,,G | 260.0 | ,,G | NaN | NaN | . 1950-08-05 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | NaN | NaN | 240.0 | ,,G | NaN | NaN | . 1950-08-06 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,E | 370.0 | ,,G | 240.0 | ,,G | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2018-07-27 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,S | 414.0 | ,,S | NaN | NaN | 359.0 | H,,S | . 2018-07-28 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,S | 386.0 | ,,S | NaN | NaN | 329.0 | H,,S | . 2018-07-29 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,S | NaN | NaN | 268.0 | ,,S | 334.0 | H,,S | . 2018-07-30 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,S | 375.0 | ,,S | 277.0 | ,,S | 327.0 | H,,S | . 2018-07-31 IS000009972 | 29.55 | 34.95 | 12.0 | ELAT, IS | 0.0 | ,,S | 390.0 | ,,S | NaN | NaN | 336.0 | H,,S | . 24836 rows × 13 columns . The rainfall data for Eilat is VERY seasonal, it&#39;s easy to see that there is no rainfall at all during the summer. We can assume a hydrological year starting on 1 August. If you&#39;re not sure, you can plot the monthly means (see last week&#39;s lecture) and find what date makes sense best. . df_month = df[&#39;PRCP&#39;].resample(&#39;M&#39;).sum().to_frame() month_numbers = np.arange(1,13) monthly_mean = np.array([]) # empty array for m in month_numbers: # cycle over months (1, 2, 3, etc) this_month_mean = df_month[df_month.index.month == m].mean() # this is the monthly mean monthly_mean = np.append(monthly_mean, this_month_mean) # append # make new df and return it df_month = pd.DataFrame({&#39;monthly rainfall (mm)&#39;:monthly_mean, &#39;month number&#39;:month_numbers }) fig, ax = plt.subplots(figsize=(10,7)) ax.bar(df_month[&#39;month number&#39;], df_month[&#39;monthly rainfall (mm)&#39;]) ax.set(xlabel=&quot;month&quot;, ylabel=&quot;monthly rainfall (mm)&quot;, title=&quot;Monthly average, Eilat, 1949--2018&quot;, xticks=np.arange(1,13)); . . Let&#39;s resample the data according to the hydrological year (1 August), and we&#39;ll keep the maximum value: . max_annual = (df[&#39;PRCP&#39;].resample(&#39;A-JUL&#39;) .max() .to_frame() ) max_annual . . PRCP . DATE . 1951-07-31 10.8 | . 1952-07-31 15.0 | . 1953-07-31 34.4 | . 1954-07-31 24.3 | . 1955-07-31 19.0 | . ... ... | . 2014-07-31 11.5 | . 2015-07-31 2.4 | . 2016-07-31 8.5 | . 2017-07-31 34.5 | . 2018-07-31 11.7 | . 68 rows × 1 columns . Make two graphs: a) the histogram for the annual maximum (pdf) b) the cumulative probability (cdf) . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8)) h=max_annual[&#39;PRCP&#39;].values ax1.hist(h, bins=np.arange(0,100,10), density=True) ax2.hist(h, bins=np.arange(0,100,10), cumulative=1, density=True) ax1.set(ylabel=&quot;pdf&quot;) ax2.set(xlabel=&quot;annual max (mm)&quot;, ylabel=&quot;cdf&quot;, ); . . Compute the plotting position and return time. You&#39;ll need to order the data in ascending order: . max_annual = max_annual.sort_values(by=[&#39;PRCP&#39;], ascending=True) . $P_m=$ plotting position, or probability of occurence for each event $n=$ total number of events $m=$ rank of each event, where $m=1$ is the lowest value, and $m=n$ is the highest . Weibull plotting position: . $$ P_m = frac{m}{n+1} $$Return period: . $$ text{Return period} = T_r = frac{1}{1-P_m} $$Plot the annual maximum against $P_m$ or against $T_r$. . fig, ax = plt.subplots(figsize=(10, 7)) # resample daily data into yearly data (maximum yearly value) max_annual = df[&#39;PRCP&#39;].resample(&#39;A-JUL&#39;).max().to_frame() # sort yearly max from lowest to highest max_annual = max_annual.sort_values(by=[&#39;PRCP&#39;], ascending=True) max_annual[&#39;rank&#39;] = np.arange(1, len(max_annual) + 1) print(max_annual) n = len(max_annual[&#39;rank&#39;]) m = max_annual[&#39;rank&#39;] Pm = m / (n+1) Tr = 1 / (1 - Pm) # ax.plot(Tr, max_annual[&#39;PRCP&#39;]) # ax.set(xlabel=&quot;return period (y)&quot;, # ylabel=&quot;annual maximum (mm/24h)&quot;) ax.plot(Pm, max_annual[&#39;PRCP&#39;]) ax.set(xlabel=&quot;non-exeedance probability&quot;, ylabel=&quot;annual maximum (mm/24h)&quot;); . . PRCP rank DATE 1996-07-31 0.5 1 2008-07-31 0.9 2 2000-07-31 1.2 3 2012-07-31 1.3 4 1959-07-31 1.5 5 ... ... ... 1966-07-31 33.8 64 1953-07-31 34.4 65 2017-07-31 34.5 66 1981-07-31 40.6 67 1975-07-31 64.3 68 [68 rows x 2 columns] . Plot the annual maximum against the exceedance probability ($1-P_m$), in a log-log scale. Use . ax.set(xscale=&quot;log&quot;, yscale(&quot;log&quot;) ) . See what data you&#39;ll want to use for a linear fit. . fig, ax = plt.subplots(figsize=(10, 6)) depth = max_annual[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, lw=3) exclude = 40 depth_tofit = depth[exclude:] exc_prob_tofit = exc_prob[exclude:] ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) ax.set(ylabel=&quot;annual maximum (mm/24h)&quot;, xlabel=&quot;exceedance probability&quot;, xscale=&quot;log&quot;, yscale=&quot;log&quot;, ); . . Let&#39;s make a linear fit. Attention! Our data is not annual_max and exceedance_prob, but their log. . We make a linear fit using: . slope, intercept = np.polyfit(xdata, ydata, 1) # the number 1 in the order of the polynomial = linear . Write a function that receives an exceedance probability and returns the corresponding rainfall depth. . fig, ax = plt.subplots(figsize=(10, 6)) depth = max_annual[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/24h)&quot;, xlabel=&quot;exceedance probability&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) exclude = 40 depth_tofit = depth[exclude:] exc_prob_tofit = exc_prob[exclude:] ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) exc_prob_tofit_log = np.log(exc_prob_tofit) depth_tofit_log = np.log(depth_tofit) slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) def equation(p): return np.exp(slope*np.log(p) + intercept) prob = [1e-3,1-1e-3] ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) . . [&lt;matplotlib.lines.Line2D at 0x7fc1aa9feb50&gt;] . Homework . Everything we did today was for 24h rainfall events. We might be interested in extreme events in longer or shorter time scales. Using the following code, calculate the return time for 3-day rainfall events: . number_of_days = 3 df2 = (df[&#39;PRCP&#39;].rolling(number_of_days) .sum() .dropna() ) . All the rest after that is the same... .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/return-period-exercises.html",
            "relUrl": "/jupyter/2020/02/02/return-period-exercises.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post31": {
            "title": "Return period - code",
            "content": "import matplotlib.pyplot as plt import numpy as np import pandas as pd from functools import reduce import re import probscale import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() import urllib.request . def download_data(station_name, station_code): url_daily = &#39;https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/&#39; url_monthly = &#39;https://www.ncei.noaa.gov/data/gsom/access/&#39; # download daily data - uncomment to make this work urllib.request.urlretrieve(url_daily + station_code + &#39;.csv&#39;, station_name + &#39;_daily.csv&#39;) # download monthly data urllib.request.urlretrieve(url_monthly + station_code + &#39;.csv&#39;, station_name + &#39;_monthly.csv&#39;) . download_data(&#39;BILBAO&#39;, &#39;SPE00120611&#39;) . df = pd.read_csv(&#39;BILBAO_daily.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) # IMPORTANT!! daily precipitation data is in tenths of mm, divide by 10 to get it in mm. df[&#39;PRCP&#39;] = df[&#39;PRCP&#39;] / 10 . fig, ax = plt.subplots(figsize=(10,7)) ax.plot(df[&#39;PRCP&#39;]) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;daily rainfall (mm)&quot;) ax.set_title(&quot;Bilbao, Spain, 1947--2021&quot;) ax.annotate(&quot;26 August 1983&quot;, xy=(&#39;1983-08-26&#39;, 2500), xycoords=&#39;data&#39;, xytext=(0.7, 0.95), textcoords=&#39;axes fraction&#39;, fontsize=16, va=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) plt.savefig(&quot;hydrology_figures/bilbao-1947-2021.png&quot;) . from matplotlib.dates import DateFormatter import matplotlib.dates as mdates import matplotlib fig, ax = plt.subplots(figsize=(10,7)) one_week = df.loc[&#39;1983-08-22&#39;:&#39;1983-08-28&#39;, &#39;PRCP&#39;] bars = ax.bar(one_week.index, one_week) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;daily rainfall (mm)&quot;) ax.set_title(&quot;Bilbao, Spain, August 1983&quot;) # write daily rainfall for i in range(len(one_week)): ax.text(one_week.index[i], one_week[i], f&quot;{one_week[i]:.0f}&quot;, ha=&quot;center&quot;, fontsize=16) ax.text(0.1, 0.8, f&quot;Total rainfall during this week: n{one_week.sum():.0f} mm&quot;, transform=ax.transAxes, fontsize=16) # Define the date format # https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior date_form = DateFormatter(&quot;%b-%d&quot;) ax.xaxis.set_major_formatter(date_form) # Ensure a major tick for each day using (interval=1) # https://matplotlib.org/stable/api/dates_api.html#date-tickers ax.xaxis.set_major_locator(mdates.DayLocator(interval=1)) plt.gcf().autofmt_xdate() plt.savefig(&quot;hydrology_figures/bilbao-august-1983.png&quot;) . import altair as alt alt.data_transformers.disable_max_rows() df_new = df.reset_index()#.replace({0.0:np.nan}) source = df_new[[&#39;DATE&#39;, &#39;PRCP&#39;]] brush = alt.selection(type=&#39;interval&#39;, encodings=[&#39;x&#39;]) base = alt.Chart(source).mark_line().encode( x = &#39;DATE:T&#39;, y = &#39;PRCP:Q&#39; ).properties( width=600, height=200 ) upper = base.encode( alt.X(&#39;DATE:T&#39;, scale=alt.Scale(domain=brush)), alt.Y(&#39;PRCP:Q&#39;, scale=alt.Scale(domain=(0,500))) ) lower = base.properties( height=60 ).add_selection(brush) alt.vconcat(upper, lower) . df_month = df[&#39;PRCP&#39;].resample(&#39;M&#39;).sum().to_frame() month_numbers = np.arange(1,13) monthly_mean = np.array([]) # empty array for m in month_numbers: # cycle over months (1, 2, 3, etc) this_month_mean = df_month[df_month.index.month == m].mean() # this is the monthly mean monthly_mean = np.append(monthly_mean, this_month_mean) # append # make new df and return it df_month = pd.DataFrame({&#39;monthly rainfall (mm)&#39;:monthly_mean, &#39;month number&#39;:month_numbers }) df_month . monthly rainfall (mm) month number . 0 130.254054 | 1 | . 1 103.468919 | 2 | . 2 95.350667 | 3 | . 3 107.420270 | 4 | . 4 84.037838 | 5 | . 5 64.563514 | 6 | . 6 50.702703 | 7 | . 7 69.922973 | 8 | . 8 85.070270 | 9 | . 9 117.237838 | 10 | . 10 153.709459 | 11 | . 11 136.832432 | 12 | . fig, ax = plt.subplots(figsize=(10,7)) ax.bar(df_month[&#39;month number&#39;], df_month[&#39;monthly rainfall (mm)&#39;]) ax.set(xlabel=&quot;month&quot;, ylabel=&quot;monthly rainfall (mm)&quot;, title=&quot;Monthly average, Bilbao, 1947--2021&quot;, xticks=np.arange(1,13)) plt.savefig(&quot;hydrology_figures/monthly_average_bilbao.png&quot;) . Let&#39;s rank the annual max . # hydrologic year starts in August max_annual = df[&#39;PRCP&#39;].resample(&#39;A-JUL&#39;).max().to_frame() # sort yearly max from highest to lowest max_annual = max_annual.sort_values(by=[&#39;PRCP&#39;], ascending=False) max_annual[&#39;rank&#39;] = np.arange(1, len(max_annual) + 1) # print(max_annual) max_annual . PRCP rank . DATE . 1984-07-31 252.6 | 1 | . 1954-07-31 172.6 | 2 | . 1964-07-31 143.5 | 3 | . 1960-07-31 137.2 | 4 | . 2010-07-31 108.1 | 5 | . ... ... | ... | . 2004-07-31 41.1 | 71 | . 2001-07-31 38.6 | 72 | . 2021-07-31 35.8 | 73 | . 2002-07-31 28.5 | 74 | . 2011-07-31 27.0 | 75 | . 75 rows × 2 columns . %matplotlib notebook fig, ax = plt.subplots(figsize=(10,6)) # plot annual max vs. rank ax.plot(max_annual[&#39;rank&#39;], max_annual[&#39;PRCP&#39;], &#39;-o&#39;) plt.gca().set(xlabel=&quot;rank&quot;, ylabel=&quot;annual max (mm)&quot;) . [Text(0.5, 0, &#39;rank&#39;), Text(0, 0.5, &#39;annual max (mm)&#39;)] . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8)) h=max_annual[&#39;PRCP&#39;].values ax1.hist(h, bins=np.arange(0,250,20)) ax2.hist(h, bins=np.arange(0,250,20), cumulative=1) ax1.set(ylabel=&quot;number of years&quot;) ax2.set(xlabel=&quot;annual max (mm)&quot;, ylabel=&quot;cumulative&quot;) plt.savefig(&quot;hydrology_figures/hist_count_cumulative_bilbao.png&quot;) . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,8)) h=max_annual[&#39;PRCP&#39;].values ax1.hist(h, bins=np.arange(0,250,20), density=True) ax2.hist(h, bins=np.arange(0,250,20), cumulative=1, density=True) ax1.set(ylabel=&quot;pdf&quot;) ax2.set(xlabel=&quot;annual max (mm)&quot;, ylabel=&quot;cdf&quot;, ) ax1.text(0.5, 0.5, &quot;probability density function&quot;, transform=ax1.transAxes, fontsize=16, bbox=dict(boxstyle=&#39;round&#39;, facecolor=&#39;wheat&#39;, alpha=1)) ax2.text(0.5, 0.5, &quot;cumulative density function&quot;, transform=ax2.transAxes, fontsize=16, bbox=dict(boxstyle=&#39;round&#39;, facecolor=&#39;wheat&#39;, alpha=1)) plt.savefig(&quot;hydrology_figures/pdf_cdf_bilbao.png&quot;) . max_annual.shape[0] . 75 . Ward, Environmental Hydrology, pages 46-47, Brutsaert, Hydrology, pages 514-516 . $P_m=$ plotting position, or probability of occurence for each event $n=$ total number of events $m=$ rank of each event . Return period: . $$ text{Return period} = frac{1}{1-P_m} $$oldest, and intuitively the simplest: . $$ P_m = frac{m}{n} $$another option: . $$ P_m = frac{m-1}{n} $$Hazen: . $$ P_m = frac{m- frac{1}{2}}{n} $$Weibull: . $$ P_m = frac{m}{n+1} $$ Return Period . Brutsaert, &quot;Hydrology, an introduction&quot;, page 513 . $F(x)$ is the CDF of the PDF $f(x)$. $F(x)$ indicates the probability that a certain event above $x$ has not occurred (or that an event below $x$ has occurred, same thing). . $1-F(x)$ is the probability that a certain event above $x$ has occurred. It&#39;s reciprocal is the return period: $$ T_r(x) = frac{1}{1-F(x)} $$ . This return period is the expected number of observations required until $x$ is exceeded once. In our case, we can ask the question: how many years will pass (on average) until we see a rainfall event greater that that of 26 August 1983? . Let&#39;s call $p=F(x)$ the probability that we measured once and that an event greater than $x$ has not occurred. What is the probability that a rainfall above $x$ will occur only on year number $k$? . it hasn&#39;t occurred on year 1 (probability p) | it hasn&#39;t occurred on year 2 (probability p) | it hasn&#39;t occurred on year 3 (probability p) | ... | it has occurred on year k (probability 1-p) | . $P {k text{ trials until }X&gt;x } = p^{k-1}(1-p)$ . Every time the number $k$ will be different. What will be $k$ on average? . $$ bar{k} = displaystyle sum_{k=1}^{ infty} k P(k) = displaystyle sum_{k=1}^{ infty} k p^{k-1}(1-p)$$ . Let&#39;s open that up: . $$ begin{align} bar{k} &amp;= 1-p + 2p(1-p) + 3p^2(1-p) + 4p^3(1-p)+ cdots bar{k} &amp;= 1-p + 2p - 2p^2 + 3p^2 - 3p^4 + 4p^3 - 4p^4+ cdots bar{k} &amp;= 1 + p + p^2 + p^3 + p^4 + cdots end{align} $$For $p&lt;1$, the series converges to $$ 1 + p + p^2 + p^3 + p^4 + cdots = frac{1}{1-p}, $$ therefore $$ bar{k} = frac{1}{1-p}. $$ . from scipy.stats import gamma import scipy from matplotlib import rc rc(&#39;text&#39;, usetex=True) fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6))#, sharex=True) a = 4 xmax = 12 b = np.arange(0,13,1) x = np.linspace(0, gamma.ppf(0.999, a), 100) # x = np.linspace(gamma.ppf(0.001, a), # gamma.ppf(0.999, a), 100) ax1.plot(x, gamma.pdf(x, a), &#39;r-&#39;, lw=5, alpha=0.6, label=&#39;gamma pdf&#39;) r = gamma.rvs(a, size=10000) ax1.hist(r, bins=b, density=True, histtype=&#39;stepfilled&#39;, alpha=0.2) ax2.hist(r, bins=b, density=True, histtype=&#39;stepfilled&#39;, alpha=0.2, cumulative=-1) ax2.plot(x, 1-scipy.special.gammainc(a, x), &#39;r-&#39;, lw=5, alpha=0.6, label=&#39;gamma cdf&#39;) quantile = lambda p: gamma.ppf(1-p, a) p = 0.05 q = quantile(p) xfill = np.linspace(q, xmax, 100) ax1.fill_between(xfill, gamma.pdf(xfill, a), color=&#39;None&#39;, hatch=&quot;//&quot;,edgecolor=&#39;k&#39;) ax2.plot([0, q, q], [p, p ,0], color=&quot;black&quot;, ls=&quot;:&quot;) ax1.annotate(r&quot; noindent probability that next occurrence is textbf{ underline{higher}} than $x^*$:&quot; + &quot; {:.0f} %&quot;.format(100*p), xy=(q+0.8, gamma.pdf(q+0.8, a)*0.6), xycoords=&#39;data&#39;, xytext=(0.7, 0.8), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.0)) ax2.annotate(r&quot; noindent textbf{ underline{exceedance}} probability&quot;, xy=(q, 1-scipy.special.gammainc(a, q)), xycoords=&#39;data&#39;, xytext=(0.5, 0.9), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.0)) ax2.text(q+0.1, 0, r&quot;$x^*$&quot;, ha=&quot;left&quot;, va=&quot;bottom&quot;, fontsize=16) ax2.text(0.5, p, r&quot;{:.0f} %&quot;.format(100*p), ha=&quot;left&quot;, va=&quot;bottom&quot;, fontsize=16) ax1.set_title(r&quot;we&#39;ll wait textbf{on average}&quot; + &quot; ({:.0f} %)&quot;.format(100*p) + r&quot;$^{-1}=$&quot; + r&quot; ({:.2f})&quot;.format(p) + r&quot;$^{-1}=$&quot; + &quot; {:.0f} years &quot;.format(1/p) + r&quot; for a yearly maximum above $x^*$&quot;, fontsize=16) ax1.set(xlim=[0, xmax], ylabel=&quot;probability density&quot;, xticks=[q], xticklabels=[r&quot;$x^*$&quot;]) ax2.set(xlim=[0, xmax], xlabel=r&quot;$x$&quot;, ylabel=&quot;cumulative&quot;) plt.savefig(&quot;hydrology_figures/return_prob_005.png&quot;) . import imageio files = [&#39;hydrology_figures/return_prob_050.png&#39;, &#39;hydrology_figures/return_prob_033.png&#39;, &#39;hydrology_figures/return_prob_020.png&#39;, &#39;hydrology_figures/return_prob_010.png&#39;, &#39;hydrology_figures/return_prob_005.png&#39;,] images = [imageio.imread(file) for file in files] imageio.mimwrite(&#39;hydrology_figures/movie.gif&#39;, images, fps=1) . from scipy.stats import gamma import scipy from matplotlib import rc rc(&#39;text&#39;, usetex=True) fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6))#, sharex=True) a = 4 xmax = 12 b = np.arange(0,13,1) x = np.linspace(0, gamma.ppf(0.999, a), 100) # x = np.linspace(gamma.ppf(0.001, a), # gamma.ppf(0.999, a), 100) ax1.plot(x, gamma.pdf(x, a), &#39;r-&#39;, lw=5, alpha=0.6, label=&#39;gamma pdf&#39;) r = gamma.rvs(a, size=10000) ax1.hist(r, bins=b, density=True, histtype=&#39;stepfilled&#39;, alpha=0.2) ax2.hist(r, bins=b, density=True, histtype=&#39;stepfilled&#39;, alpha=0.2, cumulative=1) ax2.plot(x, scipy.special.gammainc(a, x), &#39;r-&#39;, lw=5, alpha=0.6, label=&#39;gamma cdf&#39;) quantile = lambda p: gamma.ppf(1-p, a) p = 0.50 q = quantile(p) xfill = np.linspace(0, q, 100) ax1.fill_between(xfill, gamma.pdf(xfill, a), color=&#39;None&#39;, hatch=&quot;//&quot;,edgecolor=&#39;k&#39;) ax2.plot([0, q, q], [p, p ,0], color=&quot;black&quot;, ls=&quot;:&quot;) ax1.annotate(r&quot; noindent probability that next occurrence is textbf{ underline{lower}} than $x^*$:&quot; + &quot; {:.0f} %&quot;.format(100*p), xy=(q-0.8, gamma.pdf(q+0.8, a)*0.6), xycoords=&#39;data&#39;, xytext=(0.7, 0.8), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.0)) ax2.annotate(r&quot; noindent textbf{ underline{non-exceedance}} probability&quot;, xy=(q, 1-scipy.special.gammainc(a, q)), xycoords=&#39;data&#39;, xytext=(0.3, 0.9), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.0)) ax2.text(q+0.1, 0, r&quot;$x^*$&quot;, ha=&quot;left&quot;, va=&quot;bottom&quot;, fontsize=16) ax2.text(0.5, p, r&quot;{:.0f} %&quot;.format(100*p), ha=&quot;left&quot;, va=&quot;bottom&quot;, fontsize=16) # ax1.set_title(r&quot;we&#39;ll wait textbf{on average}&quot; + # &quot; ({:.0f} %)&quot;.format(100*p) + # r&quot;$^{-1}=$&quot; + # r&quot; ({:.2f})&quot;.format(p) + # r&quot;$^{-1}=$&quot; + # &quot; {:.0f} years &quot;.format(1/p) + r&quot; for a yearly maximum below $x^*$&quot;, fontsize=16) ax2.text(0.6,0.5,r&quot;$ displaystyle F(x)= int_0^x ! !f(x) textrm{d}x$&quot;, transform=ax2.transAxes, fontsize=20) ax1.set_ylabel(r&quot;$f(x)$&quot;, rotation=&quot;horizontal&quot;, labelpad=20) ax2.set_ylabel(r&quot;$F(x)$&quot;, rotation=&quot;horizontal&quot;, labelpad=20) ax1.set(xlim=[0, xmax], xticks=[q], xticklabels=[r&quot;$x^*$&quot;]) ax2.set(xlim=[0, xmax], xlabel=r&quot;$x$&quot;) plt.savefig(&quot;hydrology_figures/return_prob_050_reversed.png&quot;) . fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 10)) # resample daily data into yearly data (maximum yearly value) max_annual = df[&#39;PRCP&#39;].resample(&#39;A-JUL&#39;).max().to_frame() # sort yearly max from highest to lowest max_annual = max_annual.sort_values(by=[&#39;PRCP&#39;], ascending=True) max_annual[&#39;rank&#39;] = np.arange(1, len(max_annual) + 1) print(max_annual) # plot annual max vs. rank ax1.plot(max_annual[&#39;rank&#39;], max_annual[&#39;PRCP&#39;], &#39;-o&#39;) ax1.set(xlabel=&quot;rank&quot;, ylabel=&quot;annual max (mm)&quot;) n = len(max_annual[&#39;rank&#39;]) m = max_annual[&#39;rank&#39;] Pm = m / (n+1) Tr = 1 / (1 - Pm) ax2.plot(max_annual[&#39;rank&#39;], Tr) ax3.plot(Tr, max_annual[&#39;PRCP&#39;]) ax2.set(xlabel=&quot;rank&quot;, ylabel=&quot;return period (y)&quot;) ax3.set(xlabel=&quot;return period (y)&quot;, ylabel=&quot;yearly maximum (mm/24h)&quot;) . PRCP rank DATE 2011-07-31 27.0 1 2002-07-31 28.5 2 2021-07-31 35.8 3 2001-07-31 38.6 4 2004-07-31 41.1 5 ... ... ... 2010-07-31 108.1 71 1960-07-31 137.2 72 1964-07-31 143.5 73 1954-07-31 172.6 74 1984-07-31 252.6 75 [75 rows x 2 columns] . [Text(0.5, 0, &#39;return period (y)&#39;), Text(0, 0.5, &#39;yearly maximum (mm/24h)&#39;)] . fig, ax = plt.subplots(figsize=(10, 7)) # resample daily data into yearly data (maximum yearly value) max_annual = df[&#39;PRCP&#39;].resample(&#39;A-JUL&#39;).max().to_frame() # sort yearly max from highest to lowest max_annual = max_annual.sort_values(by=[&#39;PRCP&#39;], ascending=True) max_annual[&#39;rank&#39;] = np.arange(1, len(max_annual) + 1) print(max_annual) # plot annual max vs. rank # ax1.plot(max_annual[&#39;rank&#39;], max_annual[&#39;PRCP&#39;], &#39;-o&#39;) # ax1.set(xlabel=&quot;rank&quot;, # ylabel=&quot;annual max (mm)&quot;) n = len(max_annual[&#39;rank&#39;]) m = max_annual[&#39;rank&#39;] Pm = m / (n+1) Tr = 1 / (1 - Pm) # ax2.plot(max_annual[&#39;rank&#39;], Tr) ax.plot(Tr, max_annual[&#39;PRCP&#39;]) # ax2.set(xlabel=&quot;rank&quot;, # ylabel=&quot;return period (y)&quot;) ax.set(xlabel=&quot;return period (y)&quot;, ylabel=&quot;annual maximum (mm/24h)&quot;) plt.savefig(&quot;hydrology_figures/annual_max_vs_return_period.png&quot;) . PRCP rank DATE 2011-07-31 27.0 1 2002-07-31 28.5 2 2021-07-31 35.8 3 2001-07-31 38.6 4 2004-07-31 41.1 5 ... ... ... 2010-07-31 108.1 71 1960-07-31 137.2 72 1964-07-31 143.5 73 1954-07-31 172.6 74 1984-07-31 252.6 75 [75 rows x 2 columns] . Tr . DATE 2011-07-31 1.013333 2002-07-31 1.027027 2021-07-31 1.041096 2001-07-31 1.055556 2004-07-31 1.070423 ... 2010-07-31 15.200000 1960-07-31 19.000000 1964-07-31 25.333333 1954-07-31 38.000000 1984-07-31 76.000000 Name: rank, Length: 75, dtype: float64 . fig, ax = plt.subplots(figsize=(10, 6)) ax.hist(h, bins=np.arange(0,250,20), cumulative=1, density=True, label=&quot;1947--2021 statistics for Bilbao&quot;) ax.plot(max_annual[&#39;PRCP&#39;], Pm, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(xlabel=&quot;annual maximum (mm/24h)&quot;, ylabel=&quot;cumulative (non-exceedance) probability&quot;, xlim=[0, 250], ylim=[0, 1.2], yticks=np.arange(0,1.1,0.2)) ax.legend(loc=&quot;upper left&quot;, frameon=False) plt.savefig(&quot;hydrology_figures/weibull_plotting_position.png&quot;) . fig, ax = plt.subplots(figsize=(10, 6)) # ax.hist(h, bins=np.arange(0,2500,200), cumulative=1, density=True, label=&quot;1947--2021 statistics for Bilbao&quot;) ax.plot(max_annual[&#39;PRCP&#39;], Pm, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(xlabel=&quot;annual maximum (mm/24h)&quot;, ylabel=&quot;cumulative (non-exceedance) probability&quot;)#, # xlim=[0, 2500], # ylim=[0, 1.2], # yticks=np.arange(0,1.1,0.2)) ax.set_xscale(&quot;linear&quot;) ax.legend(loc=&quot;upper left&quot;, frameon=False) . &lt;matplotlib.legend.Legend at 0x7f87d147cad0&gt; . import imageio files = [&#39;hydrology_figures/return_prob_050.png&#39;, &#39;hydrology_figures/return_prob_033.png&#39;, &#39;hydrology_figures/return_prob_020.png&#39;, &#39;hydrology_figures/return_prob_010.png&#39;, &#39;hydrology_figures/return_prob_005.png&#39;,] images = [imageio.imread(file) for file in files] imageio.mimwrite(&#39;hydrology_figures/movie.gif&#39;, images, fps=1) . from matplotlib.ticker import ScalarFormatter import matplotlib.ticker as mtick fig, ax = plt.subplots(figsize=(10, 6)) depth = max_annual[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/24h)&quot;, xlabel=&quot;exceedance probability&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) exclude = 40 depth_tofit = depth[exclude:] exc_prob_tofit = exc_prob[exclude:] # ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) exc_prob_tofit_log = np.log(exc_prob_tofit) depth_tofit_log = np.log(depth_tofit) slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) prob = [1e-3,1-1e-3] def equation(p): return np.exp(slope*np.log(p) + intercept) # ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) one_in_x_years = np.array([5, 10, 50, 100])#, 200, 1000]) for y in one_in_x_years: ax.plot([1/y]*2, [0, equation(1/y)], color=&quot;black&quot;, ls=&quot;--&quot;) ax.text(1/y, 30, f&quot;{y}-yr event&quot;, rotation=90, ha=&quot;right&quot;, fontsize=16) ax.set_xticks([0.01, 0.02, 0.1, 0.2, 1.0]) ax.set_yticks([10, 20, 50, 100, 200, 500]) ax.yaxis.set_major_formatter(ScalarFormatter()) ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: &#39;{:.1f}%&#39;.format(y*100))) # ax.annotate(f&quot;{equation(1/5):.0f} mm&quot;, # xy=(1/5, equation(1/5)), xycoords=&#39;data&#39;, # xytext=(0.8, 0.6), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/10):.0f} mm&quot;, # xy=(1/10, equation(1/10)), xycoords=&#39;data&#39;, # xytext=(0.7, 0.7), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/50):.0f} mm&quot;, # xy=(1/50, equation(1/50)), xycoords=&#39;data&#39;, # xytext=(0.6, 0.8), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/100):.0f} mm&quot;, # xy=(1/100, equation(1/100)), xycoords=&#39;data&#39;, # xytext=(0.5, 0.9), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/200):.0f} mm&quot;, # xy=(1/200, equation(1/200)), xycoords=&#39;data&#39;, # xytext=(0.35, 0.9), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/1000):.0f} mm&quot;, # xy=(1/1000, equation(1/1000)), xycoords=&#39;data&#39;, # xytext=(0.2, 0.95), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) plt.savefig(&quot;hydrology_figures/extrapolation_exceedance1.png&quot;) . from matplotlib.ticker import ScalarFormatter import matplotlib.ticker as mtick fig, ax = plt.subplots(figsize=(10, 6)) depth = max_annual[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/24h)&quot;, xlabel=&quot;exceedance probability&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) exclude = 40 depth_tofit = depth[exclude:] exc_prob_tofit = exc_prob[exclude:] ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) exc_prob_tofit_log = np.log(exc_prob_tofit) depth_tofit_log = np.log(depth_tofit) slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) prob = [1e-3,1-1e-3] def equation(p): return np.exp(slope*np.log(p) + intercept) # ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) one_in_x_years = np.array([5, 10, 50, 100])#, 200, 1000]) for y in one_in_x_years: ax.plot([1/y]*2, [0, equation(1/y)], color=&quot;black&quot;, ls=&quot;--&quot;) ax.text(1/y, 30, f&quot;{y}-yr event&quot;, rotation=90, ha=&quot;right&quot;, fontsize=16) ax.set_xticks([0.01, 0.02, 0.1, 0.2, 1.0]) ax.set_yticks([10, 20, 50, 100, 200, 500]) ax.yaxis.set_major_formatter(ScalarFormatter()) ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: &#39;{:.1f}%&#39;.format(y*100))) # ax.annotate(f&quot;{equation(1/5):.0f} mm&quot;, # xy=(1/5, equation(1/5)), xycoords=&#39;data&#39;, # xytext=(0.8, 0.6), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/10):.0f} mm&quot;, # xy=(1/10, equation(1/10)), xycoords=&#39;data&#39;, # xytext=(0.7, 0.7), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/50):.0f} mm&quot;, # xy=(1/50, equation(1/50)), xycoords=&#39;data&#39;, # xytext=(0.6, 0.8), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/100):.0f} mm&quot;, # xy=(1/100, equation(1/100)), xycoords=&#39;data&#39;, # xytext=(0.5, 0.9), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/200):.0f} mm&quot;, # xy=(1/200, equation(1/200)), xycoords=&#39;data&#39;, # xytext=(0.35, 0.9), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/1000):.0f} mm&quot;, # xy=(1/1000, equation(1/1000)), xycoords=&#39;data&#39;, # xytext=(0.2, 0.95), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) plt.savefig(&quot;hydrology_figures/extrapolation_exceedance2.png&quot;) . from matplotlib.ticker import ScalarFormatter import matplotlib.ticker as mtick fig, ax = plt.subplots(figsize=(10, 6)) depth = max_annual[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/24h)&quot;, xlabel=&quot;exceedance probability&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) exclude = 40 depth_tofit = depth[exclude:] exc_prob_tofit = exc_prob[exclude:] ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) exc_prob_tofit_log = np.log(exc_prob_tofit) depth_tofit_log = np.log(depth_tofit) slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) prob = [1e-2,1-1e-3] def equation(p): return np.exp(slope*np.log(p) + intercept) ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) one_in_x_years = np.array([5, 10, 50, 100])#, 200, 1000]) for y in one_in_x_years: ax.plot([1/y]*2, [0, equation(1/y)], color=&quot;black&quot;, ls=&quot;--&quot;) ax.text(1/y, 30, f&quot;{y}-yr event&quot;, rotation=90, ha=&quot;right&quot;, fontsize=16) ax.set_xticks([0.01, 0.02, 0.1, 0.2, 1.0]) ax.set_yticks([10, 20, 50, 100, 200, 500]) ax.yaxis.set_major_formatter(ScalarFormatter()) ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: &#39;{:.1f}%&#39;.format(y*100))) # ax.annotate(f&quot;{equation(1/5):.0f} mm&quot;, # xy=(1/5, equation(1/5)), xycoords=&#39;data&#39;, # xytext=(0.8, 0.6), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/10):.0f} mm&quot;, # xy=(1/10, equation(1/10)), xycoords=&#39;data&#39;, # xytext=(0.7, 0.7), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/50):.0f} mm&quot;, # xy=(1/50, equation(1/50)), xycoords=&#39;data&#39;, # xytext=(0.6, 0.8), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/100):.0f} mm&quot;, # xy=(1/100, equation(1/100)), xycoords=&#39;data&#39;, # xytext=(0.5, 0.9), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/200):.0f} mm&quot;, # xy=(1/200, equation(1/200)), xycoords=&#39;data&#39;, # xytext=(0.35, 0.9), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) # ax.annotate(f&quot;{equation(1/1000):.0f} mm&quot;, # xy=(1/1000, equation(1/1000)), xycoords=&#39;data&#39;, # xytext=(0.2, 0.95), textcoords=&#39;axes fraction&#39;, # fontsize=16, horizontalalignment=&quot;center&quot;, # arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) plt.savefig(&quot;hydrology_figures/extrapolation_exceedance3.png&quot;) . from matplotlib.ticker import ScalarFormatter import matplotlib.ticker as mtick fig, ax = plt.subplots(figsize=(10, 6)) depth = max_annual[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/24h)&quot;, xlabel=&quot;exceedance probability&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) exclude = 40 depth_tofit = depth[exclude:] exc_prob_tofit = exc_prob[exclude:] ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) exc_prob_tofit_log = np.log(exc_prob_tofit) depth_tofit_log = np.log(depth_tofit) slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) prob = [1e-3,1-1e-3] def equation(p): return np.exp(slope*np.log(p) + intercept) ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) one_in_x_years = np.array([5, 10, 50, 100, 200, 1000]) for y in one_in_x_years: ax.plot([1/y]*2, [0, equation(1/y)], color=&quot;black&quot;, ls=&quot;--&quot;) ax.text(1/y, 30, f&quot;{y}-yr event&quot;, rotation=90, ha=&quot;right&quot;, fontsize=16) ax.set_xticks([0.001, 0.005, 0.01, 0.02, 0.1, 0.2, 1.0]) ax.set_yticks([10, 20, 50, 100, 200, 500]) ax.yaxis.set_major_formatter(ScalarFormatter()) ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: &#39;{:.1f}%&#39;.format(y*100))) ax.annotate(f&quot;{equation(1/5):.0f} mm&quot;, xy=(1/5, equation(1/5)), xycoords=&#39;data&#39;, xytext=(0.8, 0.6), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) ax.annotate(f&quot;{equation(1/10):.0f} mm&quot;, xy=(1/10, equation(1/10)), xycoords=&#39;data&#39;, xytext=(0.7, 0.7), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) ax.annotate(f&quot;{equation(1/50):.0f} mm&quot;, xy=(1/50, equation(1/50)), xycoords=&#39;data&#39;, xytext=(0.6, 0.8), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) ax.annotate(f&quot;{equation(1/100):.0f} mm&quot;, xy=(1/100, equation(1/100)), xycoords=&#39;data&#39;, xytext=(0.5, 0.9), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) ax.annotate(f&quot;{equation(1/200):.0f} mm&quot;, xy=(1/200, equation(1/200)), xycoords=&#39;data&#39;, xytext=(0.35, 0.9), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) ax.annotate(f&quot;{equation(1/1000):.0f} mm&quot;, xy=(1/1000, equation(1/1000)), xycoords=&#39;data&#39;, xytext=(0.2, 0.95), textcoords=&#39;axes fraction&#39;, fontsize=16, horizontalalignment=&quot;center&quot;, arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05)) plt.savefig(&quot;hydrology_figures/extrapolation_exceedance4.png&quot;) . df7days = (df[&#39;PRCP&#39;].rolling(3) .sum() .dropna() ) annual_7days = (df7days.resample(&#39;A-JUL&#39;) .max() .to_frame() ) annual_7days = annual_7days.reset_index() annual_7days = (annual_7days.iloc[1:-1] .sort_values(by=[&#39;PRCP&#39;], ascending=True) ) annual_7days[&#39;rank&#39;] = np.arange(1, len(annual_7days) + 1) n = len(annual_7days[&#39;rank&#39;]) m = annual_7days[&#39;rank&#39;] Pm = m / (n+1) fig, ax = plt.subplots(figsize=(10, 6)) depth = annual_7days[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ax.plot(exc_prob, depth, &#39;-o&#39;, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/week)&quot;, xlabel=&quot;exceedance probability&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) exclude = 40 depth_tofit = depth[exclude:-1] exc_prob_tofit = exc_prob[exclude:-1] ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) exc_prob_tofit_log = np.log(exc_prob_tofit) depth_tofit_log = np.log(depth_tofit) slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) prob = [1e-3,1-1e-3] def equation(p): return np.exp(slope*np.log(p) + intercept) ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) ax.set_xticks([0.001, 0.005, 0.01, 0.02, 0.1, 0.2, 1.0]) ax.set_yticks([50, 100, 200, 500]) ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: &#39;{:.0f}&#39;.format(y))) ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: &#39;{:.1f}%&#39;.format(x*100))) . df7days = (df[&#39;PRCP&#39;].rolling(3) .sum() .dropna() ) annual_7days = (df7days.resample(&#39;A-JUL&#39;) .max() .to_frame() ) annual_7days = annual_7days.reset_index() annual_7days = (annual_7days.iloc[1:-1] .sort_values(by=[&#39;PRCP&#39;], ascending=True) ) annual_7days[&#39;rank&#39;] = np.arange(1, len(annual_7days) + 1) n = len(annual_7days[&#39;rank&#39;]) m = annual_7days[&#39;rank&#39;] Pm = m / (n+1) fig, ax = plt.subplots(figsize=(10, 6)) depth = annual_7days[&#39;PRCP&#39;].values exc_prob = (1-Pm).values ret_time = 1 / exc_prob ax.plot(ret_time, depth, &#39;-o&#39;, lw=3, label=&quot;Weibull plotting position&quot;) ax.set(ylabel=&quot;annual maximum (mm/week)&quot;, xlabel=&quot;return time (year)&quot;) ax.set_xscale(&quot;log&quot;) ax.set_yscale(&quot;log&quot;) # exclude = 40 # depth_tofit = depth[exclude:-1] # exc_prob_tofit = exc_prob[exclude:-1] # ax.plot(exc_prob_tofit, depth_tofit, &#39;o&#39;) # exc_prob_tofit_log = np.log(exc_prob_tofit) # depth_tofit_log = np.log(depth_tofit) # slope, intercept = np.polyfit(exc_prob_tofit_log, depth_tofit_log, 1) # prob = [1e-3,1-1e-3] # def equation(p): # return np.exp(slope*np.log(p) + intercept) # ax.plot(prob, equation(prob), lw=3, color=&quot;tab:red&quot;, alpha=0.4) # ax.set_xticks([0.001, 0.005, 0.01, 0.02, 0.1, 0.2, 1.0]) # ax.set_yticks([500, 1000, 2000, 5000]) # ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: &#39;{:.0f}&#39;.format(y))) # ax.xaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: &#39;{:.1f} %&#39;.format(x*100))) .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/return-period-code.html",
            "relUrl": "/jupyter/2020/02/02/return-period-code.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post32": {
            "title": "Intra-annual variability of precipitation",
            "content": ". Let&#39;s shift the months according the the hydrological year: . . Seasonality Index, Walsh and Lawler (1981) . http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability . $R=$ mean annual precipitation $m_i$ precipitation mean for month $i$ . $$ SI = displaystyle frac{1}{R} sum_{n=1}^{n=12} left| m_i - frac{R}{12} right| $$ . $SI$ Precipitation Regime . &lt;0.19 | Precipitation spread throughout the year | . 0.20-0.39 | Precipitation spread throughout the year, but with a definite wetter season | . 0.40-0.59 | Rather seasonal with a short dry season | . 0.60-0.79 | Seasonal | . 0.80-0.99 | Marked seasonal with a long dry season | . 1.00-1.19 | Most precipitation in &lt;3 months | . # import packages import numpy as np import pandas as pd from calendar import month_abbr # load data month_numbers = np.arange(1,13) month_names = [month_abbr[i] for i in month_numbers] def monthly_mean(station_name, freq): # import daily data df = pd.read_csv(station_name + &#39;_&#39; + freq + &#39;.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) # print(df.index[0], df.index[-1]) if freq == &#39;daily&#39;: # resample data by month df_month = df[&#39;PRCP&#39;].resample(&#39;M&#39;).sum() # sum is labeled at the last day of the month df_month = df_month/10 # PRCP is given in tens of mm (see readme) if freq == &#39;monthly&#39;: df_month = df[&#39;PRCP&#39;] # calculate monthly mean monthly_mean = np.array([]) # empty array for m in month_numbers: # cycle over months (1, 2, 3, etc) this_month_all_indices = (df_month.index.month == m) # indices in df_month belonging to month m this_month_mean = df_month[this_month_all_indices].mean() # this is the monthly mean monthly_mean = np.append(monthly_mean, this_month_mean) # append # make new df and return it df_return = pd.DataFrame({&#39;monthly rainfall (mm)&#39;:monthly_mean, &#39;month names&#39;:month_names, &#39;month number&#39;:month_numbers }) return df_return # load monthly mean df_london = monthly_mean(&quot;LONDON HEATHROW&quot;, &#39;monthly&#39;) df_telaviv = monthly_mean(&quot;TEL AVIV READING&quot;, &#39;monthly&#39;) #collapse-hide def walsh_index(df): m = df[&quot;monthly rainfall (mm)&quot;] R = df[&quot;monthly rainfall (mm)&quot;].sum() SI = np.sum(np.abs(m-R/12)) / R return SI london_index = walsh_index(df_london) telaviv_index = walsh_index(df_telaviv) print(&quot;Seasonality index (Walsh and Lawler, 1981)&quot;) print(f&quot;London: {london_index:.2f}&quot;) print(f&quot;Tel Aviv: {telaviv_index:.2f}&quot;) . . Seasonality index (Walsh and Lawler, 1981) London: 0.13 Tel Aviv: 1.00 . .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/intra-annual-variability-of-precipitation-seasonality-lecture.html",
            "relUrl": "/jupyter/2020/02/02/intra-annual-variability-of-precipitation-seasonality-lecture.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post33": {
            "title": "Intra-annual variability of precipitation - code",
            "content": "import matplotlib.pyplot as plt import numpy as np import pandas as pd from calendar import month_abbr import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) import urllib.request . import data . Go to NOAA&#39;s National Centers for Environmental Information (NCEI) Climate Data Online: Dataset Discovery . Find station codes in this map . def download_data(station_name, station_code): url_daily = &#39;https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/&#39; url_monthly = &#39;https://www.ncei.noaa.gov/data/gsom/access/&#39; # download daily data urllib.request.urlretrieve(url_daily + station_code + &#39;.csv&#39;, station_name + &#39;_daily.csv&#39;) # download monthly data urllib.request.urlretrieve(url_monthly + station_code + &#39;.csv&#39;, station_name + &#39;_monthly.csv&#39;) . calculate monthly averages . month_numbers = np.arange(1,13) month_names = [month_abbr[i] for i in month_numbers] def monthly_mean(station_name, freq): # import daily data df = pd.read_csv(station_name + &#39;_&#39; + freq + &#39;.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) print(df.index[0], df.index[-1]) if freq == &#39;daily&#39;: # resample data by month df_month = df[&#39;PRCP&#39;].resample(&#39;M&#39;).sum() # sum is labeled at the last day of the month df_month = df_month/10 # PRCP is given in tens of mm (see readme) if freq == &#39;monthly&#39;: df_month = df[&#39;PRCP&#39;] # calculate monthly mean monthly_mean = np.array([]) # empty array for m in month_numbers: # cycle over months (1, 2, 3, etc) this_month_all_indices = (df_month.index.month == m) # indices in df_month belonging to month m this_month_mean = df_month[this_month_all_indices].mean() # this is the monthly mean monthly_mean = np.append(monthly_mean, this_month_mean) # append # make new df and return it df_return = pd.DataFrame({&#39;monthly rainfall (mm)&#39;:monthly_mean, &#39;month names&#39;:month_names, &#39;month number&#39;:month_numbers }) return df_return . # download_data(&#39;TEL AVIV READING&#39;, &#39;IS000002011&#39;) # download_data(&#39;SAO PAULO&#39;, &#39;BR00E3-0520&#39;) . df_london = monthly_mean(&quot;LONDON HEATHROW&quot;, &#39;monthly&#39;) df_telaviv = monthly_mean(&quot;TEL AVIV READING&quot;, &#39;monthly&#39;) df_saopaulo = monthly_mean(&quot;SAO PAULO&quot;, &#39;monthly&#39;) total_london = df_london[&#39;monthly rainfall (mm)&#39;].sum() total_telaviv = df_telaviv[&#39;monthly rainfall (mm)&#39;].sum() . 1973-01-01 00:00:00 2021-02-01 00:00:00 1939-11-01 00:00:00 1999-11-01 00:00:00 1940-04-01 00:00:00 2021-02-01 00:00:00 . fig, ax = plt.subplots(figsize=(10,7)) # bar plots ax.bar(df_london[&#39;month number&#39;], df_london[&#39;monthly rainfall (mm)&#39;], alpha=0.5, color=&quot;blue&quot;, label=f&quot;London ({total_london:.0f} mm per year)&quot;) ax.bar(df_telaviv[&#39;month number&#39;], df_telaviv[&#39;monthly rainfall (mm)&#39;], alpha=0.5, color=&quot;red&quot;, width=0.5, label=f&quot;Tel Aviv ({total_telaviv:.0f} mm per year)&quot;) # axes labels and figure title ax.set_xlabel(&#39;month&#39;) ax.set_ylabel(&#39;monthly rainfall average (mm)&#39;) ax.set_title(&#39;seasonality of two cities with similar yearly rainfall&#39;) # some ticks adjustments ax.set_xticks(month_numbers) plt.legend(loc=&#39;upper center&#39;) # save figure plt.savefig(&quot;hydrology_figures/monthly_tel_aviv_london_bars.png&quot;) . fig, ax = plt.subplots(figsize=(10,7)) # hydrological year starts in October, roll data by 9 months months = df_london[&#39;month number&#39;] months_to_roll = -9 # minus sign = roll data to the left london_rolled = np.roll(df_london[&#39;monthly rainfall (mm)&#39;], months_to_roll) telaviv_rolled = np.roll(df_telaviv[&#39;monthly rainfall (mm)&#39;], months_to_roll) months_rolled = np.roll(months, months_to_roll) months_rolled_str = [str(x) for x in months_rolled] # bar plots ax.bar(months, london_rolled, alpha=0.5, color=&quot;blue&quot;, label=f&quot;London ({total_london:.0f} mm per year)&quot;) ax.bar(months, telaviv_rolled, alpha=0.5, color=&quot;red&quot;, width=0.5, label=f&quot;Tel Aviv ({total_telaviv:.0f} mm per year)&quot;) # axes labels and figure title ax.set_xlabel(&#39;month&#39;) ax.set_ylabel(&#39;monthly rainfall average (mm)&#39;) ax.set_title(&#39;seasonality of two cities with similar yearly rainfall&#39;) # some ticks adjustments # ax.set_xticks(months) ax.set_xticklabels(months_rolled_str) plt.legend(loc=&#39;upper right&#39;) # save figure plt.savefig(&quot;hydrology_figures/monthly_tel_aviv_london_bars_hydrological_year.png&quot;) . fig = plt.figure(figsize=(10,10)) # radar chart ax = fig.add_subplot(111, polar=True) # make polar plot ax.set_theta_zero_location(&quot;N&quot;) # January on top (&quot;N&quot;orth) ax.set_theta_direction(-1) # clockwise direction ax.set_rlabel_position(90) # radial labels on the right ax.set_rticks([50,100]) # two radial ticks is enough ax.set_rlim(0,150) # limits of r axis angles=np.linspace(0, 2*np.pi, 12, endpoint=False) # divide circle into 12 slices angles=np.append(angles, angles[0]) # close loop, otherwise lines will be open ax.set_thetagrids(angles[:-1] * 180/np.pi, month_names) # relabel angles with month names # plot london data stats_london = np.array(df_london[&#39;monthly rainfall (mm)&#39;]) # get london data stats_london = np.append(stats_london, stats_london[0]) # close loop ax.plot(angles, stats_london, &quot;o-&quot;, color=&#39;blue&#39;, label=&quot;london&quot;) # plot line ax.fill(angles, stats_london, alpha=0.25, color=&#39;blue&#39;) # fill # plot tel aviv data stats_telaviv = np.array(df_telaviv[&#39;monthly rainfall (mm)&#39;]) # get tel aviv data stats_telaviv = np.append(stats_telaviv, stats_telaviv[0]) # close loop ax.plot(angles, stats_telaviv, &quot;o-&quot;, color=&#39;red&#39;, label=&quot;tel aviv&quot;) # plot line ax.fill(angles, stats_telaviv, alpha=0.25, color=&#39;red&#39;) # fill # plot sao paulo data # stats_saopaulo = np.array(df_saopaulo[&#39;monthly rainfall (mm)&#39;]) # get tel aviv data # stats_saopaulo = np.append(stats_saopaulo, stats_saopaulo[0]) # close loop # ax.plot(angles, stats_saopaulo, &quot;o-&quot;, color=&#39;green&#39;, label=&quot;sao paulo&quot;) # plot line # ax.fill(angles, stats_saopaulo, alpha=0.25, color=&#39;green&#39;) # fill ax.set_title(&quot;Monthly rainfall averages&quot;) ax.legend(loc=(-0.1,0.9)) # legend at x=-0.2 so it doesn&#39;t overlap with graph # save figure plt.savefig(&quot;hydrology_figures/radar_chart_tel_aviv_london.png&quot;) . station_name = &quot;LONDON HEATHROW&quot; freq = &#39;daily&#39; df_day = pd.read_csv(station_name + &#39;_&#39; + freq + &#39;.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df_day[&#39;DATE&#39;] = pd.to_datetime(df_day[&#39;DATE&#39;]) df_day = df_day.set_index(&#39;DATE&#39;) # resample data by month df_month1 = df_day[&#39;PRCP&#39;].resample(&#39;MS&#39;).sum() # sum is labeled at the last day of the month df_month1 = df_month1/10 # PRCP is given in tens of mm (see readme) freq = &#39;monthly&#39; df_mon = pd.read_csv(station_name + &#39;_&#39; + freq + &#39;.csv&#39;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df_mon[&#39;DATE&#39;] = pd.to_datetime(df_mon[&#39;DATE&#39;]) df_mon = df_mon.set_index(&#39;DATE&#39;) # resample data by month df_month2 = df_mon[&#39;PRCP&#39;] . %matplotlib notebook plt.plot(df_month1, label=&#39;from daily data&#39;) plt.plot(df_month2, label=&#39;from monthly data&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f93c9228cd0&gt; . %matplotlib notebook df = pd.read_csv(&quot;TEL AVIV READING_monthly.csv&quot;, sep=&quot;,&quot;) df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) df_by_year = df.groupby([df.index.year]) for year_number, df_year in df_by_year: year_precipitation = df_year[&#39;PRCP&#39;].values year_precipitation = np.roll(year_precipitation, 6) month_numbers = np.arange(1,len(year_precipitation)+1) month_numbers_roll = np.roll(month_numbers, 6) plt.plot(month_numbers, year_precipitation, color=&quot;gray&quot;, alpha=0.2) month_numbers = np.arange(1,12+1) month_numbers_roll = np.roll(month_numbers, 6) plt.xticks(month_numbers, month_numbers_roll) . ([&lt;matplotlib.axis.XTick at 0x7f83097830d0&gt;, &lt;matplotlib.axis.XTick at 0x7f82f83d3f10&gt;, &lt;matplotlib.axis.XTick at 0x7f82f83d3390&gt;, &lt;matplotlib.axis.XTick at 0x7f82e86780d0&gt;, &lt;matplotlib.axis.XTick at 0x7f835ad1a610&gt;, &lt;matplotlib.axis.XTick at 0x7f835acf4610&gt;, &lt;matplotlib.axis.XTick at 0x7f835acf4ed0&gt;, &lt;matplotlib.axis.XTick at 0x7f835acf42d0&gt;, &lt;matplotlib.axis.XTick at 0x7f835acf4510&gt;, &lt;matplotlib.axis.XTick at 0x7f835ad0f590&gt;, &lt;matplotlib.axis.XTick at 0x7f835ad0fa90&gt;, &lt;matplotlib.axis.XTick at 0x7f83096f7090&gt;], [Text(1, 0, &#39;7&#39;), Text(2, 0, &#39;8&#39;), Text(3, 0, &#39;9&#39;), Text(4, 0, &#39;10&#39;), Text(5, 0, &#39;11&#39;), Text(6, 0, &#39;12&#39;), Text(7, 0, &#39;1&#39;), Text(8, 0, &#39;2&#39;), Text(9, 0, &#39;3&#39;), Text(10, 0, &#39;4&#39;), Text(11, 0, &#39;5&#39;), Text(12, 0, &#39;6&#39;)]) . np.roll(np.arange(12),6) . array([ 6, 7, 8, 9, 10, 11, 0, 1, 2, 3, 4, 5]) . Seasonality Index, Walsh and Lawler (1981) . http://leddris.aegean.gr/ses-parameters/293-rainfall-seasonality.html#:~:text=Rainfall%20seasonality%20index%20is%20a,in%20relation%20to%20water%20availability . SI Precipitation Regime . &lt;0.19 | Precipitation spread throughout the year | . 0.20-0.39 | Precipitation spread throughout the year, but with a definite wetter season | . 0.40-0.59 | Rather seasonal with a short dry season | . 0.60-0.79 | Seasonal | . 0.80-0.99 | Marked seasonal with a long dry season | . 1.00-1.19 | Most precipitation in &lt;3 months | . def walsh_index(df): X = df[&quot;monthly rainfall (mm)&quot;] Ri = df[&quot;monthly rainfall (mm)&quot;].sum() SI = np.sum(np.abs(X-Ri/12)) / Ri return SI london_index = walsh_index(df_london) telaviv_index = walsh_index(df_telaviv) print(&quot;london seasonality: t&quot;, london_index) print(&quot;tel aviv seasonality: t&quot;, telaviv_index) print(&quot;ratio: t&quot;, telaviv_index/london_index) . london seasonality: 0.114678755577802 tel aviv seasonality: 1.0004295512696868 ratio: 8.723756603645398 . fig, ax = plt.subplots(figsize=(10,7)) plt.rcParams[&#39;hatch.linewidth&#39;] = 3 # hydrological year starts in October, roll data by 9 months months = df_london[&#39;month number&#39;] months_to_roll = -9 # minus sign = roll data to the left # london_rolled = np.roll(df_london[&#39;monthly rainfall (mm)&#39;], months_to_roll) telaviv_rolled = np.roll(df_telaviv[&#39;monthly rainfall (mm)&#39;], months_to_roll) months_rolled = np.roll(months, months_to_roll) months_rolled_str = [str(x) for x in months_rolled] # bar plots # ax.bar(months, london_rolled, # alpha=0.5, color=&quot;blue&quot;, # label=f&quot;London ({total_london:.0f} mm per year)&quot;) xlim = [1, 13] ax.plot(xlim, [total_telaviv/12]*2, color=&quot;tab:blue&quot;, linewidth=3) ax.set_xlim(xlim) shaded = telaviv_rolled - total_telaviv/12 ax.bar(months, shaded, alpha=0.9, color=&quot;None&quot;, width=1, hatch=&quot;//&quot;, edgecolor=&#39;k&#39;, align=&#39;edge&#39;, bottom=total_telaviv/12, label=f&quot;absolute difference&quot;) ax.bar(months, telaviv_rolled, alpha=0.5, color=&quot;red&quot;, width=1, align=&#39;edge&#39;, label=f&quot;total rainfall&quot;, zorder=0) ax.text(5.3, 86.5, r&quot;SI$=1.00=$&quot;, fontsize=24) ax.text(xlim[-1], total_telaviv/12, &quot; mean&quot;, va=&quot;center&quot;) ax.plot([8.2, 12.8], [89.5]*2, color=&quot;black&quot;, lw=2) # # axes labels and figure title ax.set_xlabel(&#39;month&#39;) ax.set_ylabel(&#39;monthly rainfall average (mm)&#39;) ax.set_title(&#39;Walsh and Lawler (1981) Seasonality Index; Tel Aviv&#39;) ax.set_xticks(np.arange(1.5,12.6,1)) ax.set_xticklabels(months_rolled_str) # ax.set_title(&#39;seasonality of two cities with similar yearly rainfall&#39;) # # some ticks adjustments # # # ax.set_xticks(months) # ax.set_xticklabels(months_rolled_str) plt.legend(loc=&#39;upper right&#39;, frameon=False, bbox_to_anchor=(1, 0.7), fontsize=18) # save figure plt.savefig(&quot;hydrology_figures/si_walsh_telaviv.png&quot;) . fig, ax = plt.subplots(figsize=(10,7)) plt.rcParams[&#39;hatch.linewidth&#39;] = 3 # hydrological year starts in October, roll data by 9 months months = df_london[&#39;month number&#39;] months_to_roll = -9 # minus sign = roll data to the left london_rolled = np.roll(df_london[&#39;monthly rainfall (mm)&#39;], months_to_roll) # telaviv_rolled = np.roll(df_telaviv[&#39;monthly rainfall (mm)&#39;], months_to_roll) months_rolled = np.roll(months, months_to_roll) months_rolled_str = [str(x) for x in months_rolled] xlim = [1, 13] ax.plot(xlim, [total_london/12]*2, color=&quot;tab:blue&quot;, linewidth=3) ax.set_xlim(xlim) shaded = london_rolled - total_london/12 ax.bar(months, shaded, alpha=0.9, color=&quot;None&quot;, width=1, hatch=&quot;//&quot;, edgecolor=&#39;k&#39;, align=&#39;edge&#39;, bottom=total_london/12, label=f&quot;absolute difference&quot;) ax.bar(months, london_rolled, alpha=0.5, color=&quot;red&quot;, width=1, align=&#39;edge&#39;, label=f&quot;total rainfall&quot;, zorder=0) ax.text(5.3, 73.5, r&quot;SI$=0.13=$&quot;, fontsize=24) ax.text(xlim[-1], total_london/12, &quot; mean&quot;, va=&quot;center&quot;) ax.plot([8.2, 12.8], [75]*2, color=&quot;black&quot;, lw=2) # # axes labels and figure title ax.set_xlabel(&#39;month&#39;) ax.set_ylabel(&#39;monthly rainfall average (mm)&#39;) ax.set_title(&#39;Walsh and Lawler (1981) Seasonality Index; London&#39;) ax.set_xticks(np.arange(1.5,12.6,1)) ax.set_xticklabels(months_rolled_str) ax.set_ylim([0, 83]) # ax.set_title(&#39;seasonality of two cities with similar yearly rainfall&#39;) # # some ticks adjustments # # # ax.set_xticks(months) # ax.set_xticklabels(months_rolled_str) plt.legend(loc=&#39;upper right&#39;, frameon=False, bbox_to_anchor=(1, 1.005), fontsize=18) # save figure plt.savefig(&quot;hydrology_figures/si_walsh_london.png&quot;) .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/intra-annual-variability-of-precipitation-code.html",
            "relUrl": "/jupyter/2020/02/02/intra-annual-variability-of-precipitation-code.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post34": {
            "title": "Interannual variability of precipitation",
            "content": ". hydrological year . A time period of 12 months for which precipitation totals are measured. The hydrological year is designated by the calendar year in which it ends. Let&#39;s define the hydrological year for Tel Aviv from 1 October to 30 September. . האם אקלים הגשם שלנו משתנה . . coefficient of variation . $ langle{P} rangle=$ average precipitation $ sigma=$ standard deviation . $$CV = frac{ sigma}{ langle{P} rangle}$$ . Assuming that the inter-annual distribution is a gaussian: 67% of the time, rainfall will vary +/- 30% from its long term average in Tel Aviv. . Precipitation averages are usually calculated for time intervals of 30 years. . . . import altair as alt import pandas as pd df = pd.read_csv(&quot;TEL AVIV READING_monthly.csv&quot;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) df_year_all = df[&#39;PRCP&#39;].resample(&#39;A-SEP&#39;).sum().to_frame() # annual frequency, anchored end of September df_year_all.columns = [&#39;rain (mm)&#39;] # rename &#39;PRCP&#39; column to &#39;rain (mm)&#39; df_year = df_year_all.iloc[:-1] # exclude last row # Altair only recognizes column data; it ignores index values. # You can plot the index data by first resetting the index # I know that I&#39;ve just made &#39;DATE&#39; the index, but I want to have this here nonetheless so I can refer to this in the future source = df_year.reset_index() brush = alt.selection(type=&#39;interval&#39;, encodings=[&#39;x&#39;]) # T: temporal, a time or date value # Q: quantitative, a continuous real-valued quantity # https://altair-viz.github.io/user_guide/encoding.html#encoding-data-types bars = alt.Chart().mark_bar().encode( x=alt.X(&#39;DATE:T&#39;, axis=alt.Axis(title=&#39;date&#39;)), y=alt.Y(&#39;rain (mm):Q&#39;, axis=alt.Axis(title=&#39;annual precipitation (mm) and average&#39;)), opacity=alt.condition(brush, alt.OpacityValue(1), alt.OpacityValue(0.2)), ).add_selection( brush ).properties( title=&#39;Select year range and drag for rolling average of annual precipitation in Tel Aviv&#39; ).properties( width=600, height=400 ) line = alt.Chart().mark_rule(color=&#39;orange&#39;).encode( y=&#39;mean(rain (mm)):Q&#39;, size=alt.SizeValue(3) ).transform_filter( brush ) alt.layer(bars, line, data=source) . . .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/interannual-variability-of-precipitation-lecture.html",
            "relUrl": "/jupyter/2020/02/02/interannual-variability-of-precipitation-lecture.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post35": {
            "title": "Interannual variability of precipitation - code",
            "content": "import matplotlib.pyplot as plt import matplotlib import numpy as np import pandas as pd from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() # datetime converter for a matplotlib from calendar import month_abbr import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) import urllib.request . def download_data(station_name, station_code): url_daily = &#39;https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/&#39; url_monthly = &#39;https://www.ncei.noaa.gov/data/gsom/access/&#39; # download daily data urllib.request.urlretrieve(url_daily + station_code + &#39;.csv&#39;, station_name + &#39;_daily.csv&#39;) # download monthly data urllib.request.urlretrieve(url_monthly + station_code + &#39;.csv&#39;, station_name + &#39;_monthly.csv&#39;) . df = pd.read_csv(&quot;TEL AVIV READING_monthly.csv&quot;, sep=&quot;,&quot;) # make &#39;DATE&#39; the dataframe index df[&#39;DATE&#39;] = pd.to_datetime(df[&#39;DATE&#39;]) df = df.set_index(&#39;DATE&#39;) df . STATION LATITUDE LONGITUDE ELEVATION NAME CDSD CDSD_ATTRIBUTES CLDD CLDD_ATTRIBUTES DP01 ... HTDD HTDD_ATTRIBUTES PRCP PRCP_ATTRIBUTES TAVG TAVG_ATTRIBUTES TMAX TMAX_ATTRIBUTES TMIN TMIN_ATTRIBUTES . DATE . 1939-11-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | NaN | NaN | NaN | NaN | 7.0 | ... | NaN | NaN | 106.5 | ,,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1939-12-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | NaN | NaN | NaN | NaN | 7.0 | ... | NaN | NaN | 100.1 | ,,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1940-01-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | NaN | NaN | NaN | NaN | 11.0 | ... | NaN | NaN | 181.5 | ,,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1940-02-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | NaN | NaN | NaN | NaN | 6.0 | ... | NaN | NaN | 57.7 | ,,,E | NaN | NaN | NaN | NaN | NaN | NaN | . 1940-03-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | NaN | NaN | NaN | NaN | 7.0 | ... | NaN | NaN | 27.2 | ,,,E | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1999-05-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | 165.9 | NaN | 125.0 | ,I | NaN | ... | 0.0 | ,I | NaN | NaN | 22.37 | ,I | 26.15 | ,,,I | 18.58 | ,,,I | . 1999-06-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | 367.1 | NaN | 201.2 | 1,I | NaN | ... | 0.0 | 1,I | NaN | NaN | 25.29 | 1,I | 28.93 | 1,,,I | 21.65 | ,,,I | . 1999-07-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | 612.0 | NaN | 244.9 | 4,I | NaN | ... | 0.0 | 4,I | NaN | NaN | 27.44 | 4,I | 31.09 | 4,,,I | 23.80 | ,,,I | . 1999-08-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | 921.4 | NaN | 309.4 | ,I | NaN | ... | 0.0 | ,I | NaN | NaN | 28.31 | ,I | 31.54 | ,,,I | 25.09 | ,,,I | . 1999-11-01 IS000002011 | 32.1 | 34.7831 | 3.0 | TEL AVIV READING, IS | NaN | NaN | 62.1 | ,I | NaN | ... | 13.3 | ,I | NaN | NaN | 19.96 | ,I | 24.41 | ,,,I | 15.51 | ,,,I | . 719 rows × 43 columns . fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,7)) # plot precipitation ax1.fill_between(df.index, df[&#39;PRCP&#39;], 0, color=&#39;tab:blue&#39;) df_1990_1992 = df.loc[&#39;1990-07-01&#39;:&#39;1992-07-01&#39;] ax2.bar(df_1990_1992.index, df_1990_1992[&#39;PRCP&#39;], width=30) # adjust labels, ticks, title, etc ax1.set_title(&quot;Monthly precipitation in Tel Aviv&quot;) ax2.tick_params(axis=&#39;x&#39;, rotation=45) ax2.set_xlabel(&quot;date&quot;) # dirty trick to get common y label between the two panels: # make a large invisible axes, give it a ylabel ax0 = fig.add_subplot(111, frame_on=False) ax0.tick_params(labelcolor=&quot;none&quot;, bottom=False, left=False) ax0.set_ylabel(&quot;monthly precipitation (mm)&quot;, labelpad=20) # write yearly rainfall rain_1990_1991 = df.loc[&#39;1990-07-01&#39;:&#39;1991-07-01&#39;,&#39;PRCP&#39;].sum() rain_1991_1992 = df.loc[&#39;1991-07-01&#39;:&#39;1992-07-01&#39;,&#39;PRCP&#39;].sum() ax2.text(&#39;1991-01-01&#39;, 300, &quot;{:.0f} mm&quot;.format(rain_1990_1991)) ax2.text(&#39;1992-01-01&#39;, 300, &quot;{:.0f} mm&quot;.format(rain_1991_1992)) # save figure plt.savefig(&quot;monthly_tel_aviv_1940-1999.png&quot;) . hydrological year . A time period of 12 months for which precipitation totals are measured. The water year is designated by the calendar year in which it ends. Let&#39;s define the hydrological year for Tel Aviv from 1 October to 30 September. . # https://pandas.pydata.org/pandas-docs/version/0.12.0/timeseries.html#offset-aliases # also, annual resampling can be anchored to the end of specific months: # https://pandas.pydata.org/pandas-docs/version/0.12.0/timeseries.html#anchored-offsets df_year_all = df[&#39;PRCP&#39;].resample(&#39;A-SEP&#39;).sum().to_frame() # annual frequency, anchored end of September df_year_all.columns = [&#39;rain (mm)&#39;] # rename &#39;PRCP&#39; column to &#39;rain (mm)&#39; df_year_all . rain (mm) . DATE . 1940-09-30 474.9 | . 1941-09-30 447.8 | . 1942-09-30 372.9 | . 1943-09-30 618.2 | . 1944-09-30 440.5 | . ... ... | . 1996-09-30 488.2 | . 1997-09-30 619.1 | . 1998-09-30 489.6 | . 1999-09-30 226.5 | . 2000-09-30 0.0 | . 61 rows × 1 columns . df_year = df_year_all.iloc[:-1] # exclude last row df_year.tail() # show &quot;tail&quot; of the dataframe to see that year 2000 was excluded . rain (mm) . DATE . 1995-09-30 804.7 | . 1996-09-30 488.2 | . 1997-09-30 619.1 | . 1998-09-30 489.6 | . 1999-09-30 226.5 | . fig, ax = plt.subplots(figsize=(10,7)) # plot YEARLY precipitation ax.bar(df_year.index, df_year[&#39;rain (mm)&#39;], width=365, align=&#39;edge&#39;, color=&quot;tab:blue&quot;) # plot mean rain_mean = df_year[&#39;rain (mm)&#39;].mean() ax.plot(df_year*0 + rain_mean, linewidth=3, color=&quot;tab:orange&quot;) # adjust labels, ticks, title, etc ax.set_title(&quot;Annual precipitation in Tel Aviv, 1940–1999&quot;) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;annual precipitation (mm)&quot;) ax.set_xlim([df_year.index[0], df_year.index[-1]]) # write mean on the right ax.text(df_year.index[-1], rain_mean, &quot; mean n {:.0f} mm&quot;.format(rain_mean), horizontalalignment=&quot;left&quot;, verticalalignment=&quot;center&quot;) # save figure plt.savefig(&quot;annual_tel_aviv_with_mean.png&quot;) . fig, ax = plt.subplots(figsize=(10,7)) # calculate mean and standard deviation rain_mean = df_year[&#39;rain (mm)&#39;].mean() rain_std = df_year[&#39;rain (mm)&#39;].std() # plot histogram b = np.arange(0, 1101, 100) # bins from 0 to 55, width = 5 ax.hist(df_year, bins=b) # plot vertical lines with mean, std, etc ylim = np.array(ax.get_ylim()) ylim[1] = ylim[1]*1.1 ax.plot([rain_mean]*2, ylim, linewidth=3, color=&quot;tab:orange&quot;) ax.plot([rain_mean+rain_std]*2, ylim, linewidth=3, linestyle=&quot;--&quot;, color=&quot;tab:olive&quot;) ax.plot([rain_mean-rain_std]*2, ylim, linewidth=3, linestyle=&quot;--&quot;, color=&quot;tab:olive&quot;) ax.set_ylim(ylim) # write mean, std, etc ax.text(rain_mean, ylim[1]*0.99, &quot;mean&quot;, horizontalalignment=&quot;center&quot;, verticalalignment=&quot;top&quot;, bbox=dict(facecolor=&#39;white&#39;, edgecolor=&#39;none&#39;, pad=0.0)) ax.text(rain_mean+rain_std, ylim[1]*0.99, &quot;mean+std&quot;, horizontalalignment=&quot;center&quot;, verticalalignment=&quot;top&quot;, bbox=dict(facecolor=&#39;white&#39;, edgecolor=&#39;none&#39;, pad=0.0)) ax.text(rain_mean-rain_std, ylim[1]*0.99, &quot;mean-std&quot;, horizontalalignment=&quot;center&quot;, verticalalignment=&quot;top&quot;, bbox=dict(facecolor=&#39;white&#39;, edgecolor=&#39;none&#39;, pad=0.0)) # adjust labels, ticks, title, limits, etc ax.set_title(&quot;Histogram of annual precipitation in Tel Aviv, 1940–1999&quot;) ax.set_xlabel(&quot;annual rainfall (mm)&quot;) ax.set_ylabel(&quot;number of years&quot;) # save figure plt.savefig(&quot;histogram_tel_aviv_with_mean_and_std.png&quot;) . coefficient of variation . $ langle{P} rangle=$ average precipitation $ sigma=$ standard deviation . $$CV = frac{ sigma}{ langle{P} rangle}$$ . Assuming that the inter-annual distribution is a gaussian: 67% of the time, rainfall will vary +/- 30% from its long term average in Tel Aviv. . CV = rain_std / rain_mean print(f&quot;CV = {CV:.2f}&quot;) # rain_mean . CV = 0.30 . fig, ax = plt.subplots(figsize=(10,7)) # windows of length 30 years windows = [[1940,1969], [1970,1999]] for window in windows: start_date = f&quot;{window[0]:d}-09-30&quot; end_date = f&quot;{window[1]:d}-09-30&quot; window_mean = df_year[&#39;rain (mm)&#39;][start_date:end_date].mean() ax.plot(df_year[start_date:end_date]*0+window_mean, color=&quot;purple&quot;, linewidth=3) ax.text(start_date, window_mean+0.5, f&quot;{window[0]} to {window[1]}: {window_mean:.0f} mm&quot;) # plot mean rain_mean = df_year[&#39;rain (mm)&#39;].mean() ax.plot(df_year*0 + rain_mean, linewidth=3, color=&quot;tab:orange&quot;, alpha=0.5) ax.text(df_year.index[-1], rain_mean, &quot; mean&quot;.format(rain_mean), horizontalalignment=&quot;left&quot;, verticalalignment=&quot;center&quot;) # adjust labels, ticks, title, limits, etc ax.set_title(&quot;Annual precipitation averages in Tel Aviv, 1940–1999&quot;) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;annual precipitation (mm)&quot;) ax.set_xlim([df_year.index[0], df_year.index[-1]]) ax.set_ylim([500, 560]) # save figure plt.savefig(&quot;mean_tel_aviv_2_windows.png&quot;) . fig, ax = plt.subplots(figsize=(10,7)) # windows of length 30 years windows = [[x,x+29] for x in [1940,1950,1960,1970]] for window in windows: start_date = f&quot;{window[0]:d}-09-30&quot; end_date = f&quot;{window[1]:d}-09-30&quot; window_mean = df_year[&#39;rain (mm)&#39;][start_date:end_date].mean() ax.plot(df_year[start_date:end_date]*0+window_mean, color=&quot;purple&quot;, linewidth=3) ax.text(start_date, window_mean+0.5, f&quot;{window[0]} to {window[1]}: {window_mean:.0f} mm&quot;) # plot mean ax.plot(df_year*0 + rain_mean, linewidth=3, color=&quot;tab:orange&quot;, alpha=0.5) ax.text(df_year.index[-1], rain_mean, &quot; mean&quot;.format(rain_mean), horizontalalignment=&quot;left&quot;, verticalalignment=&quot;center&quot;) # adjust labels, ticks, title, limits, etc ax.set_title(&quot;Annual precipitation averages in Tel Aviv&quot;) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;annual precipitation (mm)&quot;) ax.set_xlim([df_year.index[0], df_year.index[-1]]) ax.set_ylim([500, 560]) # save figure plt.savefig(&quot;mean_tel_aviv_4_windows.png&quot;) . import altair as alt from vega_datasets import data # Altair only recognizes column data; it ignores index values. You can plot the index data by first resetting the index source = df_year.reset_index() brush = alt.selection(type=&#39;interval&#39;, encodings=[&#39;x&#39;]) # T: temporal, a time or date value # Q: quantitative, a continuous real-valued quantity # https://altair-viz.github.io/user_guide/encoding.html#encoding-data-types bars = alt.Chart().mark_bar().encode( x=alt.X(&#39;DATE:T&#39;, axis=alt.Axis(title=&#39;date&#39;)), y=alt.Y(&#39;rain (mm):Q&#39;, axis=alt.Axis(title=&#39;annual precipitation (mm) and average&#39;)), opacity=alt.condition(brush, alt.OpacityValue(1), alt.OpacityValue(0.2)), ).add_selection( brush ).properties( title=&#39;Select year range and drag for rolling average of annual precipitation in Tel Aviv&#39; ).properties( width=600, height=400 ) line = alt.Chart().mark_rule(color=&#39;orange&#39;).encode( y=&#39;mean(rain (mm)):Q&#39;, size=alt.SizeValue(3) ).transform_filter( brush ) alt.layer(bars, line, data=source) . fig, ax = plt.subplots(figsize=(10,7)) rolling_mean = df_year.rolling(30, center=True).mean() ax.plot(rolling_mean, linewidth=3, color=&quot;tab:red&quot;, zorder=5) ax.set_title(&quot;30-year rolling average, Tel Aviv&quot;) ax.set_xlabel(&quot;date&quot;) ax.set_ylabel(&quot;annual precipitation (mm)&quot;) # windows of length 30 years windows = [[x,x+29] for x in [1940,1950,1960,1970]] for window in windows: start_date = f&quot;{window[0]:d}-09-30&quot; end_date = f&quot;{window[1]:d}-09-30&quot; window_mean = df_year[&#39;rain (mm)&#39;][start_date:end_date].mean() ax.plot(df_year[start_date:end_date]*0+window_mean, color=&quot;purple&quot;, linewidth=3, alpha=0.5) ax.text(start_date, window_mean+0.5, f&quot;{window[0]} to {window[1]}: {window_mean:.0f} mm&quot;, alpha=0.5) ax.set_ylim([480, 560]) # plot mean ax.plot(df_year*0 + rain_mean, linewidth=3, color=&quot;tab:orange&quot;, alpha=0.5) ax.text(df_year.index[-1], rain_mean, &quot; mean&quot;.format(rain_mean), horizontalalignment=&quot;left&quot;, verticalalignment=&quot;center&quot;) ax.set_xlim([df_year.index[0], df_year.index[-1]]) # save figure plt.savefig(&quot;rolling_average_tel_aviv.png&quot;) . rolling_mean . rain (mm) . DATE . 1940-09-30 NaN | . 1941-09-30 NaN | . 1942-09-30 NaN | . 1943-09-30 NaN | . 1944-09-30 NaN | . 1945-09-30 NaN | . 1946-09-30 NaN | . 1947-09-30 NaN | . 1948-09-30 NaN | . 1949-09-30 NaN | . 1950-09-30 NaN | . 1951-09-30 NaN | . 1952-09-30 NaN | . 1953-09-30 NaN | . 1954-09-30 NaN | . 1955-09-30 543.683333 | . 1956-09-30 541.690000 | . 1957-09-30 539.496667 | . 1958-09-30 547.746667 | . 1959-09-30 541.823333 | . 1960-09-30 550.390000 | . 1961-09-30 542.760000 | . 1962-09-30 536.510000 | . 1963-09-30 545.810000 | . 1964-09-30 545.803333 | . 1965-09-30 537.756667 | . 1966-09-30 530.206667 | . 1967-09-30 535.093333 | . 1968-09-30 527.663333 | . 1969-09-30 528.926667 | . 1970-09-30 516.710000 | . 1971-09-30 510.670000 | . 1972-09-30 495.516667 | . 1973-09-30 495.690000 | . 1974-09-30 502.350000 | . 1975-09-30 506.033333 | . 1976-09-30 517.593333 | . 1977-09-30 513.926667 | . 1978-09-30 527.450000 | . 1979-09-30 533.643333 | . 1980-09-30 524.583333 | . 1981-09-30 526.223333 | . 1982-09-30 531.463333 | . 1983-09-30 529.980000 | . 1984-09-30 532.553333 | . 1985-09-30 517.790000 | . 1986-09-30 NaN | . 1987-09-30 NaN | . 1988-09-30 NaN | . 1989-09-30 NaN | . 1990-09-30 NaN | . 1991-09-30 NaN | . 1992-09-30 NaN | . 1993-09-30 NaN | . 1994-09-30 NaN | . 1995-09-30 NaN | . 1996-09-30 NaN | . 1997-09-30 NaN | . 1998-09-30 NaN | . 1999-09-30 NaN | .",
            "url": "https://yairmau.github.io/website/jupyter/hydrology/2020/02/02/interannual-variability-of-precipitation-code.html",
            "relUrl": "/jupyter/hydrology/2020/02/02/interannual-variability-of-precipitation-code.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post36": {
            "title": "Assignment 2 - Evapotranspiration",
            "content": "&#128210; instructions . This is where learning happens, not during a lecture. You&#39;ll learn a ton of things by doing them yourself. Much success! 😄 . Create a Jupyter Notebook called assignment-02-IDNUMBER, where IDNUMBER is your 9-digit ID. This is the file only file we will check. . &#128204; locations and data . Choose two stations with different climates. . Go to NOAA&#39;s Climate Reference Network Data website. The sub-hourly (5-min) data contains information on . air temperature, | precipitation, | global solar radiation, | surface infrared temperature, | relative humidity, | soil moisture and temperature, | wetness, and | 1.5 meter wind speed. There is no data on air pressure, so one needs to use the stations coordinates (lat, lon) to find its height above sea level, and from that infer the air pressure. You can use Google Earth or any other means to find the station&#39;s height. | . In the Data Access link, choose a year and a station you would like to analyze. If you are not sure where the stations are, find them using the 2-letter state abbreviation and the station name. . Download the following files: . One full year of data for each station. Make sure important data we need to calculate Penman&#39;s ET estimation is available. | The headers file | The documentation file | Make sure you understand what are the units provided for each measurement (see documentation). . &#128736; tasks . Produce potential ET estimates using Thornthwaite&#39;s equation and Penman&#39;s equation. Produce plots of ET as a function of time for each station, comparing the two methods you used. Also, using Penman&#39;s ET estimates, compare the two stations and discuss about their differences/similarities. . You might find interesting things in the data, such as periods of unusually high/low temperatures, radiation, etc. Discuss how these factors might have affected the ET estimates that you calculated. . You will have two weeks to deliver your assignment. You should not hand in a dry document with only figures and code, I&#39;m expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Don&#39;t forget to put labels on your plot axes, title, legend, etc. . Your Jupyter Notebook should be fully functional: if we press Kernel &gt; Restart &amp; Run All, all the code must work without any errors. . &#127749; presentation . All the assignment must be in one single Jupyter Notebook. Use markdown cells to discuss the analysis and results, and in code cells show all the code you used to produce the figures and data analysis. Leave only the code necessary for your analysis, delete unnecessary lines your wrote while analyzing your data. Don&#39;t forget to comment your code, just like we did during exercise sessions. . You can write in English or in Hebrew, but the text in the figures must be in English. If you choose to write the discussion in Hebrew, be aware that Jupyter Notebooks don&#39;t have native right-to-left language support: . ניתן לכתוב בעברית, למרות שזה לא נראה כ״כ טוב... . You can use some HTML code to achieve best results in Hebrew. Type the following . &lt;p dir=&quot;rtl&quot; style=&quot;text-align: right;&quot;&gt; עכשיו הרבה יותר טוב! &lt;/p&gt; . to get . עכשיו הרבה יותר טוב! . If you have many paragraphs in hebrew, do the following: . פסקה מספר 1. . פסקה מספר 2. . אם יש לכם כמה פסקאות, כל אחת מהן תהיה בתוך &quot;dir&quot; משלה . In my opinion it is too complicated to write in Hebrew in Jupyter Notebooks, just write in English, your grade will not be affected by typos nor less-than-perfect English proficiency. . &#128175; evaluation . Your assignment will be evaluated according to the following criteria: . 40% Presentation. How the graphs look, labels, general organization, markdown, clean code. | 30% Discussion. This is where you explain what you did, what you found out, etc. | 15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration. | 10% Replicability: Your code runs flawlessly. | 5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself! | . &#128666; importing the data . Below you can find an example of how to import the data file provided by NOAA&#39;s Climate Reference Network Data website. You might have to make some adjustments to it. . data_file = &quot;CRNS0101-05-2020-CO_Boulder_14_W.txt&quot; df = pd.read_csv(data_file, header=None, # no headers needed, we&#39;ll do that later delim_whitespace=True, # blank spaces separate between columns na_values=[&quot;-99.000&quot;, &quot;-9999.0&quot;] # substitute these values for missing (NaN) values ) headers = pd.read_csv(&quot;HEADERS_sub_hourly.txt&quot;, # load headers file header=1, # skip the first [0] line delim_whitespace=True ) df.columns = headers.columns # rename df columns with headers columns # LST = local standard time df[&quot;LST_TIME&quot;] = [f&quot;{x:04d}&quot; for x in df[&quot;LST_TIME&quot;]] # time needs padding of zeros, then convert to string df[&#39;LST_DATE&#39;] = df[&#39;LST_DATE&#39;].astype(str) # convert date into string df[&#39;datetime&#39;] = df[&#39;LST_DATE&#39;] + &#39; &#39; + df[&#39;LST_TIME&#39;] # combine date+time into datetime df[&#39;datetime&#39;] = pd.to_datetime(df[&#39;datetime&#39;]) # interpret datetime df = df.set_index(&#39;datetime&#39;) # make datetime the index df .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/02/assignment-02-ET.html",
            "relUrl": "/jupyter/2020/02/02/assignment-02-ET.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post37": {
            "title": "Introduction - lecture",
            "content": "Sources . Sources used: . (USGS, 2019) . How much water is there? Where? . . Source: usgs.gov . Source: usgs.gov The water cycle . . Global water distribution . Water source Volume (km$^3$) % of freshwater % of total water . Oceans, Seas, &amp; Bays | 1,338,000,000 | – | 96.54 | . Ice caps, Glaciers,&amp; Permanent Snow | 24,064,000 | 68.7 | 1.74 | . Groundwater | 23,400,000 | – | 1.69 | . $ quad$Fresh | 10,530,000 | 30.1 | 0.76 | . $ quad$Saline | 12,870,000 | – | 0.93 | . Soil Moisture | 16,500 | 0.05 | 0.001 | . Ground Ice&amp; Permafrost | 300,000 | 0.86 | 0.022 | . Lakes | 176,400 | – | 0.013 | . $ quad$Fresh | 91,000 | 0.26 | 0.007 | . $ quad$Saline | 85,400 | – | 0.006 | . Atmosphere | 12,900 | 0.04 | 0.001 | . Swamp Water | 11,470 | 0.03 | 0.0008 | . Rivers | 2,120 | 0.006 | 0.0002 | . Biological Water | 1,120 | 0.003 | 0.0001 | . * (Percents are rounded, so will not add to 100) https://www.usgs.gov/special-topic/water-science-school/science/fundamentals-water-cycle . Energy drives the hydrologic cycle . A key aspect of the hydrologic cycle is the fact that it is driven by energy inputs (primarily from the sun). At the global scale, the system is essentially closed with respect to water; negligible water is entering or leaving the system. In other words, there is no external forcing in terms of a water flux. Systems with no external forcing will generally eventually come to an equilibrium state. So what makes the hydrologic cycle so dynamic? The solar radiative energy input, which is external to the system, drives the hydrologic cycle. Averaged over the globe, 342 W m$^{-2}$ of solar radiative energy is being continuously input to the system at the top of the atmosphere. This energy input must be dissipated, and this is done, to a large extent, via the hydrologic cycle. Due to this fact, the study of hydrology is not isolated to the study of water storage and movement, but also must often include study of energy storage and movements. . Margulis, 2017, “Introduction to Hydrology” . Components of the water cycle . Water storage in oceans . Evaporation / Sublimation . Evaporation $ longrightarrow$ cooling . . . . . Evapotranspiration . . Water storage in the atmosphere . Cumulonimbus cloud over Africa . Picture of cumulonimbus taken from the International Space Station, over western Africa near the Senegal-Mali border. . If all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters. . amount of water in the atmosphereV=12 900 km3surface of EarthS=4πR2;R=6371 kmV=S×hheighth=VS≃2.5 cm begin{align} text{amount of water in the atmosphere} &amp; qquad V = 12 , 900 , text{km}^3 text{surface of Earth} &amp; qquad S = 4 pi R^2; quad R=6371 , text{km} &amp; qquad V = S times h text{height} &amp; qquad h = frac{V}{S} simeq 2.5 , text{cm} end{align}amount of water in the atmospheresurface of Earthheight​V=12900km3S=4πR2;R=6371kmV=S×hh=SV​≃2.5cm​​ . Try to calculate this yourself, and click on the button below to check how to do it. . Show/Hide Code . # amount of water in the atmosphere V = 12900 # km^3 # Earth&#39;s radius R = 6371 # km # surface of Earth = 4 pi Rˆ2 S = 4 * 3.141592 * R**2 # Volume: V = S * h, therefore # height h = V / S # in km h_cm = h * 1e5 # in cm print(f&quot;The height would be ~ {h_cm:.1f} cm&quot;) . Condensation . Precipitation . .   Intensity (cm/h) Median diameter (mm) Velocity of fall (m/s) Drops s$^{-1}$ m$^{-2}$ . Fog | 0.013 | 0.01 | 0.003 | 67,425,000 | . Mist | 0.005 | 0.1 | 0.21 | 27,000 | . Drizzle | 0.025 | 0.96 | 4.1 | 151 | . Light rain | 0.10 | 1.24 | 4.8 | 280 | . Moderate rain | 0.38 | 1.60 | 5.7 | 495 | . Heavy rain | 1.52 | 2.05 | 6.7 | 495 | . Excessive rain | 4.06 | 2.40 | 7.3 | 818 | . Cloudburst | 10.2 | 2.85 | 7.9 | 1,220 | . Source: https://www.usgs.gov/special-topic/water-science-school/science/precipitation-and-water-cycle . Water storage in ice and snow . . . Snowmelt runoff to streams . Surface runoff . . . Streamflow . The Mississippi river basin is very large . The Amazon river basin is Huge . . Lakes and rivers . . Lake Malawi . . Infiltration . . Groundwater storage . . . . Center Pivot irrigation in Nebraska taps the Ogallala Aquifer. . Groundwater flow and discharge . . . . Spring . Ein Gedi . . Source: haaretz.com . Source: usgs.gov References . USGS, 2019. How Much Water is There on Earth? |",
            "url": "https://yairmau.github.io/website/markdown/2020/02/01/introduction-lecture.html",
            "relUrl": "/markdown/2020/02/01/introduction-lecture.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post38": {
            "title": "let's have fun plotting some data 😀",
            "content": "download the data . Go to the Faculty of Agriculture&#39;s weather station. | Click on משיכת נתונים and download data for 1 September to 28 February, with a 24h interval. Call it data-sep2020-feb2021. You can download an example file here. | Open the .csv file with Excel, see how it looks like | import packages . We need to import this data into python. First we import useful packages. Type (don&#39;t copy and paste) the following lines in the code cell below: . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) . import data with pandas . Import data from csv and put it in a pandas dataframe (a table). Make line 5 the header (column names) . df = pd.read_csv(&quot;data-sep2020-feb2021.csv&quot;, header=[4]) df . rename columns . rename the columns to: date, tmax, tmin, wind, rain24h, rain_cumulative . df.columns = [&#39;date&#39;, &#39;tmax&#39;, &#39;tmin&#39;, &#39;wind&#39;, &#39;rain24h&#39;, &#39;rain_cumulative&#39;] df . a first plot! . plot the minimum temperature: . plt.plot(df[&#39;tmin&#39;]) . how to deal with dates . We want the dates to appear on the horizontal axis. Interpret &#39;date&#39; column as a pandas datetime, see how it looks different from before before: 01/09/20 after: 2020-09-01 . df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;], dayfirst=True) df . date as dataframe index . Make &#39;date&#39; the dataframe&#39;s index . df = df.set_index(&#39;date&#39;) df . plot again, now with dates . Plot minimum temperature, now we have dates on the horizontal axis . plt.plot(df[&#39;tmin&#39;]) . we&#39;re getting there! the graph could look better . Let&#39;s make the graph look better: labels, title, slanted dates, etc . %matplotlib notebook # creates figure (the canvas) and the axis (rectangle where the plot sits) fig, ax = plt.subplots(1, figsize=(10,7)) # two line plots ax.plot(df[&#39;tmin&#39;], color=&quot;red&quot;, label=&quot;Temp (min)&quot;) ax.plot(df[&#39;tmax&#39;], color=&quot;blue&quot;, label=&quot;Temp (max)&quot;) # axes labels and figure title ax.set_xlabel(&#39;date&#39;) ax.set_ylabel(&#39;temperature (°C)&#39;) ax.set_title(&#39;maximum and minimum temperatures&#39;) # some ticks adjustments ax.set_yticks([10,15,20,25]) # we can choose where to put ticks ax.grid(axis=&#39;y&#39;) # makes horizontal lines plt.gcf().autofmt_xdate() # makes slated dates # legend ax.legend(loc=&#39;upper right&#39;) # save png figure plt.savefig(&quot;temp_max_min.png&quot;) . make the following figure . Use the following function to plot bars for daily rainfall . ax.bar(x_array, y_array) . Can you write yourself some lines of code that calculate the cumulative rainfall from the daily rainfall? . . double click this markdown cell to reveal the code I used to produce the figure. Don&#39;t do this right away, try to go as far as you can! | . make another figure . In order to choose just a part of the time series, you can use the following: . start_date = &#39;2021-01-01&#39; end_date = &#39;2021-01-31&#39; january = df[start_date:end_date] . . double click this markdown cell to reveal the code I used to produce the figure. Don&#39;t do this right away, try to go as far as you can! | . one last figure for today . Use the following code to create histograms with user-defined bins: . b = np.arange(0, 56, 5) # bins from 0 to 55, width = 5 ax.hist(df[&#39;wind&#39;], bins=b, density=True) . Play with the bins, see what happens. What does density=True do? . . double click this markdown cell to reveal the code I used to produce the figure. Don&#39;t do this right away, try to go as far as you can! | . homework . Go back to the weather station website, download one year of data from 01.01.2020 to 31.12.2020 (24h data). Make the following graph: . daily tmax and tmin | smoothed data for tmax and tmin | . In order to smooth the data with a 30 day window, use the following function: df[&#39;tmin&#39;].rolling(30, center=True).mean() This means that you will take the mean of 30 days, and put the result in the center of this 30-day window. . Play with this function, see what you can do with it. What happens when you change the size of the window? Why is the smoothed data shorter than the original data? See the documentation for rolling to find more options. . . double click this markdown cell to reveal the code I used to produce the figure. Don&#39;t do this right away, try to go as far as you can! | .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/01/python-intro.html",
            "relUrl": "/jupyter/2020/02/01/python-intro.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post39": {
            "title": "Hydrology --- introduction",
            "content": "How much water is there? Where? . . . The water cycle . Global water distribution . Water source Volume (km$^3$) % of freshwater % of total water . Oceans, Seas, &amp; Bays | 1,338,000,000 | -- | 96.54 | . Ice caps, Glaciers,&amp; Permanent Snow | 24,064,000 | 68.7 | 1.74 | . Groundwater | 23,400,000 | -- | 1.69 | . $ quad$Fresh | 10,530,000 | 30.1 | 0.76 | . $ quad$Saline | 12,870,000 | -- | 0.93 | . Soil Moisture | 16,500 | 0.05 | 0.001 | . Ground Ice&amp; Permafrost | 300,000 | 0.86 | 0.022 | . Lakes | 176,400 | -- | 0.013 | . $ quad$Fresh | 91,000 | 0.26 | 0.007 | . $ quad$Saline | 85,400 | -- | 0.006 | . Atmosphere | 12,900 | 0.04 | 0.001 | . Swamp Water | 11,470 | 0.03 | 0.0008 | . Rivers | 2,120 | 0.006 | 0.0002 | . Biological Water | 1,120 | 0.003 | 0.0001 | . * (Percents are rounded, so will not add to 100) https://www.usgs.gov/special-topic/water-science-school/science/fundamentals-water-cycle . Energy drives the hydrologic cycle . A key aspect of the hydrologic cycle is the fact that it is driven by energy inputs (primarily from the sun). At the global scale, the system is essentially closed with respect to water; negligible water is entering or leaving the system. In other words, there is no external forcing in terms of a water flux. Systems with no external forcing will generally eventually come to an equilibrium state. So what makes the hydrologic cycle so dynamic? The solar radiative energy input, which is external to the system, drives the hydrologic cycle. Averaged over the globe, 342 W m$^{-2}$ of solar radiative energy is being continuously input to the system at the top of the atmosphere. This energy input must be dissipated, and this is done, to a large extent, via the hydrologic cycle. Due to this fact, the study of hydrology is not isolated to the study of water storage and movement, but also must often include study of energy storage and movements. . Margulis, 2017, &quot;Introduction to Hydrology&quot; . Components of the water cycle . Water storage in oceans . Evaporation / Sublimation . Evaporation $ longrightarrow$ cooling . . . . . Evapotranspiration . Water storage in the atmosphere . Cumulonimbus cloud over Africa . Picture of cumulonimbus taken from the International Space Station, over western Africa near the Senegal-Mali border. . If all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters. $$ begin{align} text{amount of water in the atmosphere} &amp; qquad V = 12 , 900 , text{km}^3 text{surface of Earth} &amp; qquad S = 4 pi R^2; quad R=6371 , text{km} &amp; qquad V = S times h text{height} &amp; qquad h = frac{V}{S} simeq 2.5 , text{cm} end{align} $$ . Try to calculate this yourself, and click on the button below to check how to do it. . # amount of water in the atmosphere V = 12900 # km^3 # Earth&#39;s radius R = 6371 # km # surface of Earth = 4 pi Rˆ2 S = 4 * 3.141592 * R**2 # Volume: V = S * h, therefore # height h = V / S # in km h_cm = h * 1e5 # in cm print(f&quot;The height would be ~ {h_cm:.1f} cm&quot;) . . The height would be ~ 2.5 cm . Condensation . Precipitation . Intensity (cm/h) Median diameter (mm) Velocity of fall (m/s) Drops s$^{-1}$ m$^{-2}$ . Fog | 0.013 | 0.01 | 0.003 | 67,425,000 | . Mist | 0.005 | 0.1 | 0.21 | 27,000 | . Drizzle | 0.025 | 0.96 | 4.1 | 151 | . Light rain | 0.10 | 1.24 | 4.8 | 280 | . Moderate rain | 0.38 | 1.60 | 5.7 | 495 | . Heavy rain | 1.52 | 2.05 | 6.7 | 495 | . Excessive rain | 4.06 | 2.40 | 7.3 | 818 | . Cloudburst | 10.2 | 2.85 | 7.9 | 1,220 | . Source: https://www.usgs.gov/special-topic/water-science-school/science/precipitation-and-water-cycle . Water storage in ice and snow . . Snowmelt runoff to streams . Surface runoff . . Streamflow . The Mississippi river basin is very large . The Amazon river basin is Huge . . Lakes and rivers . Lake Malawi . . Infiltration . Groundwater storage . . . Center Pivot irrigation in Nebraska taps the Ogallala Aquifer. . Groundwater flow and discharge . . . Spring . Ein Gedi . Thousand Springs, Idaho .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/01/introduction.html",
            "relUrl": "/jupyter/2020/02/01/introduction.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post40": {
            "title": "Hydrology --- introduction",
            "content": "How much water is there? Where? . . . The water cycle . Global water distribution . Water source Volume (km$^3$) % of freshwater % of total water . Oceans, Seas, &amp; Bays | 1,338,000,000 | -- | 96.54 | . Ice caps, Glaciers,&amp; Permanent Snow | 24,064,000 | 68.7 | 1.74 | . Groundwater | 23,400,000 | -- | 1.69 | . $ quad$Fresh | 10,530,000 | 30.1 | 0.76 | . $ quad$Saline | 12,870,000 | -- | 0.93 | . Soil Moisture | 16,500 | 0.05 | 0.001 | . Ground Ice&amp; Permafrost | 300,000 | 0.86 | 0.022 | . Lakes | 176,400 | -- | 0.013 | . $ quad$Fresh | 91,000 | 0.26 | 0.007 | . $ quad$Saline | 85,400 | -- | 0.006 | . Atmosphere | 12,900 | 0.04 | 0.001 | . Swamp Water | 11,470 | 0.03 | 0.0008 | . Rivers | 2,120 | 0.006 | 0.0002 | . Biological Water | 1,120 | 0.003 | 0.0001 | . * (Percents are rounded, so will not add to 100) https://www.usgs.gov/special-topic/water-science-school/science/fundamentals-water-cycle . Energy drives the hydrologic cycle . A key aspect of the hydrologic cycle is the fact that it is driven by energy inputs (primarily from the sun). At the global scale, the system is essentially closed with respect to water; negligible water is entering or leaving the system. In other words, there is no external forcing in terms of a water flux. Systems with no external forcing will generally eventually come to an equilibrium state. So what makes the hydrologic cycle so dynamic? The solar radiative energy input, which is external to the system, drives the hydrologic cycle. Averaged over the globe, 342 W m$^{-2}$ of solar radiative energy is being continuously input to the system at the top of the atmosphere. This energy input must be dissipated, and this is done, to a large extent, via the hydrologic cycle. Due to this fact, the study of hydrology is not isolated to the study of water storage and movement, but also must often include study of energy storage and movements. . Margulis, 2017, &quot;Introduction to Hydrology&quot; . Components of the water cycle . Water storage in oceans . Evaporation / Sublimation . Evaporation $ longrightarrow$ cooling . . . . . Evapotranspiration . Water storage in the atmosphere . Cumulonimbus cloud over Africa . Picture of cumulonimbus taken from the International Space Station, over western Africa near the Senegal-Mali border. . If all of the water in the atmosphere rained down at once, it would only cover the globe to a depth of 2.5 centimeters. $$ begin{align} text{amount of water in the atmosphere} &amp; qquad V = 12 , 900 , text{km}^3 text{surface of Earth} &amp; qquad S = 4 pi R^2; quad R=6371 , text{km} &amp; qquad V = S times h text{height} &amp; qquad h = frac{V}{S} simeq 2.5 , text{cm} end{align} $$ . Try to calculate this yourself, and click on the button below to check how to do it. . # amount of water in the atmosphere V = 12900 # km^3 # Earth&#39;s radius R = 6371 # km # surface of Earth = 4 pi Rˆ2 S = 4 * 3.141592 * R**2 # Volume: V = S * h, therefore # height h = V / S # in km h_cm = h * 1e5 # in cm print(f&quot;The height would be ~ {h_cm:.1f} cm&quot;) . . The height would be ~ 2.5 cm . Condensation . Precipitation . Intensity (cm/h) Median diameter (mm) Velocity of fall (m/s) Drops s$^{-1}$ m$^{-2}$ . Fog | 0.013 | 0.01 | 0.003 | 67,425,000 | . Mist | 0.005 | 0.1 | 0.21 | 27,000 | . Drizzle | 0.025 | 0.96 | 4.1 | 151 | . Light rain | 0.10 | 1.24 | 4.8 | 280 | . Moderate rain | 0.38 | 1.60 | 5.7 | 495 | . Heavy rain | 1.52 | 2.05 | 6.7 | 495 | . Excessive rain | 4.06 | 2.40 | 7.3 | 818 | . Cloudburst | 10.2 | 2.85 | 7.9 | 1,220 | . Source: https://www.usgs.gov/special-topic/water-science-school/science/precipitation-and-water-cycle . Water storage in ice and snow . . Snowmelt runoff to streams . Surface runoff . . Streamflow . The Mississippi river basin is very large . The Amazon river basin is Huge . . Lakes and rivers . Lake Malawi . . Infiltration . Groundwater storage . . . Center Pivot irrigation in Nebraska taps the Ogallala Aquifer. . Groundwater flow and discharge . . . Spring . Ein Gedi . Thousand Springs, Idaho .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/01/introduction-lecture.html",
            "relUrl": "/jupyter/2020/02/01/introduction-lecture.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post41": {
            "title": "Introduction - some first exercises in python",
            "content": "let&#39;s have fun plotting some data &#128512; . download the data . Go to the Faculty of Agriculture&#39;s weather station. | Click on משיכת נתונים and download data for 1 September to 28 February, with a 24h interval. Call it data-sep2020-feb2021 | Open the .csv file with Excel, see how it looks like | If you can&#39;t download the data, just click here. | import packages . We need to import this data into python. First we import useful packages. Type (don&#39;t copy and paste) the following lines in the code cell below. . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns sns.set(style=&quot;ticks&quot;, font_scale=1.5) . . import data with pandas . Import data from csv and put it in a pandas dataframe (a table). Make line 5 the header (column names) . df = pd.read_csv(&quot;data-sep2020-feb2021.csv&quot;, header=[4]) df . . Unnamed: 0 �C �C.1 km/h mm mm.1 . 0 01/09/20 | 32.8 | 25.3 | 29.7 | 0.0 | 0.0 | . 1 02/09/20 | 33.0 | 24.0 | 28.8 | 0.0 | 0.0 | . 2 03/09/20 | 34.2 | 23.8 | 31.6 | 0.0 | 0.0 | . 3 04/09/20 | 36.3 | 27.3 | 24.2 | 0.0 | 0.0 | . 4 05/09/20 | 34.2 | 26.3 | 22.4 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | ... | . 176 24/02/21 | 20.6 | 9.9 | 28.8 | 0.0 | 481.7 | . 177 25/02/21 | 19.4 | 9.3 | 23.3 | 0.0 | 481.7 | . 178 26/02/21 | 21.3 | 8.0 | 24.2 | 0.1 | 481.8 | . 179 27/02/21 | 23.4 | 9.2 | 30.6 | 0.0 | 481.8 | . 180 28/02/21 | 19.7 | 9.2 | 22.4 | 0.0 | 481.8 | . 181 rows × 6 columns . rename columns . rename the columns to: date, tmax, tmin, wind, rain24h, rain_cumulative . df.columns = [&#39;date&#39;, &#39;tmax&#39;, &#39;tmin&#39;, &#39;wind&#39;, &#39;rain24h&#39;, &#39;rain_cumulative&#39;] df . . date tmax tmin wind rain24h rain_cumulative . 0 01/09/20 | 32.8 | 25.3 | 29.7 | 0.0 | 0.0 | . 1 02/09/20 | 33.0 | 24.0 | 28.8 | 0.0 | 0.0 | . 2 03/09/20 | 34.2 | 23.8 | 31.6 | 0.0 | 0.0 | . 3 04/09/20 | 36.3 | 27.3 | 24.2 | 0.0 | 0.0 | . 4 05/09/20 | 34.2 | 26.3 | 22.4 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | ... | . 176 24/02/21 | 20.6 | 9.9 | 28.8 | 0.0 | 481.7 | . 177 25/02/21 | 19.4 | 9.3 | 23.3 | 0.0 | 481.7 | . 178 26/02/21 | 21.3 | 8.0 | 24.2 | 0.1 | 481.8 | . 179 27/02/21 | 23.4 | 9.2 | 30.6 | 0.0 | 481.8 | . 180 28/02/21 | 19.7 | 9.2 | 22.4 | 0.0 | 481.8 | . 181 rows × 6 columns . a first plot! . plot the minimum temperature: . plt.plot(df[&#39;tmin&#39;]) . . [&lt;matplotlib.lines.Line2D at 0x7fd02954bbd0&gt;] . how to deal with dates . We want the dates to appear on the horizontal axis. Interpret &#39;date&#39; column as a pandas datetime, see how it looks different from before before: 01/09/20 after: 2020-09-01 . df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;], dayfirst=True) df . . date tmax tmin wind rain24h rain_cumulative . 0 2020-09-01 | 32.8 | 25.3 | 29.7 | 0.0 | 0.0 | . 1 2020-09-02 | 33.0 | 24.0 | 28.8 | 0.0 | 0.0 | . 2 2020-09-03 | 34.2 | 23.8 | 31.6 | 0.0 | 0.0 | . 3 2020-09-04 | 36.3 | 27.3 | 24.2 | 0.0 | 0.0 | . 4 2020-09-05 | 34.2 | 26.3 | 22.4 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | ... | . 176 2021-02-24 | 20.6 | 9.9 | 28.8 | 0.0 | 481.7 | . 177 2021-02-25 | 19.4 | 9.3 | 23.3 | 0.0 | 481.7 | . 178 2021-02-26 | 21.3 | 8.0 | 24.2 | 0.1 | 481.8 | . 179 2021-02-27 | 23.4 | 9.2 | 30.6 | 0.0 | 481.8 | . 180 2021-02-28 | 19.7 | 9.2 | 22.4 | 0.0 | 481.8 | . 181 rows × 6 columns . date as dataframe index . Make &#39;date&#39; the dataframe&#39;s index (leftmost column, but not really a column!) . df = df.set_index(&#39;date&#39;) df . . tmax tmin wind rain24h rain_cumulative . date . 2020-09-01 32.8 | 25.3 | 29.7 | 0.0 | 0.0 | . 2020-09-02 33.0 | 24.0 | 28.8 | 0.0 | 0.0 | . 2020-09-03 34.2 | 23.8 | 31.6 | 0.0 | 0.0 | . 2020-09-04 36.3 | 27.3 | 24.2 | 0.0 | 0.0 | . 2020-09-05 34.2 | 26.3 | 22.4 | 0.0 | 0.0 | . ... ... | ... | ... | ... | ... | . 2021-02-24 20.6 | 9.9 | 28.8 | 0.0 | 481.7 | . 2021-02-25 19.4 | 9.3 | 23.3 | 0.0 | 481.7 | . 2021-02-26 21.3 | 8.0 | 24.2 | 0.1 | 481.8 | . 2021-02-27 23.4 | 9.2 | 30.6 | 0.0 | 481.8 | . 2021-02-28 19.7 | 9.2 | 22.4 | 0.0 | 481.8 | . 181 rows × 5 columns . plot again, now with dates . Plot minimum temperature, now we have dates on the horizontal axis . plt.plot(df[&#39;tmin&#39;]) . . [&lt;matplotlib.lines.Line2D at 0x7fd0795aa190&gt;] . we&#39;re getting there! the graph could look better . Let&#39;s make the graph look better: labels, title, slanted dates, etc . # creates figure (the canvas) and the axis (rectangle where the plot sits) fig, ax = plt.subplots(1, figsize=(10,7)) # two line plots ax.plot(df[&#39;tmin&#39;], color=&quot;red&quot;, label=&quot;Temp (min)&quot;) ax.plot(df[&#39;tmax&#39;], color=&quot;blue&quot;, label=&quot;Temp (max)&quot;) # axes labels and figure title ax.set_xlabel(&#39;date&#39;) ax.set_ylabel(&#39;temperature (°C)&#39;) ax.set_title(&#39;maximum and minimum temperatures&#39;) # some ticks adjustments ax.set_yticks([10,15,20,25]) # we can choose where to put ticks ax.grid(axis=&#39;y&#39;) # makes horizontal lines plt.gcf().autofmt_xdate() # makes slated dates # legend ax.legend(loc=&#39;upper right&#39;) # save png figure plt.savefig(&quot;temp_max_min.png&quot;) . . make the following figure . Use the following function to plot bars for daily rainfall . ax.bar(x_array, y_array) . Can you write yourself some lines of code that calculate the cumulative rainfall from the daily rainfall? . # creates figure (the canvas) and the axis (rectangle where the plot sits) fig, ax = plt.subplots(1, figsize=(10,7)) # line and bar plots ax.bar(df.index, df[&#39;rain24h&#39;], color=&quot;blue&quot;, label=&quot;daily rainfall&quot;) # there are many ways of calculating the cumulative rain # method 1, use a for loop: # rain = df[&#39;rain24h&#39;].to_numpy() # cumulative = rain * 0 # for i in range(len(rain)): # cumulative[i] = np.sum(rain[:i]) # df[&#39;cumulative1&#39;] = cumulative # method 2, use list comprehension: # rain = df[&#39;rain24h&#39;].to_numpy() # cumulative = [np.sum(rain[:i]) for i in range(len(rain))] # df[&#39;cumulative2&#39;] = cumulative # method 3, use existing functions: df[&#39;cumulative3&#39;] = np.cumsum(df[&#39;rain24h&#39;]) ax.plot(df[&#39;cumulative3&#39;], color=&quot;red&quot;, label=&quot;cumulative rainfall&quot;) # compare our cumulative rainfall with the downloaded data # ax.plot(df[&#39;rain_cumulative&#39;], &#39;x&#39;) # axes labels and figure title ax.set_xlabel(&#39;date&#39;) ax.set_ylabel(&#39;rainfall (mm)&#39;) ax.set_title(&#39;daily and cumulative rainfall&#39;) ax.set_xlim([&#39;2020-11-01&#39;,&#39;2021-02-28&#39;]) # some ticks adjustments plt.gcf().autofmt_xdate() # makes slated dates # legend ax.legend(loc=&#39;upper left&#39;) # save png figure plt.savefig(&quot;cumulative_rainfall.png&quot;) . . make another figure . In order to choose just a part of the time series, you can use the following: . start_date = &#39;2021-01-01&#39; end_date = &#39;2021-01-31&#39; january = df[start_date:end_date] . # creates figure (the canvas) and the axis (rectangle where the plot sits) fig, ax = plt.subplots(1, figsize=(10,7)) # define date range start_date = &#39;2021-01-01&#39; end_date = &#39;2021-01-31&#39; january = df[start_date:end_date][&#39;tmax&#39;] # plots ax.plot(january, color=&quot;red&quot;, label=&quot;daily max&quot;) ax.plot(january*0 + january.mean(), color=&quot;purple&quot;, linestyle=&quot;--&quot;, label=&quot;average daily max&quot;) # axes labels and figure title ax.set_xlabel(&#39;date&#39;) ax.set_ylabel(&#39;temperature (°C)&#39;) ax.set_title(&#39;average daily maximum temperature for January 2021&#39;) # some ticks adjustments plt.gcf().autofmt_xdate() # makes slated dates # legend ax.legend(loc=&#39;lower left&#39;) # save png figure plt.savefig(&quot;average_max_temp.png&quot;) . . one last figure for today . Use the following code to create histograms with user-defined bins: . b = np.arange(0, 56, 5) # bins from 0 to 55, width = 5 ax.hist(df[&#39;wind&#39;], bins=b, density=True) . Play with the bins, see what happens. What does density=True do? . # creates figure (the canvas) and the axis (rectangle where the plot sits) fig, ax = plt.subplots(1, figsize=(10,7)) # histogram b = np.arange(0, 56, 5) # bins from 0 to 55, width = 5 ax.hist(df[&#39;wind&#39;], bins=b, density=True) # axes labels and figure title ax.set_xlabel(&#39;max wind speed (km/h)&#39;) ax.set_ylabel(&#39;frequency&#39;) ax.set_title(&#39;frequency of maximum wind speed&#39;) # save png figure plt.savefig(&quot;wind-histogram.png&quot;) . . homework . Go back to the weather station website, download one year of data from 01.01.2020 to 31.12.2020 (24h data). If you can&#39;t download the data, just click here. Make the following graph: . daily tmax and tmin | smoothed data for tmax and tmin | . In order to smooth the data with a 30 day window, use the following function: df[&#39;tmin&#39;].rolling(30, center=True).mean() This means that you will take the mean of 30 days, and put the result in the center of this 30-day window. . Play with this function, see what you can do with it. What happens when you change the size of the window? Why is the smoothed data shorter than the original data? See the documentation for rolling to find more options. . fig, ax = plt.subplots(figsize=(10,7)) df2 = pd.read_csv(&quot;1year.csv&quot;, header=[4]) df2[&#39;date&#39;] = pd.to_datetime(df2[&#39;date&#39;], dayfirst=True) df2 = df2.set_index(&#39;date&#39;) plt.plot(df2[&#39;tmax&#39;], label=&#39;tmax&#39;, color=&quot;tab:red&quot;) plt.plot(df2[&#39;tmin&#39;], label=&#39;tmin&#39;, color=&quot;tab:blue&quot;) tmin_smooth = df2[&#39;tmin&#39;].rolling(30, center=True).mean() tmax_smooth = df2[&#39;tmax&#39;].rolling(30, center=True).mean() plt.plot(tmax_smooth, label=&#39;tmax smoothed&#39;, color=&quot;tab:pink&quot;, linestyle=&quot;--&quot;, linewidth=3) plt.plot(tmin_smooth, label=&#39;tmin smoothed&#39;, color=&quot;tab:cyan&quot;, linestyle=&quot;--&quot;, linewidth=3) plt.legend() plt.savefig(&quot;t_smoothed.png&quot;) . .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/01/introduction-exercises.html",
            "relUrl": "/jupyter/2020/02/01/introduction-exercises.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post42": {
            "title": "Final Assignment",
            "content": "&#128210; instructions . This is where learning happens, not during a lecture. You&#39;ll learn a ton of things by doing them yourself. Much success! 😄 . Create two Jupyter Notebooks called . assignment-FINAL-CODE-IDNUMBER, and | assignment-FINAL-REPORT-IDNUMBER, where IDNUMBER is your 9-digit ID. These are the only files we will check. | &#128204; locations and data . Choose one location in the US. . Download relevant data from NOAA&#39;s Global Summary of the Month, NOAA&#39;s Climate Reference Network Data, and from the USGS&#39;s National Water Information System. . Try to find locations with many years of data, the more the better. Take some time to choose your station, plan well. Choose a location you have not worked with in past assignments. . &#128736; tasks . In this final project, we will integrate the various topics we learned throughout the semester. You will tell a story about the location you chose, and describe the changes it experienced in the past many decades. You can focus on any kind of changes that would influence the hydrological fluxes we learned about. Here are a few examples of changes that you might work on: . severe droughts in part of the studied period, or an increasing trend in drought severity. | same as above for rainfall/floods, high temperatures, low temperatures, etc. | significant changes in land use, such as urbanization, deforestation, agricultural practices, etc. | . The list above is not comprehensive, you can choose other factors. Consult with me in case of doubt. . Try to find on the media and in scientific papers evidence for the change you are focusing on. Cite these sources: at least one peer-reviewed scientific paper, and at least 3 other sources, such as a government website, official weather sites, books, reputable news websites, etc. . Can you see the same when analyzing data for the location you chose? Do your findings corroborate the expectation you had when you started this project? If they don&#39;t, can you explain why? Did you reach interesting or surprising conclusions in your analysis? . Analyze your location&#39;s history with respect to the following: . Precipitation: seasonality, inter-annual variability, extreme precipitation events and return periods. | Potential evapotranspiration: Calculate PET using Penman&#39;s equation for at least three different years of interest (not necessarily contiguous years). Calculate Thornthwaite&#39;s PET for the whole length of the available data (comment about the suitability of Thornthwaite&#39;s PET to the location you chose). | Analyze streamflow statistics in a similar manner as for precipitation: extreme discharge events and return periods. | Use Budyko&#39;s framework to calculate where the location you chose falls on the $(ET/P,PET/P)$ space for at least three different years of interest. | . Try to connect the dots: how do your different findings fit together? Discuss what you are trying to show, tell your story with the help of the data and your analyses. If you find things that go contrary to your expectations, can you raise hypotheses of why you see what you see? . You will have one month to hand in your project. Much success! 😁 . &#127749; presentation . All the assignment must be in two Jupyter Notebooks. . The notebook called CODE will contain all the code for the analyses you made. It must be fully functional, i.e., we must be able to Run All and not get any errors. Explain what you are doing in each step. Comment your code. Use markdown cells to split the notebook into subsections, one for each analysis (e.g.: ## Precipitation Analysis, ### Inter-annual variability, etc). . The notebook called Report will contain graphs and relevant data from the CODE notebook. It is here where you will introduce the location you chose, what you are trying to see. Here you will write all the results and discussion, as supported by the graphs and results you produced. Divide this notebook into sections: Introduction, Results and Discussion, Conclusion. Subdivide the sections into subsections when needed. In this file there should be no code at all. . You can write in English or in Hebrew, but the text in the figures must be in English. If you choose to write the discussion in Hebrew, be aware that Jupyter Notebooks don&#39;t have native right-to-left language support: . ניתן לכתוב בעברית, למרות שזה לא נראה כ״כ טוב... . You can use some HTML code to achieve best results in Hebrew. Type the following . &lt;p dir=&quot;rtl&quot; style=&quot;text-align: right;&quot;&gt; עכשיו הרבה יותר טוב! &lt;/p&gt; . to get . עכשיו הרבה יותר טוב! . If you have many paragraphs in hebrew, do the following: . פסקה מספר 1. . פסקה מספר 2. . אם יש לכם כמה פסקאות, כל אחת מהן תהיה בתוך &quot;dir&quot; משלה . In my opinion it is too complicated to write in Hebrew in Jupyter Notebooks, just write in English, your grade will not be affected by typos nor less-than-perfect English proficiency. . &#128175; evaluation . Your assignment will be evaluated according to the following criteria: . 40% Presentation. How the graphs look, labels, general organization, markdown, clean code. | 30% Discussion. This is where you explain what you did, what you found out, etc. | 15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration. | 10% Replicability: Your code runs flawlessly. | 5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself! | . &#128666; importing the data . You can use the code from previous assignments and from the exercise lectures. .",
            "url": "https://yairmau.github.io/website/jupyter/2020/02/01/assignment-FINAL.html",
            "relUrl": "/jupyter/2020/02/01/assignment-FINAL.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post43": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://yairmau.github.io/website/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post44": {
            "title": "This website's logo",
            "content": ". Introduction . This will only work if you have Mathematica installed in your machine. Python can interface with Wolfram Mathematica, taking advantage of its awesome power. . The curve inside the square is a parabola: $$ y = ax^2 + bx + c $$ . This parabola passes through the points $(0.3, 0)$ and $(1, 1)$, and it&#39;s derivative at $(0.3, 0)$ is zero. We use Mathematica to figure out what are the parameters $a,b,c$. Finally, we transpose the line when plotting, i.e., $x$ is in the vertical axis, and $y$ is in the horizontal axis. . The code . %matplotlib inline import matplotlib.pyplot as plt import numpy as np from wolframclient.language import wl from wolframclient.evaluation import WolframLanguageSession from wolframclient.language import wl, wlexpr w = 20 plt.rc(&#39;axes&#39;, linewidth=w) fig=plt.figure(1, (5, 5)) fig.subplots_adjust(left=0.0, right=1.0, top=1.0, bottom=0.0, hspace=0, wspace=0) ax = plt.Axes(fig, [0., 0., 1., 1.]) fig.add_axes(ax) session = WolframLanguageSession() session.evaluate(wlexpr(&#39;y[x_] := a x^2 + b x + c&#39;)) session.evaluate(wlexpr(&#39;p1 = {0.3, 0}&#39;)) session.evaluate(wlexpr(&#39;p2 = {1, 1}&#39;)) session.evaluate(wlexpr(&#39;sol1 = Solve[ {y[p1[[1]]] == p1[[2]], y[p2[[1]]] == p2[[2]]}, {a, b, c}][[1]]&#39;)) session.evaluate(wlexpr(&#39;sol2 = Solve[(D[(y[x] /. sol1), x] /. x -&gt; 0.3) == 0, a][[1]]&#39;)) par = list(session.evaluate(wlexpr(&#39;{a, b, c} /. sol1 /. sol2&#39;))) x0 = 0.3 x=np.linspace(x0, 1, 1001) a, b, c = par# [2.08163, -1.24898, 0.167347] y = lambda x: a*x**2 + b*x + c c1 = &#39;white&#39; # bottom right c2 = &#39;white&#39; # top left # c1 = &#39;#6c7053&#39; # bottom right # c2 = &#39;#6e0014&#39; # top left # ax.fill_between(y(x), x, y2=0, facecolor=c1, # edgecolor=&#39;black&#39;) # bottom right # ax.fill_between(y(x), x, y2=1, facecolor=c2, # edgecolor=&quot;black&quot;, linewidth=10) # top left ax.plot(y(x), x, color=&quot;black&quot;, lw=w) ax.set_xlim([0,1]) ax.set_ylim([0,1]) ax.set_xticks([]) ax.set_yticks([]) fig.savefig(&quot;./python_figures/site-logo.png&quot;, resolution=600, transparent=True, bbox_inches=&quot;tight&quot;) fig.savefig(&quot;./python_figures/site-logo.svg&quot;) plt.show() . Equations may not give solutions for all &#34;solve&#34; variables. Equations may not give solutions for all &#34;solve&#34; variables. . session = WolframLanguageSession() session.evaluate(wlexpr(&#39;y[x_] := a x^2 + b x + c&#39;)) session.evaluate(wlexpr(&#39;p1 = {0.3, -0.02}&#39;)) session.evaluate(wlexpr(&#39;p2 = {1, 1}&#39;)) session.evaluate(wlexpr(&#39;sol1 = Solve[ {y[p1[[1]]] == p1[[2]], y[p2[[1]]] == p2[[2]]}, {a, b, c}][[1]]&#39;)) session.evaluate(wlexpr(&#39;sol2 = Solve[(D[(y[x] /. sol1), x] /. x -&gt; 0.3) == 0, a][[1]]&#39;)) par = list(session.evaluate(wlexpr(&#39;{a, b, c} /. sol1 /. sol2&#39;))) . Equations may not give solutions for all &#34;solve&#34; variables. Equations may not give solutions for all &#34;solve&#34; variables. . par . [2.0816326530612246, -1.2489795918367346, 0.16734693877551027] .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/websitelogo.html",
            "relUrl": "/jupyter/2020/01/01/websitelogo.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post45": {
            "title": "The time-dependent Ginzburg-Landau equation",
            "content": ". Introduction . Simulation of the Time-Dependent Ginzburg-Landau Equation $$ frac{ text{d}u}{ text{d}t}= u - u^3 +D nabla^2 u,$$ in 1 and 2 spatial dimensions. This is the simplest example of numerical integration through Finite Differences: . Euler method to advance time | Five-point stencil to compute the laplacian, periodic boundary conditions are assumed. See an example of the output here: https://www.youtube.com/watch?v=JgE9Px7zsQE | . Code . import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.axes_grid1 import make_axes_locatable import time as tm . n = 128 # for 1d simulation write N=(n,) N=(n,n) # diffusion coefficient D = 1.0 # spatial dimensions L = 100.0 dx = L / n x = np.arange(0,L,dx) # time t = 0.0 total_time = 3.0 # beware of the Von Neumann stability analysis # https://en.wikipedia.org/wiki/Von_Neumann_stability_analysis dt = 0.2 * 0.5 * dx**2 / D . define functions . def periodic_lap_1d(u,dx=1.0): return (+1*np.roll(u,+1) +1*np.roll(u,-1) -2*u) / dx**2 def periodic_lap_2d(u,dx=1.0): return (+1*np.roll(u,+1,axis=0) +1*np.roll(u,-1,axis=0) +1*np.roll(u,+1,axis=1) +1*np.roll(u,-1,axis=1) -4*u) / dx**2 f = lambda u: u - u**3 . initialize and start plotting . plt.ion() fig = plt.figure(1,figsize=(7,6)) plt.clf() ax = fig.add_subplot(111) # random initial condition u = 2*np.random.random(N)-1.0 if len(N) == 1: lap = periodic_lap_1d p, = ax.plot(x,u) ax.axis([x[0],x[-1],-1.1,1.1]) if len(N) == 2: lap = periodic_lap_2d p = ax.imshow(u,cmap=&quot;RdGy&quot;, vmin=-1.0, vmax=1.0,extent=[0,L,0,L]) # create an axes on the right side of ax. The width of cax will be 5% # of ax and the padding between cax and ax will be fixed at 0.15 inch. divider = make_axes_locatable(ax) colorbar_ax = divider.append_axes(&quot;right&quot;, size=&quot;5%&quot;, pad=0.15) cbar = fig.colorbar(p, cax=colorbar_ax, ticks=[-1,-0.5,0,0.5,1]) ax.set_title(&quot;time={:5.1f}&quot;.format(0.0)) . Text(0.5, 1.0, &#39;time= 0.0&#39;) . start simulation . while t&lt;total_time: t += dt u = u + dt * (f(u) + D * lap(u,dx) ) # we don&#39;t need to plot again, just to update the data of the plot if len(N) == 1: p.set_data(x,u) if len(N) == 2: p.set_data(u) ax.set_title(&quot;time={:5.1f}&quot;.format(t)) fig.canvas.draw() .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/tdgle.html",
            "relUrl": "/jupyter/2020/01/01/tdgle.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post46": {
            "title": "Fancy subplot grid",
            "content": ". Introduction . With GridSpec you can create any combination of panels . The code . import numpy as np import matplotlib import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import FuncFormatter . # this is a latex constant, don&#39;t change it. pts_per_inch = 72.27 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) text_width_in_pts = 246.0 # inside a figure environment in latex, the result will be on the # dvi/pdf next to the figure. See url above. text_width_in_inches = text_width_in_pts / pts_per_inch # make rectangles with a nice proportion golden_ratio = 0.618 # figure.png or figure.eps will be intentionally larger, because it is prettier inverse_latex_scale = 2 # when compiling latex code, use # includegraphics[scale=(1/inverse_latex_scale)]{figure} # we want the figure to occupy 2/3 (for example) of the text width fig_proportion = (3.0 / 3.0) csize = inverse_latex_scale * fig_proportion * text_width_in_inches # always 1.0 on the first argument fig_size = (1.0 * csize, 1.1 * csize) # find out the fontsize of your latex text, and put it here text_size = inverse_latex_scale * 12 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {&#39;backend&#39;: &#39;ps&#39;, &#39;axes.labelsize&#39;: text_size, &#39;legend.fontsize&#39;: tick_size, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # Times, Palatino, New Century Schoolbook, # Bookman, Computer Modern Roman &#39;font.serif&#39;: [&#39;Times&#39;], &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, # include here any neede package for latex &#39;text.latex.preamble&#39;: [r&#39; usepackage{amsmath}&#39;, ], } plt.rcParams.update(params) plt.ioff() plt.clf() # figsize accepts only inches. fig = plt.figure(1, figsize=fig_size) gs = gridspec.GridSpec(3, 2, width_ratios=[1,0.5], height_ratios=[1,0.7,0.3]) gs.update(left=0.16, right=0.86,top=0.92, bottom=0.08, hspace=0.05, wspace=0.05) . subplot a . ax0 = plt.subplot(gs[0, :]) heaviside = lambda x: 0.5 * (np.sign(x) + 1) x = np.arange(0, 10.01, 0.01) ax0.plot(x, heaviside(x - 2), color=&#39;purple&#39;, lw=3) ax0.text(2.5, 1.1, r&quot;$ longleftarrow$ heaviside&quot;) # y ticks as a percentage ax0.set_yticks(np.arange(-0.5, 2.0, 0.5)) def to_percent(y, position): # Ignore the passed in position. This has the effect of scaling the default # tick locations. s = &quot;{:+.0f}&quot;.format(y * 100) # str(100 * y) # The percent symbol needs escaping in latex if matplotlib.rcParams[&#39;text.usetex&#39;] is True: return s + r&#39;$ %$&#39; else: return s + &#39;%&#39; # Create the formatter using the function to_percent. This multiplies all the # default labels by 100, making them all percentages formatter = FuncFormatter(to_percent) # Set the formatter ax0.yaxis.set_major_formatter(formatter) ax0.set_ylabel(&quot;heaviside, percentage&quot;) # x ticks on top ax0.axis([x.min(), x.max(), -0.5, 1.5]) ax0.xaxis.tick_top() ax0.set_xlabel(r&quot;x labels on top&quot;) ax0.xaxis.set_label_position(&quot;top&quot;) # transAxes makes position relative to axes ax0.text(0.97, 0.97, r&quot; textbf{a}&quot;, transform=ax0.transAxes, horizontalalignment=&#39;right&#39;, verticalalignment=&#39;top&#39;) # copy window with same x axis (y will be different) ax0b = ax0.twinx() ax0b.plot(x, np.tanh(x - 5), color=&quot;green&quot;, linewidth=3) ax0b.axis([x.min(), x.max(), -1.1, 2.5]) ax0b.text(5.5, 0, r&quot;tanh $ longrightarrow$&quot;) ax0b.set_ylabel(r&#39;tanh, offset label&#39;) ax0b.yaxis.set_label_coords(1.1, 0.70) . subplot b . ax10 = plt.subplot(gs[1, 0]) x = np.arange(-5, 5, 0.01) y = np.exp(-x) ax10.plot(x, y, color=&quot;orange&quot;, lw=3) ax10.set_yscale(&#39;log&#39;, basey=2) ax10.set_yticks(2.0 ** np.arange(-7, 7, 3)) ax10.text(1.0, 1, r&quot;$y=e^{-x}$&quot;) ax10.set_xticks(np.arange(-5, 6, 2)) ax10.set_xticklabels(np.arange(-5, 6, 2), y=0.15) ax10.get_yaxis().set_tick_params(direction=&#39;out&#39;) ax10.set_ylabel(&quot;log scale base 2&quot;, labelpad=15) ax10.text(0.97, 0.97, r&quot; textbf{b}&quot;, transform=ax10.transAxes, horizontalalignment=&#39;right&#39;, verticalalignment=&#39;top&#39;) . Text(0.97, 0.97, &#39; textbf{b}&#39;) . subplot c . ax11 = plt.subplot(gs[1, 1]) x = np.arange(1.0, np.e ** 4, 0.01) y = x ** (-0.8) ax11.plot(x, y, color=&quot;cyan&quot;, lw=3) ax11.text(2, 1, r&quot;$y=x^{-0.8}$&quot;, fontsize=tick_size) ax11.loglog(x, y, basex=np.e, basey=np.e) xt = np.exp(np.arange(1, 4, 1)) yt = np.pi ** (np.arange(-3, 2, 1)) ax11.set_xticks(xt) ax11.set_xticklabels(xt, y=0.15) ax11.set_yticks(yt) def ticks_e(y, pos): # base e return r&#39;$e^{:.0f}$&#39;.format(np.log(y)) def ticks_pi(y, pos): # base pi, why not? return r&#39;$ pi^{%+.0f}$&#39;%(np.log(y)/np.log(np.pi)) ax11.xaxis.set_major_formatter(FuncFormatter(ticks_e)) ax11.yaxis.set_major_formatter(FuncFormatter(ticks_pi)) ax11.yaxis.tick_right() ax11.yaxis.set_label_position(&quot;right&quot;) ax11.set_ylabel(&quot;right side&quot;, labelpad=10) ax11.text(0.97, 0.97, r&quot; textbf{c}&quot;, transform=ax11.transAxes, horizontalalignment=&#39;right&#39;, verticalalignment=&#39;top&#39;) . Text(0.97, 0.97, &#39; textbf{c}&#39;) . subplot d . ax20 = plt.subplot(gs[2, 0]) ax20.axis([0, 1, 0, 1]) ax20.set_xticks(np.arange(0, 1.1, 0.2)) ax20.set_xticklabels([&quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;, &quot;May&quot;, &quot;June&quot;], rotation=30, horizontalalignment=&quot;right&quot;) ax20.set_yticks([]) ax20.text(0.97, 0.97, r&quot; textbf{d}&quot;, transform=ax20.transAxes, horizontalalignment=&#39;right&#39;, verticalalignment=&#39;top&#39;) . Text(0.97, 0.97, &#39; textbf{d}&#39;) . subplot e . ax21 = plt.subplot(gs[2, 1]) ax21.set_xticks([]) ax21.set_yticks([]) ax21.axis([0, 1, 0, 1]) ax21.text(0.97, 0.97, r&quot; textbf{e}&quot;, transform=ax21.transAxes, horizontalalignment=&#39;right&#39;, verticalalignment=&#39;top&#39;) . Text(0.97, 0.97, &#39; textbf{e}&#39;) . %matplotlib notebook fig.savefig(&quot;./python_figures/subplot-grid.png&quot;, dpi=300) fig .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/subplotgrid.html",
            "relUrl": "/jupyter/2020/01/01/subplotgrid.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post47": {
            "title": "Streamplot",
            "content": ". Introduction . Streamplot of a two-dimensional linear system, with eigenvectors and nullclines. Python shows LaTeX equations beautifully. Main features: meshgrid, streamplot, contour, legend, LaTeX . The code . %matplotlib notebook import matplotlib import matplotlib.pyplot as plt import numpy as np . make graph look pretty . # this is a latex constant, don&#39;t change it. pts_per_inch = 72.27 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) text_width_in_pts = 300.0 # inside a figure environment in latex, the result will be on the # dvi/pdf next to the figure. See url above. text_width_in_inches = text_width_in_pts / pts_per_inch # make rectangles with a nice proportion golden_ratio = 0.618 # figure.png or figure.eps will be intentionally larger, because it is prettier inverse_latex_scale = 2 # when compiling latex code, use # includegraphics[scale=(1/inverse_latex_scale)]{figure} # we want the figure to occupy 2/3 (for example) of the text width fig_proportion = (3.0 / 3.0) csize = inverse_latex_scale * fig_proportion * text_width_in_inches # always 1.0 on the first argument fig_size = (1.0 * csize, 0.8 * csize) # find out the fontsize of your latex text, and put it here text_size = inverse_latex_scale * 12 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {&#39;backend&#39;: &#39;ps&#39;, &#39;axes.labelsize&#39;: text_size, &#39;legend.fontsize&#39;: tick_size, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # Times, Palatino, New Century Schoolbook, # Bookman, Computer Modern Roman # &#39;font.serif&#39;: [&#39;Times&#39;], &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, # include here any neede package for latex &#39;text.latex.preamble&#39;: [r&#39; usepackage{amsmath}&#39;, ], } plt.rcParams.update(params) plt.ioff() # figsize accepts only inches. fig = plt.figure(1, figsize=fig_size) fig.subplots_adjust(left=0.10, right=0.97, top=0.82, bottom=0.10, hspace=0.02, wspace=0.02) ax = fig.add_subplot(111) . define parameters, system of equations, and equation for eigenvectors . p = {&#39;a&#39;: -1.0, &#39;b&#39;: +0.2, &#39;c&#39;: +1.2, &#39;d&#39;: -1.5} # the equations def system_equations(x,y): return [p[&#39;a&#39;] * x + p[&#39;b&#39;] * y, p[&#39;c&#39;] * x + p[&#39;d&#39;] * y, ] # eigenvectors eigen_vec = 100 * np.array([ [(p[&#39;a&#39;] - p[&#39;d&#39;] - np.sqrt((p[&#39;a&#39;] - p[&#39;d&#39;]) ** 2 + 4.0 * p[&#39;b&#39;] * p[&#39;c&#39;])) / (2.0 * p[&#39;c&#39;]), 1.0], [(p[&#39;a&#39;] - p[&#39;d&#39;] + np.sqrt((p[&#39;a&#39;] - p[&#39;d&#39;]) ** 2 + 4.0 * p[&#39;b&#39;] * p[&#39;c&#39;])) / (2.0 * p[&#39;c&#39;]), 1.0], ]) . there are two equivalent ways to build a mesh, choose the one that makes more sense to you... . min_x, max_x = [-1, 1] min_y, max_y = [-4, 4] divJ = 50j div = 50 # 1st way # Y, X = np.mgrid[min_y:max_y:div,min_x:max_x:div] # 2nd way X, Y = np.meshgrid(np.linspace(min_x, max_x, div), np.linspace(min_y, max_y, div)) # streamplot density = 2 * [0.80] minlength = 0.2 arrow_color = 3 * [0.5] ax.streamplot(X, Y, system_equations(X, Y)[0], system_equations(X, Y)[1], density=density, color=arrow_color, arrowsize=2, linewidth=2, minlength=minlength) . &lt;matplotlib.streamplot.StreamplotSet at 0x7ff7c5afdd50&gt; . nullclines . null_0 = ax.contour(X, Y, system_equations(X, Y)[0], levels=[0], colors=&#39;black&#39;, linewidths=3) null_1 = ax.contour(X, Y,system_equations(X, Y)[1], levels=[0], colors=&#39;blue&#39;, linewidths=3) n0 = null_0.collections[0] n1 = null_1.collections[0] . eigenvectors . eigen_0, = ax.plot([eigen_vec[0, 0],-eigen_vec[0, 0]], [eigen_vec[0, 1],-eigen_vec[0, 1]], color=&#39;red&#39;, lw=2, ls=&quot;--&quot;) eigen_1, = ax.plot([eigen_vec[1, 0],-eigen_vec[1, 0]], [eigen_vec[1, 1],-eigen_vec[1, 1]], color=&#39;orange&#39;, lw=2, ls=&quot;--&quot;) dash = (15, 10, 15, 10) eigen_0.set_dashes(dash) eigen_1.set_dashes(dash) . some labels, legend, and text . ax.set_ylabel(r&quot;$y$&quot;, rotation=&#39;horizontal&#39;) ax.set_xlabel(r&quot;$x$&quot;, labelpad=5) ax.legend([n0, n1, eigen_0, eigen_1], [r&#39;$dx/dt=0$&#39;, r&#39;$dy/dt=0$&#39;, &quot;eigenvector 1&quot;, &quot;eigenvector 2&quot;], loc=&quot;lower right&quot;, frameon=True, fancybox=False, shadow=False, ncol=2, borderpad=0.5, labelspacing=0.5, handlelength=3, handletextpad=0.1, borderaxespad=0.3, columnspacing=2) ax.text(-1.0, 4.3, (r&quot;$ frac{d}{dt} begin{pmatrix}x y end{pmatrix}=$&quot; r&quot;$ begin{pmatrix}a&amp;b c&amp;d end{pmatrix} cdot$&quot; r&quot;$ begin{pmatrix}x y end{pmatrix}$&quot;)) ax.text(0.1, 5.0, r&quot;$a={:.1f} qquad b={:.1f}$ &quot;.format(p[&#39;a&#39;], p[&#39;b&#39;])) ax.text(0.1, 4.3, r&quot;$c={:.1f} qquad d={:.1f}$ &quot;.format(p[&#39;c&#39;], p[&#39;d&#39;])) ax.axis([min_x, max_x, min_y, max_y]) fig.savefig(&quot;python_figures/streamplot.png&quot;, resolution=300) plt.draw() fig .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/streamplot.html",
            "relUrl": "/jupyter/2020/01/01/streamplot.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post48": {
            "title": "Least Squares",
            "content": ". Introduction . This code produces the figure above. It&#39;s main tool is the curve_fit method, that allows us to fit any function to data, and get optimal parameter values. . The code . %matplotlib notebook import matplotlib.pyplot as plt import numpy as np import matplotlib.gridspec as gridspec import scipy.special from scipy.optimize import curve_fit import matplotlib.patches as patches . Make graph look pretty . %%capture out %matplotlib notebook # http://wiki.scipy.org/Cookbook/Matplotlib/LaTeX_Examples # this is a latex constant, don&#39;t change it. pts_per_inch = 72.27 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) text_width_in_pts = 300.0 # inside a figure environment in latex, the result will be on the # dvi/pdf next to the figure. See url above. text_width_in_inches = text_width_in_pts / pts_per_inch # make rectangles with a nice proportion golden_ratio = 0.618 # figure.png or figure.eps will be intentionally larger, because it is prettier inverse_latex_scale = 2 # when compiling latex code, use # includegraphics[scale=(1/inverse_latex_scale)]{figure} # we want the figure to occupy 2/3 (for example) of the text width fig_proportion = (3.0 / 3.0) csize = inverse_latex_scale * fig_proportion * text_width_in_inches # always 1.0 on the first argument fig_size = (1.0 * csize, 0.85 * csize) # find out the fontsize of your latex text, and put it here text_size = inverse_latex_scale * 12 label_size = inverse_latex_scale * 10 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {#&#39;backend&#39;: &#39;ps&#39;, &#39;axes.labelsize&#39;: 16, &#39;legend.fontsize&#39;: tick_size, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;axes.labelsize&#39;: label_size, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # &#39;font.serif&#39;: [&#39;Computer Modern Roman&#39;], &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, # include here any neede package for latex &#39;text.latex.preamble&#39;: [r&#39; usepackage{amsmath}&#39;], } plt.rcParams.update(params) plt.clf() fig = plt.figure(1, figsize=fig_size) # figsize accepts only inches. fig.subplots_adjust(left=0.04, right=0.98, top=0.93, bottom=0.15, hspace=0.05, wspace=0.02) plt.ioff() . Configure axes and some function definitions . x = np.arange(0, 12, 0.4) ax1 = fig.add_subplot(211, aspect=&#39;equal&#39;) ax2 = fig.add_subplot(212, aspect=&#39;equal&#39;) ax1.set_xlim((x.min(), x.max())) ax2.set_xlim((x.min(), x.max())) ax1.set_ylim(-1, 3.5) ax2.set_ylim(-1, 3.5) ax1.set_xticklabels([]) ax1.set_yticks(np.arange(-1, 4)) ax2.set_yticks(np.arange(-1, 4)) def func(x, par0, par1, par2): return par0 + np.cos(par1 * x + par2) def add_rec(ax, c, v, col): ax.add_patch( patches.Rectangle( c, # (x,y) np.abs(v), # width v, # height alpha=0.4, color=col ) ) . Now let&#39;s plot some stuff . %matplotlib notebook # the parameter values par = (1, 2, 1) # generating data with noise y = func(x, *par) + (np.random.random(len(x)) - 0.5) ax1.plot(x, y, marker=&#39;o&#39;, ls=&#39;None&#39;, markerfacecolor=&quot;blue&quot;, markeredgecolor=&quot;black&quot;) ax2.plot(x, y, marker=&#39;o&#39;, ls=&#39;None&#39;, markerfacecolor=&quot;red&quot;, markeredgecolor=&quot;black&quot;) # best fit popt, pcov = curve_fit(func, x, y, p0=(1.5, 1.5, 2.5)) # p0 = initial guess p0, p1, p2 = popt # The total sum of squares (proportional to the variance of the data) SStot = ((y - y.mean()) ** 2).sum() # The sum of squares of residuals SSres = ((y - func(x, p0, p1, p2)) ** 2).sum() Rsquared = 1 - SSres / SStot # plot best fit h = np.linspace(x.min(), x.max(), 1001) fit, = ax1.plot(h, func(h, p0, p1, p2), color=&#39;black&#39;, linewidth=2) ax1.legend([fit], [&quot;Best fit&quot;], loc=&quot;upper right&quot;, frameon=False, handlelength=4) # plot mean mean, = ax2.plot(h, h * 0 + np.mean(y), ls=&#39;--&#39;, color=&#39;black&#39;, linewidth=2) ax2.legend([mean], [&quot;Mean&quot;], loc=&quot;upper right&quot;, frameon=False, handlelength=4) # plot blue and red squares for ind in np.arange(len(x)): x0 = x[ind] y0 = y[ind] # print(x0,y0) v1 = y0 - func(x0, p0, p1, p2) v2 = y0 - y.mean() add_rec(ax1, (x0, y0), -v1, &quot;blue&quot;) add_rec(ax2, (x0, y0), -v2, &quot;red&quot;) ax2.text(0.5, 2.7, r&quot;Total sum of squares: {:.1f}&quot;.format(SStot)) ax1.text(0.5, 2.7, r&quot;Sum of squares of residuals: {:.1f}&quot;.format(SSres)) ax2.set_xlabel( r&quot;R-squared = $1 - displaystyle frac{ text{blue area}}{ text{red area}}$ = &quot; + &quot;{:.2f}&quot;.format(Rsquared)) ax1.set_xlabel( r&quot;Data: $f(x) = p_0 + cos(p_1 x + p_2)+ $ noise &quot;) ax1.xaxis.set_label_position(&quot;top&quot;) fig.savefig(&quot;./python_figures/least-squares.png&quot;,dpi=300) fig .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/leastsquares.html",
            "relUrl": "/jupyter/2020/01/01/leastsquares.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post49": {
            "title": "A hysteresis mechanism",
            "content": ". Introduction . Hysteresis mechanism created by bistability of states. . Energy function: $$f = u^4 - 2u^2 + hu$$ . The code . # i.e., if you want to see the animation in real time. import matplotlib matplotlib.use(&#39;Agg&#39;) . import matplotlib.pyplot as plt import numpy as np import os import sympy from scipy.integrate import ode # learn how to configure: http://matplotlib.sourceforge.net/users/customizing.html params = {#&#39;backend&#39;: &#39;GTKAgg&#39;, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;font.family&#39;:&#39;serif&#39;, &#39;font.size&#39;: 18, &#39;font.serif&#39;:[&#39;Times&#39;], # Times, Palatino, New Century Schoolbook, Bookman, Computer Modern Roman &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, } plt.rcParams.update(params) fig=plt.figure(1,figsize=(9.6,5.4),dpi=100) # 1920x1080 # figsize accepts only inches. if you rather think in cm, change the code yourself. fig.clf() fig.subplots_adjust(left=0.07, right=0.93,top=0.90, bottom=0.12,hspace=0.02,wspace=0.10) Hlim=2.5 # parameter range from -Hlim to Hlim ax1=fig.add_subplot(121) ax1.set_xticks([]) ax1.set_yticks([]) ax1.set_xlabel(r&#39;System response&#39;,labelpad=12) ax1.set_ylabel(&#39;Energy&#39;,labelpad=12) ax1.axis([-Hlim,Hlim,-5,5]) ax2=fig.add_subplot(122) ax2.set_xticks([]) ax2.set_yticks([]) ax2.set_xlabel(r&#39;Parameter&#39;,labelpad=12) ax2.set_ylabel(r&#39;System response&#39;,labelpad=12) ax2.yaxis.set_label_position(&quot;right&quot;) ax2.axis([-Hlim*1.2,Hlim*1.2,-2,2]) frame_names = [] frame_index = 0 make_movie=True plt.ion() . f = lambda u,h: u**4-2*u**2+h*u fprime = lambda u,h: sympy.diff(f(u,h),u) Hinit=Hlim ulim=2.5 # system response axis, from -ulim to ulim u = np.linspace(-ulim,ulim,101) x = sympy.Symbol(&#39;x&#39;) def res(h): &quot;&quot;&quot;System response is one of the real roots of the energy function derivative &quot;&quot;&quot; # derivative roots, complex resp = sympy.solvers.solve(fprime(x,h),x) # numerical evaluation resp = map(sympy.N,resp) # let&#39;s check which roots are real isreal = len(resp)*[False] for i in range(len(resp)): # negligible imaginary component if np.abs(sympy.functions.im(resp[i]))&lt;1e-15: resp[i]=sympy.functions.re(resp[i]) isreal[i]=True resp = np.array(resp) # return only real roots return resp[np.array(isreal)] # let&#39;s plot stuff, and make a nice movie #### left plot, ax1 #### line_func, = ax1.plot(u,f(u,Hinit),lw=2,color=&#39;black&#39;) # ball color ball_color = &quot;blue&quot; # minimum = the smallest root, the leftmost root mini = np.min(res(Hinit)) # calculated for initial parameter value boost = 0.22 # so that ball sits on top of the curve # plot ball ball_u, = ax1.plot([mini],[f(mini,Hinit)+boost],&#39;o&#39;, markersize=12, markerfacecolor=ball_color) #### right plot, ax2 #### # build empty hysteresis array, we will add values # as simulation progresses deetype = np.dtype([(&#39;h&#39;, &#39;float64&#39;), (&#39;u&#39;, &#39;float64&#39;)]) hysteresis = np.array([(Hinit,mini)],dtype=deetype) line_hyst, = ax2.plot(hysteresis[&#39;h&#39;],hysteresis[&#39;u&#39;], lw=2,color=&#39;black&#39;) ballH, = ax2.plot([hysteresis[&#39;h&#39;][-1]],[hysteresis[&#39;u&#39;][-1]],&#39;o&#39;, markersize=12, markerfacecolor=ball_color) plt.show() . Total_time = 15 # seconds fps = 24 # frames per second # divided by 2 because we ramp down then up param_vec = np.linspace(Hlim,-Hlim,Total_time*fps/2) # ramp down for H in param_vec: line_func.set_data(u,f(u,H)) # update line on the left mini = np.min(res(H)) # calculate new minimum ball_u.set_data([mini],[f(mini,H)+boost]) # update ball on the left new_line = np.array([(H,mini)],dtype=deetype) # create new line # append new line to hysteresis array hysteresis = np.concatenate((hysteresis,new_line)) line_hyst.set_data(hysteresis[&#39;h&#39;],hysteresis[&#39;u&#39;]) # update line ballH.set_data([hysteresis[&#39;h&#39;][-1]],[hysteresis[&#39;u&#39;][-1]]) # update ball on the right fig.canvas.draw() if make_movie: fname = &quot;_tmp{:05d}.png&quot;.format(frame_index) frame_names.append(fname) fig.savefig(fname,dpi=200) frame_index+=1 # ramp up for H in param_vec[::-1]: # just reverse parameter array line_func.set_data(u,f(u,H)) maxi = np.max(res(H)) # everything is the same, but now with maximum ball_u.set_data([maxi],[f(maxi,H)+boost]) new_line = np.array([(H,maxi)],dtype=deetype) hysteresis = np.concatenate((hysteresis,new_line)) line_hyst.set_data(hysteresis[&#39;h&#39;],hysteresis[&#39;u&#39;]) ballH.set_data([hysteresis[&#39;h&#39;][-1]],[hysteresis[&#39;u&#39;][-1]]) fig.canvas.draw() if make_movie: fname = &quot;_tmp{:05d}.png&quot;.format(frame_index) frame_names.append(fname) fig.savefig(fname,dpi=200) frame_index+=1 if make_movie: frames = &quot;_tmp%5d.png&quot; movie_command = &quot;ffmpeg -y -r {:} -i {:} ball.mp4&quot;.format(fps,frames) os.system(movie_command) for fname in frame_names: # pass os.remove(fname) .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/hysteresis.html",
            "relUrl": "/jupyter/2020/01/01/hysteresis.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post50": {
            "title": "Fun with histograms",
            "content": ". Introduction . This code produces the figure above. I tried to showcase a few things one can do with 1d and 2d histograms. . The code . import matplotlib.pyplot as plt import numpy as np import matplotlib.gridspec as gridspec import scipy.special from scipy.optimize import curve_fit . make graph look pretty . # this is a latex constant, don&#39;t change it. pts_per_inch = 72.27 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) text_width_in_pts = 450.0 # inside a figure environment in latex, the result will be on the # dvi/pdf next to the figure. See url above. text_width_in_inches = text_width_in_pts / pts_per_inch # make rectangles with a nice proportion golden_ratio = 0.618 # figure.png or figure.eps will be intentionally larger, because it is prettier inverse_latex_scale = 2 # when compiling latex code, use # includegraphics[scale=(1/inverse_latex_scale)]{figure} # we want the figure to occupy 2/3 (for example) of the text width fig_proportion = (3.0 / 3.0) csize = inverse_latex_scale * fig_proportion * text_width_in_inches # always 1.0 on the first argument fig_size = (1.0 * csize, 0.5 * csize) # find out the fontsize of your latex text, and put it here text_size = inverse_latex_scale * 12 label_size = inverse_latex_scale * 10 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {&#39;backend&#39;: &#39;ps&#39;, &#39;axes.labelsize&#39;: 16, &#39;legend.fontsize&#39;: tick_size, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;axes.labelsize&#39;: label_size, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # &#39;font.serif&#39;: [&#39;Computer Modern Roman&#39;], &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, } plt.rcParams.update(params) plt.ioff() fig = plt.figure(1, figsize=fig_size) # figsize accepts only inches. . Panels on the left of the figure . gs = gridspec.GridSpec(2, 2, width_ratios=[1, 0.2], height_ratios=[0.2, 1]) gs.update(left=0.05, right=0.50, top=0.95, bottom=0.10, hspace=0.02, wspace=0.02) sigma = 1.0 # standard deviation (spread) mu = 0.0 # mean (center) of the distribution x = np.random.normal(loc=mu, scale=sigma, size=5000) k = 2.0 # shape theta = 1.0 # scale y = np.random.gamma(shape=k, scale=theta, size=5000) # bottom left panel ax10 = plt.subplot(gs[1, 0]) counts, xedges, yedges, image = ax10.hist2d(x, y, bins=40, cmap=&quot;YlOrRd&quot;, density=True) dx = xedges[1] - xedges[0] dy = yedges[1] - yedges[0] xvec = xedges[:-1] + dx / 2 yvec = yedges[:-1] + dy / 2 ax10.set_xlabel(r&quot;$x$&quot;) ax10.set_ylabel(r&quot;$y$&quot;, rotation=&quot;horizontal&quot;) ax10.text(-2, 8, r&quot;$p(x,y)$&quot;) ax10.set_xlim([xedges.min(), xedges.max()]) ax10.set_ylim([yedges.min(), yedges.max()]) # top left panel ax00 = plt.subplot(gs[0, 0]) gaussian = (1.0 / np.sqrt(2.0 * np.pi * sigma ** 2)) * np.exp(-((xvec - mu) ** 2) / (2.0 * sigma ** 2)) xdist = counts.sum(axis=1) * dy ax00.bar(xvec, xdist, width=dx, fill=False, edgecolor=&#39;black&#39;, alpha=0.8) ax00.plot(xvec, gaussian, color=&#39;black&#39;) ax00.set_xlim([xedges.min(), xedges.max()]) ax00.set_xticklabels([]) ax00.set_yticks([]) ax00.set_xlabel(&quot;Normal distribution&quot;, fontsize=16) ax00.xaxis.set_label_position(&quot;top&quot;) ax00.set_ylabel(r&quot;$p(x)$&quot;, rotation=&quot;horizontal&quot;, labelpad=20) # bottom right panel ax11 = plt.subplot(gs[1, 1]) gamma_dist = yvec ** (k - 1.0) * np.exp(-yvec / theta) / (theta ** k * scipy.special.gamma(k)) ydist = counts.sum(axis=0) * dx ax11.barh(yvec, ydist, height=dy, fill=False, edgecolor=&#39;black&#39;, alpha=0.8) ax11.plot(gamma_dist, yvec, color=&#39;black&#39;) ax11.set_ylim([yedges.min(), yedges.max()]) ax11.set_xticks([]) ax11.set_yticklabels([]) ax11.set_ylabel(&quot;Gamma distribution&quot;, fontsize=16) ax11.yaxis.set_label_position(&quot;right&quot;) ax11.set_xlabel(r&quot;$p(y)$&quot;) ax11.xaxis.set_label_position(&quot;top&quot;) . Panels on the right of the figure . gs2 = gridspec.GridSpec(2, 1, width_ratios=[1], height_ratios=[1, 1]) gs2.update(left=0.60, right=0.98, top=0.95, bottom=0.10, hspace=0.02, wspace=0.05) x = np.random.normal(loc=0, scale=1, size=1000) y = np.random.gamma(shape=2, size=1000) bx10 = plt.subplot(gs2[1, 0]) bx00 = plt.subplot(gs2[0, 0]) N = 100 a = np.random.gamma(shape=5, size=N) my_bins = np.arange(0,15,1.5) n1, bins1, patches1 = bx00.hist(a, bins=my_bins, density=True, histtype=&#39;stepfilled&#39;, alpha=0.2, hatch=&#39;/&#39;) bx00.set_xlim([0, 15]) bx00.set_ylim([0, 0.28]) bx00.set_xticklabels([]) bx00.set_xlabel(r&quot; texttt{plt.hist}&quot;) bx00.xaxis.set_label_position(&quot;top&quot;) # the following way is equivalent to plt.hist, but it gives # the user more flexibility when plotting and analysing the results n2, bins2 = np.histogram(a, bins=my_bins, density=True) wid = bins2[1] - bins2[0] red, = bx10.plot(bins2[:-1]+wid/2, n2, marker=&#39;o&#39;, color=&#39;red&#39;) bx10.bar(bins2[:-1], n2, width=wid, fill=False, edgecolor=&#39;black&#39;, linewidth=3, alpha=0.8, align=&quot;edge&quot;) bx10.set_xlim([0, 15]) bx10.set_ylim([0, 0.28]) bx10.set_xlabel(r&quot; texttt{np.histogram}; quad texttt{plt.bar}&quot;) . Text(0.5, 0, &#39; texttt{np.histogram}; quad texttt{plt.bar}&#39;) . best fit . xdata = my_bins[:-1] + wid/2 ydata = n2 def func(x, p1, p2): return x ** (p1 - 1.0) * np.exp(-x / p2) / (p2 ** p1 * scipy.special.gamma(p1)) popt, pcov = curve_fit(func, xdata, ydata, p0=(1.5, 1.5)) # p0 = initial guess p1, p2 = popt SStot = ((ydata - ydata.mean()) ** 2).sum() SSres = ((ydata - func(xdata, p1, p2)) ** 1).sum() Rsquared = 1 - SSres / SStot h = np.linspace(0,15,101) bx00.plot(h, func(h, p1, p2), color=&#39;blue&#39;, linewidth=2) # dummy plot, just so we can have a legend on the bottom panel blue, = ax10.plot([100],[100], color=&#39;blue&#39;, linewidth=2, label=&quot;Best fit&quot;) bx10.legend([red,blue],[r&#39;Data&#39;,r&#39;Best fit, $r^2=${:.2f}&#39;.format(Rsquared)], loc=&#39;upper right&#39;, frameon=False, handlelength=4, markerfirst=False, numpoints=3) . /Users/yairmau/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars after removing the cwd from sys.path. . &lt;matplotlib.legend.Legend at 0x7fde860d7ed0&gt; . fig.savefig(&quot;./python_figures/histograms.png&quot;,dpi=300) fig .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/histograms.html",
            "relUrl": "/jupyter/2020/01/01/histograms.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post51": {
            "title": "Hilbert Curve",
            "content": ". Introduction . The Hilbert curve is calculated iteratively. Check out this: Hilbert_curve: Representation_as_Lindenmayer_system . The code . import matplotlib matplotlib.use(&#39;AGG&#39;) . import numpy as np import matplotlib.pyplot as plt import os . def apply_rules(s): &quot;&quot;&quot; Hilbert Curve as a Lindenmayer system (L-system) https://en.wikipedia.org/wiki/Hilbert_curve#Representation_as_Lindenmayer_system&quot;&quot;&quot; s=s.replace(&quot;a&quot;,&quot;-Bf+AfA+fB-&quot;) # capital letters &quot;A&quot; and &quot;B&quot; so that the second operation s=s.replace(&quot;b&quot;,&quot;+Af-BfB-fA+&quot;) # doesn&#39;t apply to the changes already made return s.lower() # make everyone lowercase axiom = &quot;a&quot; n=3 # number of iterations # displacements, ordered in a counter-clockwise direction dxdy = np.array([[ 1, 0], # right [ 0, 1], # up [-1, 0], # left [ 0,-1] ]) # down # displacement is of size 1, so the higher n is, the greater the domain length = 2**n-1; margin = 0.05*length domain = [0-margin,length+margin,0-margin,length+margin] # a 5% margin around the curve s = axiom # string to iterate upon for i in np.arange(n): s = apply_rules(s) . make_movie=True plt.ion() # interactive mode disabled if &quot;matplotlib.use(&#39;AGG&#39;)&quot; fig = plt.figure(figsize=(6,6)) ax = fig.add_subplot(111) ax.axis(&#39;off&#39;) # no frame ax.axis(domain) # domain size ax.set_aspect(&#39;equal&#39;) # square look ax.set_xticks([]); ax.set_yticks([]) # no ticks ax.set_title(r&quot;$n = {:d}$&quot;.format(n)) plt.show() # &quot;a&quot; and &quot;b&quot; can be erased now s=s.replace(&quot;a&quot;,&quot;&quot;) s=s.replace(&quot;b&quot;,&quot;&quot;) frame_names = [] # these two are only relevant if make_movie==True frame_counter=0 p = np.array([[0.0,0.0]]) # this is the starting point (0,0) p_plot, = plt.plot(p[:,0],p[:,1],color=&quot;black&quot;) # iterate on the string s for i,c in enumerate(s): # uncomment to see how fast things are going # print(&quot;{:d}/{:d}&quot;.format(i,len(s))) # rotations &quot;+&quot; and &quot;-&quot; change the displacement array dxdy # &quot;+&quot; means clockwise rotation if c == &#39;+&#39;: dxdy = np.roll(dxdy,+1,axis=0) # &quot;-&quot; means counter-clockwise rotation if c == &#39;-&#39;: dxdy = np.roll(dxdy,-1,axis=0) # forward &quot;f&quot; if c == &#39;f&#39;: # add one more point to array p p = np.vstack([p, [p[-1,0]+dxdy[0,0],p[-1,1]+dxdy[0,1]] ]) # update p_plot data, this is MUCH faster that plotting # several line segments separately p_plot.set_data(p[:,0],p[:,1]) fig.canvas.draw() if make_movie: fname = &quot;_tmp{:05d}.png&quot;.format(frame_counter) frame_names.append(fname) fig.savefig(fname,bbox_inches=&#39;tight&#39;,resolution=300) frame_counter += 1 . if make_movie: frames = &quot;_tmp%5d.png&quot; # movie_command = &quot;mencoder mf://*.png -mf fps=24:type=png --ovc lavc -lavcopts vcodec=mpeg4:mbd=2:trell -oac copy -o hil{:d}.avi&quot;.format(n) # we might have other .png figures in the directory # in this case, use the code below f = open(&quot;png_list.txt&quot;, &quot;w&quot;) for i in frame_names: f.write(i+&quot; n&quot;) f.close() movie_command = &quot;mencoder mf://@png_list.txt -mf fps=24:type=png -ovc lavc -lavcopts vcodec=mpeg4:mbd=2:trell -oac copy -o hil{:d}.avi&quot;.format(n) err=os.system(movie_command) if err!=0: raise RuntimeError(&quot;Couldn&#39;t run mencoder. Data in tmp*.png files&quot;) for fname in frame_names: os.remove(fname) # we now have one video ready. # if you want to join several videos, use this: # sudo apt-get install gpac # MP4Box -cat part1.avi -cat part2.avi -new joinedfile.avi .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/hilbertcurve.html",
            "relUrl": "/jupyter/2020/01/01/hilbertcurve.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post52": {
            "title": "Conway's Game of Life",
            "content": ". Introduction . This is a (slightly) modified version of Glowing Python&#39;s code. I make it available here because it features a few nice things: . how to make a movie using matplotlib.animation | how to write a generator (function with yield) | how to plot a sparce array (spy) | . The code . import numpy as np from matplotlib import pyplot as plt import matplotlib.animation as manimation def life(X, steps): &quot;&quot;&quot; Conway&#39;s Game of Life. - X, matrix with the initial state of the game. - steps, number of generations. &quot;&quot;&quot; def roll_it(x, y): # rolls the matrix X in a given direction # x=1, y=0 left; x=-1, y=0 right; return np.roll(np.roll(X, y, axis=0), x, axis=1) for _ in range(steps): # count the number of neighbours # the universe is considered toroidal Y = roll_it(1, 0) + roll_it(0, 1) + roll_it(-1, 0) + roll_it(0, -1) + roll_it(1, 1) + roll_it(-1, -1) + roll_it(1, -1) + roll_it(-1, 1) # game of life rules X = np.logical_or(np.logical_and(X, Y == 2), Y == 3) X = X.astype(int) yield X . dimensions = (90, 160) # height, width X = np.zeros(dimensions) # Y by X dead cells middle_y = dimensions[0] / 2 middle_x = dimensions[1] / 2 N_iterations = 600 # acorn initial condition # http://www.conwaylife.com/w/index.php?title=Acorn X[middle_y, middle_x:middle_x+2] = 1 X[middle_y, middle_x+4:middle_x+7] = 1 X[middle_y+1, middle_x+3] = 1 X[middle_y+2, middle_x+1] = 1 . FFMpegWriter = manimation.writers[&#39;ffmpeg&#39;] metadata = dict(title=&#39;Game of life&#39;, artist=&#39;Acorn initial condition&#39;) writer = FFMpegWriter(fps=10, metadata=metadata) fig = plt.figure() fig.patch.set_facecolor(&#39;black&#39;) with writer.saving(fig, &quot;game_of_life.mp4&quot;, 300): # last argument: dpi plt.spy(X, origin=&#39;lower&#39;) plt.axis(&#39;off&#39;) writer.grab_frame() plt.clf() for i, x in enumerate(life(X, N_iterations)): plt.title(&quot;iteration: {:03d}&quot;.format(i + 1)) plt.spy(x, origin=&#39;lower&#39;) plt.axis(&#39;off&#39;) writer.grab_frame() plt.clf() .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/gol.html",
            "relUrl": "/jupyter/2020/01/01/gol.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post53": {
            "title": "Fitzhugh-Nagumo Equation",
            "content": "https://youtu.be/5au-G5FuI_A . Introduction . We simulate the Fitzhugh-Nagumo equations $$ u_t = u - u^3 - v + nabla^2 u v_t = epsilon(u - a_1 v - a_0) + delta nabla^2 v, $$ using the semi-spectral time integration method. . This simultation was heavily inspired by Aric Hagberg&#39;s simulation in &quot;From Labyrinthine Patterns to Spiral Turbulence&quot;, PRL 1994. . The code below provides 3 initial conditions, &quot;squiggle, blocks, and random&quot;. For time integration, besides the spectral method, we also provide the Euler method. Details about the semi-spectral method can be found after the code. . Parameters: $ epsilon=0.3$, $ delta=2.0$, $a_1=1.4$, and $a_0=0$. . Other simulations and Python examples can be found on my website: yairmau.com. . The code . import packages . import numpy as np import matplotlib.pyplot as plt import os from matplotlib import rcParams rcParams[&#39;font.family&#39;] = &#39;monospace&#39; . define class with all the methods . class FitzHughNagumo(object): def __init__(self, epsilon=0.3, delta=2.0, a1=1.4, a0=0.0, n=(256, 256), l=(400, 400), start=0.0, step=1.0, finish=2000.0, dt=0.1, integration_type=&quot;spectral&quot;): self.epsilon = epsilon self.delta = delta self.a1 = a1 self.a0 = a0 self.n = n self.l = l self.start = start self.step = step self.finish = finish self.dt = dt self.integration_type = integration_type self.rhs_a = np.zeros((2, self.n[0], self.n[1])) def spectral_multiplier(self): dx = float(self.l[0]) / self.n[0] dy = float(self.l[1]) / self.n[1] # wave numbers fx = 2.0 * np.pi * np.fft.fftfreq(self.n[0], dx) fy = 2.0 * np.pi * np.fft.fftfreq(self.n[1], dy) kx = np.outer(fx, np.ones(self.n[0])) ky = np.outer(np.ones(self.n[1]), fy) # multiplier mult_a = np.zeros((2, self.n[0], self.n[1])) mult_a[0] = np.exp(-(kx ** 2 + ky ** 2) * self.dt) # u mult_a[1] = np.exp(-self.delta * (kx ** 2 + ky ** 2) * self.dt) # v return mult_a def rhs_reaction(self, a): u = a[0] # alias v = a[1] # alias # FHN right hand side self.rhs_a[0] = u - u ** 3 - v self.rhs_a[1] = self.epsilon * (u - self.a1 * v - self.a0) return self.rhs_a def rhs_euler(self, a): # boundary conditions in laplacian laplacian = self.periodic_laplacian u = a[0] # alias v = a[1] # alias dx = float(self.l[0]) / self.n[0] # FHN right hand side self.rhs_a[0] = u - u ** 3 - v + laplacian(u, dx=dx) self.rhs_a[1] = self.epsilon * (u - self.a1 * v - self.a0) + self.delta * laplacian(v, dx=dx) return self.rhs_a def draw(self, a, t): u = a[0] self.im = plt.imshow(u.real, cmap=&quot;Greys_r&quot;, origin=&#39;lower&#39;, vmin=-0.534522, vmax=0.534522, interpolation=&quot;gaussian&quot;) self.title = plt.title(&#39;time = {:&gt;4.0f}&#39;.format(0)) plt.xticks([]) plt.yticks([]) self.im.figure.canvas.draw() def draw_update(self, a, t): u = a[0] self.title.set_text(&#39;time = {:&gt;4.0f}&#39;.format(t)) self.im.set_data(u.real) self.im.figure.canvas.draw() def save_frame(self, i): fname = &quot;_tmp{:05d}.png&quot;.format(i) self.frame_names.append(fname) self.fig.savefig(fname, bbox_inches=&#39;tight&#39;, dpi=300) def periodic_laplacian(self, u, dx=1): &quot;&quot;&quot;Return finite difference Laplacian approximation of 2d array. Uses periodic boundary conditions and a 2nd order approximation.&quot;&quot;&quot; laplacian = (np.roll(u, -1, axis=0) + np.roll(u, +1, axis=0) + np.roll(u, -1, axis=1) + np.roll(u, +1, axis=1) - 4.0 * u) / (dx ** 2) return laplacian def random_ic(self): return 0.5 * (np.random.random((2, self.n[0], self.n[1])) - 0.5) def blocks_ic(self): a = np.ones((2, self.n[0], self.n[1])) a[0] = 0.534522 a[1] = 0.381802 n = self.n p = n[0] / 8 a[0][3 * p - 4:3 * p + 4, 5 * p - 4:5 * p + 4] = -0.534522 a[0][6 * p - 4:6 * p + 4, 3 * p - 4:3 * p + 4] = -0.534522 return a def squiggle_ic(self): a = np.ones((2, self.n[0], self.n[1])) l = self.l uplus = 0.534522 vplus = 0.381802 uminus = -uplus X, Y = np.meshgrid(np.linspace(0, self.l[0], self.n[0]), np.linspace(0, self.l[0], self.n[0])) cos_term = 0.05 * l[0] * np.sin(10 * (2 * np.pi) * Y / l[1] + np.pi * 0.3) exp_term = np.exp(-((Y - l[1] / 2) / (0.1 * l[1])) ** 2) width = 0.05 * l[0] Z = np.exp(-((X - l[0] / 2 + cos_term * exp_term) / width) ** 2) a[0] = uplus a[1] = vplus a[0][Z &gt; 0.8] = uminus return a . run simulation, save snapshots . plt.ion() plt.clf() foo = FitzHughNagumo() foo.fig = plt.figure(1) ax = foo.fig.add_subplot(111) a = foo.squiggle_ic() mult_a = foo.spectral_multiplier() fft_a = np.fft.fftn(a, axes=(1, 2)) t = foo.start foo.draw(a, t) foo.frame_names = [] foo.save_frame(0) for i, tout in enumerate(np.arange(foo.start + foo.step, foo.finish + foo.step, foo.step)): while t &lt; tout: if foo.integration_type == &quot;spectral&quot;: rhs_a = foo.rhs_reaction(a) fft_a = mult_a * (fft_a + foo.dt * np.fft.fftn(rhs_a, axes=(1, 2))) a = np.fft.ifftn(fft_a, axes=(1, 2)) if foo.integration_type == &quot;euler&quot;: a = a + foo.dt * foo.rhs_euler(a) t += foo.dt foo.draw_update(a, t) foo.save_frame(i + 1) . make movie, delete snapshots . fps = 24 frames = &quot;_tmp%5d.png&quot; movie_command = &quot;ffmpeg -y -r {:} -i {:} fhn.mp4&quot;.format(fps, frames) os.system(movie_command) for fname in foo.frame_names: os.remove(fname) . The semi-spectral method . The explanation below was taken from my thesis: &quot;Pattern Formation in Spatially Forced Systems: Application to Vegetation Restoration&quot;. . The semi-spectral method is extremely useful when working with reaction-diffusion systems, and with parabolic PDEs in general. This was the method used to run all the simulations of the Swift-Hohenberg model in this thesis, and it proved to be reliable and fast. The explanation below is a summary of &quot;Spectral algorithms for reaction-diffusion equations&quot;, by Richard V. Craster and Roberto Sassi, with a step by step recipe, so the reader can easily apply the method to any suitable problem. . the method . The semi-spectral transform method is very useful when we have to integrate a system that evolves really slowly. Let us say we have a (parabolic) system of the form: $$ begin{equation*} u_t= epsilon u + f(u)+D nabla^2u, label{eq:1} tag{1} end{equation*} $$ . where $f(u)$ is a nonlinear function. First, we compute the Fourier transform of eqref{eq:1}: $$ begin{equation*} hat{u}_t= epsilon hat{u} + hat{f}(u)-k^2D hat{u}, label{eq:2} tag{2} end{equation*} $$ where the hat denotes the Fourier transform. . We rearrange eqref{eq:2} in the following way: $$ begin{equation*} hat{u}_t+a hat{u}= hat{f}(u), label{eq:3} tag{3} end{equation*} $$ where $a=- epsilon +k^2D$, and now we make a variable substitution $$ begin{align*} hat{v}(k,t)&amp;= ; hat{u}(k,t) ,e^{at} label{eq:4a} tag{4a} hat{v}_t&amp;= ; hat{u}_te^{at}+a hat{u} ,e^{at}. label{eq:4b} tag{4b} end{align*} $$ . We multiply eqref{eq:3} by $e^{at}$ and we finally get $$ begin{equation*} hat{v}_t=e^{at} hat{f}(u). label{eq:5} tag{5} end{equation*} $$ . We can now advance $ hat{v}$ in time using a simple Euler step $$ begin{equation*} hat{v}^{t_{n+1}}= hat{v}^{t_n}+ Delta t left( e^{at_n} hat{f}(u) right). label{eq:6} tag{6} end{equation*} $$ . What we really want is $ hat{u}$, which, according to eqref{eq:4a}, is given by . $$ begin{align*} displaystyle hat{u}^{t_{n+1}}=&amp; ; hat{v}^{t_{n+1}}e^{-at_{n+1}} label{eq:7a} tag{7a} =&amp; ; hat{v}^{t_{n+1}}e^{-at_{n}}e^{-a Delta t} label{eq:7b} tag{7b} =&amp; ; left( hat{v}^{t_n}+ Delta t ; e^{a t_n} hat{f}(u) right)e^{-at_{n}}e^{-a Delta t} label{eq:7c} tag{7c} =&amp; ; left( hat{v}^{t_n}e^{-at_{n}}+ Delta t ;{e^{a t_n}} hat{f}(u) {e^{-at_{n}}} right)e^{-a Delta t} label{eq:7d} tag{7d} =&amp; ; left( hat{u}^{t_n}+ Delta t hat{f}(u) right)e^{-a Delta t} label{eq:7e} tag{7e}. end{align*} $$There is actually no need to use the variable substitution in eqref{eq:4a}. We now have an expression for $ hat{u}^{t_{n+1}}$: $$ begin{equation*} hat{u}^{t_{n+1}}= left( hat{u}^{t_n}+ Delta t hat{f}(u) right)e^{-a Delta t}. label{eq:8} tag{8} end{equation*} $$ . Now it is time to go back from the Fourier space to the real space, and for that we use an inverse Fourier transform $$ u^{t_{n+1}}= mathcal{F}^{-1}[ hat{u}^{t_{n+1}}]. label{eq:9} tag{9} $$ . step by step . To implement this technique, one just has to follow the steps below: . Calculate the Fourier transform of $u$: $ hat{u}= mathcal{F}[u]$. | Have $f(u)$ calculated and then take its Fourier transform: $ hat{f}(u)= mathcal{F}[f(u)]$. | For a given lattice with $N$ points, and $ delta x$ being the distance between them, make the frequency bin vector (matrix) $k$ for your one (two) dimensional system. In python the command would benumpy.fft.fftfreq(N, dx). . The frequency bin vector $k$ looks like: | . $$ begin{align} k&amp;=2 pi cdot left[ 0,1, cdots, tfrac{N}{2}-1,- tfrac{N}{2}, cdots,-1 right]/(N , delta x), qquad mbox{if N is even;} label{eq:10a} tag{10a} k&amp;=2 pi cdot left[ 0,1, cdots, tfrac{N-1}{2},- tfrac{N-1}{2}, cdots,-1 right]/(N , delta x), qquad mbox{if N is odd.} label{eq:10b} tag{10b} end{align} $$Remember that the domain size is given by $L=N , delta x$, which means that the denominator in the expressions above can be written simply as $L$. It is clear from that fact that $ delta k$, the tiniest slice of the Fourier space is $ delta k=2 pi/L$. Corollary: if you want to divide the Fourier space into very many parts, simply have a huge domain. If the system is two-dimensional, then have $k_x$ and $k_y$ calculated separately. The domain might not be square ($L_x neq L_y$), and you might want to divide the domain into a different number of points ($N_x neq N_y$). Anyway, prepare one-dimensional arrays of $k_x$ and $k_y$ as explained above, and then make an outer product of these arrays with a ones array of length $N$, as following: . $$ k_{x,2d} = begin{pmatrix} 1 1 vdots 1 end{pmatrix} begin{pmatrix} k_{x1} &amp; k_{x2} &amp; ... &amp; k_{xN} end{pmatrix} = begin{pmatrix} k_{x1} &amp; k_{x2} &amp; ... &amp; k_{xN} k_{x1} &amp; k_{x2} &amp; ... &amp; k_{xN} &amp; vdots &amp; &amp; k_{x1} &amp; k_{x2} &amp; ... &amp; k_{xN} end{pmatrix} label{eq:11} tag{11} $$and . $$ k_{y,2d} = begin{pmatrix} k_{x1} k_{x2} vdots k_{xN} end{pmatrix} begin{pmatrix} 1 &amp; 1 &amp; ... &amp; 1 end{pmatrix} = begin{pmatrix} k_{y1} &amp; k_{y1} &amp; &amp; k_{y1} k_{y2} &amp; k_{y2} &amp; ... &amp; k_{y2} vdots &amp; vdots &amp; &amp; vdots k_{yN} &amp; k_{yN} &amp; &amp; k_{yN} end{pmatrix}. label{eq:12} tag{12} $$Then factor $e^{-a Delta t}$ equals . $$ e^{-a Delta t}= e^{ left[ epsilon-D(k_x^2+k_y^2) right] Delta t}, label{eq:13} tag{13} $$where $k_x^2$ is the element-wise exponentiation of the 2d array $k_{x,2d}$. . Now that we have all the factors we need, we simply calculate $$ hat{u}^{t_{n+1}}= left( hat{u}^{t_n}+ Delta t hat{f}(u) right)e^{ left[ epsilon-D(k_x^2+k_y^2) right] Delta t}. label{eq:14} tag{14} $$ | We finally go back to the real space by applying the inverse Fourier transform: $u^{t_{n+1}}= mathcal{F}^{-1}[ hat{u}^{t_{n+1}}]$. | . example . For the parametrically forced Swift-Hohenberg equation $$ frac{ partial u}{ partial t} = [ epsilon + gamma cos(k_f x)]u - u^3 -( nabla^2+k_0^2)^2 u, label{eq:15} tag{15} $$ we have $$ f(u)= -u^3 + gamma u cos(k_f x), qquad a = epsilon - left(k_0- k_x^2 - k_y^2 right)^2. label{eq:16} tag{16} $$ .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/fhn.html",
            "relUrl": "/jupyter/2020/01/01/fhn.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post54": {
            "title": "Double Pendulum",
            "content": ". Introduction . The double pendulum is one of the most famous examples of chaos. Enjoy making your own animations! . The code . comment the lines below if you want interactive mode, i.e., if you want to see the animation in real time. . import matplotlib matplotlib.use(&#39;Agg&#39;) . import matplotlib.pyplot as plt import numpy as np import os from scipy.integrate import ode . define equations of motion and other functions . def equations(t, y, args): &quot;&quot;&quot; the equations for the double pendulum &quot;&quot;&quot; x1 = y[0] # x1 = theta1, angle x2 = y[1] # x2 = theta2, angle p1 = y[2] # p1 = omega1, angular velocity p2 = y[3] # p2 = omega2, angular velocity l1,l2,m1,m2,g = args x1_eq = p1 x2_eq = p2 p1_eq = -((g*(2*m1+m2)*np.sin(x1)+m2*(g*np.sin(x1-2*x2)+2*(l2*p2**2+l1*p1**2*np.cos(x1-x2))*np.sin(x1-x2)))/(2*l1*(m1+m2-m2*(np.cos(x1-x2))**2))) p2_eq = ((l1*(m1+m2)*p1**2+g*(m1+m2)*np.cos(x1)+l2*m2*p2**2*np.cos(x1-x2))*np.sin(x1-x2))/(l2*(m1+m2-m2*(np.cos(x1-x2))**2)) return [x1_eq, x2_eq, p1_eq, p2_eq] def calculate_trajectory(args,time,y0): &quot;&quot;&quot; uses scipy&#39;s ode itegrator to simulate the equations &quot;&quot;&quot; t0,t1,dt = time r = ode(equations).set_integrator(&#39;dopri5&#39;) r.set_initial_value(y0, t0).set_f_params(args) data=[[t0, y0[0], y0[1], y0[2], y0[3] ]] while r.successful() and r.t &lt; t1: r.integrate(r.t+dt) data.append([r.t, r.y[0], r.y[1], r.y[2], r.y[3] ]) return np.array(data) def from_angle_to_xy(args,angles): &quot;&quot;&quot; converts angles into xy positions &quot;&quot;&quot; l1,l2,m1,m2,g = args time,theta1,theta2 = angles.T x1 = l1*np.sin(theta1) y1 = -l1*np.cos(theta1) x2 = l2*np.sin(theta2) + x1 y2 = -l2*np.cos(theta2) + y1 return np.array([time,x1,y1,x2,y2]).T . parameters . l1 = 0.5 # length of arms l2 = 0.5 m1 = 1.0 # mass of the pendulum m2 = 1.0 g = 10.0 # acceleration of gravity args = [l1,l2,m1,m2,g] fps = 80 total_time = 5 # seconds time = [0.0,total_time,1.0/fps] # start, finish, dt ic = [np.pi*0.65, np.pi*1.1, 0.0, 0.0] . here the magic happens . d = calculate_trajectory(args,time,ic) data_TXY = from_angle_to_xy(args,d[:,:3]) . Let&#39;s plot stuff, and make a nice movie. Requrement: ffmpeg . make_movie=True params = {&#39;backend&#39;: &#39;ps&#39;, &#39;font.size&#39;: 20, &#39;font.family&#39;:&#39;serif&#39;, &#39;font.serif&#39;:[&#39;Computer Modern Roman&#39;], # Times, Palatino, New Century Schoolbook, Bookman, Computer Modern Roman &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, } plt.rcParams.update(params) plt.ion() fig = plt.figure(figsize=(9.6,5.4),dpi=100) # 1920x1080 fig.subplots_adjust(left=0, right=1, top=1, bottom=0,hspace=0.02,wspace=0.02) ax = fig.add_subplot(111) ax.axis(&#39;off&#39;) # no frame def plot_last_seconds(data,index): &quot;&quot;&quot; Plots a line with the trajectory of the tip of pendulum 2 (x2,y2) &quot;&quot;&quot; how_long = 1.0 # seconds n = int(how_long/time[2]) to_plot = data[:index,:] if index &lt; n: prepend = np.tile(data[0],(n-index,1)) to_plot = np.vstack([prepend,to_plot]) index = n colormap = plt.cm.Greys_r colors = [colormap(i) for i in np.linspace(0.0, 1.0, n-1)] plots = [] for j in np.arange(n-1): p, = ax.plot(to_plot[index-j-1:index-j+1,3],to_plot[index-j-1:index-j+1,4], color=colors[j], zorder=-1) plots.append(p) return plots # &quot;plot&quot; returns a tuple of line objects, thus the comma t,x1,y1,x2,y2 = data_TXY[0] line1, = ax.plot([0.0,x1], [0.0,y1], &#39;r-&#39;) line2, = ax.plot([x1,x2], [y1,y2], &#39;r-&#39;) circ1, = ax.plot([x1], [y1], &#39;ro&#39;,markersize=10) circ2, = ax.plot([x2], [y2], &#39;ro&#39;,markersize=10) sizeY = 1.2 ax.axis([-sizeY*16/9,sizeY*16/9,-sizeY,sizeY]) frame_names = [] tex=ax.text(0.0,0.85,&#39;&#39;,ha=&quot;center&quot;) for i,v in enumerate(data_TXY): t,x1,y1,x2,y2 = v # print(&quot;t={:.2f}&quot;.format(t)) # you might want to know how things are going... line1.set_data([0.0,x1],[0.0,y1]) line2.set_data([x1,x2],[y1,y2]) circ1.set_data([x1],[y1]) circ2.set_data([x2],[y2]) # plot_last_seconds considerably slows down the simulation, # but makes it much prettier... pls = plot_last_seconds(data_TXY,i+1) tex.set_text(r&quot;$t={:.3f}$ s&quot;.format(t)) fig.canvas.draw() if make_movie: fname = &quot;_tmp{:05d}.png&quot;.format(i) frame_names.append(fname) fig.savefig(fname,bbox_inches=&#39;tight&#39;) for k in pls: k.remove() if make_movie: frames = &quot;_tmp%5d.png&quot; frames = &quot;_tmp%5d.png&quot; movie_command = &quot;ffmpeg -y -r {:} -i {:} double.mp4&quot;.format(fps,frames) os.system(movie_command) for fname in frame_names: os.remove(fname) .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/doublependulum.html",
            "relUrl": "/jupyter/2020/01/01/doublependulum.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post55": {
            "title": "Contour plots",
            "content": ". Introduction . Contour plots are great to show how a variable depends on two parameters. . The code . import numpy as np import matplotlib.pyplot as plt import matplotlib from IPython.display import Math # %matplotlib inline . configure plotting preferences . # this is a latex constant, don&#39;t change it. pts_per_inch = 72.27 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) text_width_in_pts = 246.0 # inside a figure environment in latex, the result will be on the # dvi/pdf next to the figure. See url above. text_width_in_inches = text_width_in_pts / pts_per_inch # make rectangles with a nice proportion golden_ratio = 0.618 # figure.png or figure.eps will be intentionally larger, because it is prettier inverse_latex_scale = 2 # when compiling latex code, use # includegraphics[scale=(1/inverse_latex_scale)]{figure} # we want the figure to occupy 2/3 (for example) of the text width fig_proportion = (3.0 / 3.0) csize = inverse_latex_scale * fig_proportion * text_width_in_inches # always 1.0 on the first argument fig_size = (1.0 * csize,golden_ratio * csize) # find out the fontsize of your latex text, and put it here text_size = inverse_latex_scale * 12 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {&#39;backend&#39;: &#39;ps&#39;, &#39;axes.labelsize&#39;: text_size, &#39;legend.fontsize&#39;: tick_size, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # Times, Palatino, New Century Schoolbook, # Bookman, Computer Modern Roman &#39;font.serif&#39;: [&#39;Times&#39;], &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, # include here any neede package for latex &#39;text.latex.preamble&#39;: [r&#39; usepackage{amsmath}&#39;, ], } plt.rcParams.update(params) plt.ioff() plt.clf() # figsize accepts only inches. fig = plt.figure(1, figsize=fig_size) fig.subplots_adjust(left=0.12, right=0.96, top=0.96, bottom=0.18, hspace=0.02, wspace=0.02) ax = fig.add_subplot(111) . def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=256): new_cmap = matplotlib.colors.LinearSegmentedColormap.from_list( &#39;trunc({n},{a:.2f},{b:.2f})&#39;.format(n=cmap.name, a=minval, b=maxval), cmap(np.linspace(minval, maxval, n))) return new_cmap cmap = plt.get_cmap(&#39;YlOrBr&#39;) my_cmap = truncate_colormap(cmap, 0.2, 0.9) . minX = 0 maxX = 10 minY = 0 maxY = 3 N = 50j y, x = np.mgrid[minY:maxY:N, minX:maxX:N] z = 2 * np.exp(-(0.02 * (x + 1) ** 2 + 0.05 * (y - 3.1) **2 )) divisions = np.arange(0.3, 2.1, 0.3) divisions2 = np.append(divisions, 2.5) divisions2 = np.append(-0.5, divisions2) # contour filled with colors ax.contourf(x, y, z, divisions2, cmap=my_cmap, vmin=0.0,vmax=2.0) # contour lines cont = ax.contour(x, y, z, divisions, colors=2 * [&#39;black&#39;] + [&#39;green&#39;] + 3 * [&#39;black&#39;], linewidth=.5) zcontour = cont.collections[1] dash1=(15, 10, 15, 10) zcontour.set_dashes([(0, dash1)]) zcontour = cont.collections[4] dash2=(20, 30) zcontour.set(color=&#39;blue&#39;, linestyle=[(0, dash2)], linewidth=4) # labels manual_locations = [(1.0, 2.5), (2.5, 2.5), (3.8, 2.5), (5.0, 2.5), (6.2, 2.5), (8.3, 2.5)] ax.clabel(cont, inline=1, fontsize=tick_size, fmt=&#39;z=%.2f%%&#39;, manual=manual_locations, colors=5 * [&#39;black&#39;] + [&#39;white&#39;]) ax.set_xlabel(r&quot;$x$ axis&quot;) ax.set_ylabel(r&quot;$y$ axis&quot;) fig . /Users/yairmau/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: The following kwargs were not used by contour: &#39;linewidth&#39; . %matplotlib notebook fig.savefig(&quot;./python_figures/contours.png&quot;,dpi=300) # fig.savefig(&quot;cont.eps&quot;) .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/contours.html",
            "relUrl": "/jupyter/2020/01/01/contours.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post56": {
            "title": "What's the best path to save someone from drowning?",
            "content": ". Introduction . Snell&#39;s law of refraction can be understood in this example, where the lifeguard wants to minimize the time it takes to get to the drowning person. . Code . import matplotlib import matplotlib.pyplot as plt import numpy as np . # this is a latex constant, don&#39;t change it. pts_per_inch = 72.27 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) text_width_in_pts = 252.0 # inside a figure environment in latex, the result will be on the # dvi/pdf next to the figure. See url above. text_width_in_inches = text_width_in_pts / pts_per_inch # make rectangles with a nice proportion golden_ratio = 0.618 # figure.png or figure.eps will be intentionally larger, because it is prettier inverse_latex_scale = 2 # when compiling latex code, use # includegraphics[scale=(1/inverse_latex_scale)]{figure} # we want the figure to occupy 2/3 (for example) of the text width fig_proportion = (3.0 / 3.0) csize = inverse_latex_scale * fig_proportion * text_width_in_inches # always 1.0 on the first argument fig_size = (1.0 * csize,golden_ratio * csize) # find out the fontsize of your latex text, and put it here text_size = inverse_latex_scale * 12 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {&#39;axes.labelsize&#39;: text_size, &#39;legend.fontsize&#39;: tick_size, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # Times, Palatino, New Century Schoolbook, # Bookman, Computer Modern Roman # &#39;font.serif&#39;: [&#39;Times&#39;], # &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, # include here any neede package for latex &#39;text.latex.preamble&#39;: [r&#39; usepackage{amsmath}&#39;, ], } plt.rcParams.update(params) # plt.clf() # figsize accepts only inches. plt.ioff() fig = plt.figure(1, figsize=fig_size) fig.subplots_adjust(left=0.0, right=1.0, top=1.0, bottom=0.0, hspace=0.02, wspace=0.02) ax = fig.add_subplot(111) . origin = [0, 0] lifeguard = [-3, -2] drowning = [2, 3] ax.set_xticks([]) ax.set_yticks([]) xlim = [-4, 4] ylim = [-4, 4] ax.axis([xlim[0], xlim[1], ylim[0], ylim[1]]) ##### drowning ##### # line ax.plot([origin[0], drowning[0]], [origin[1], drowning[1]], color=&quot;black&quot;, lw=2) # diamond ax.plot(drowning[0], drowning[1], &quot;D&quot;, markerfacecolor=&quot;black&quot;, markersize=10, markeredgewidth=3, color=&quot;black&quot;) # explanation ax.text(drowning[0], drowning[1] - 0.3, r&quot;drowning&quot;, verticalalignment=&quot;top&quot;) ax.text(drowning[0], drowning[1] - 0.8, r&quot;person&quot;, verticalalignment=&quot;top&quot;) ##### lifeguard ##### # line ax.plot([origin[0], lifeguard[0]], [origin[1], lifeguard[1]], color=&quot;black&quot;, lw=2) # circle ax.plot(lifeguard[0], lifeguard[1], &quot;o&quot;, markerfacecolor=&quot;black&quot;, markersize=10, markeredgewidth=3, color=&quot;black&quot;) # explanation ax.text(lifeguard[0], lifeguard[1] - 0.3, r&quot;lifeguard&quot;, verticalalignment=&quot;top&quot;) . Text(-3, -2.3, &#39;lifeguard&#39;) . background colors . sand = matplotlib.patches.Rectangle([xlim[0], ylim[0]], (xlim[1] - xlim[0]), (ylim[1] - ylim[0]) / 2.0, color=&quot;yellow&quot;, alpha=0.6) ax.add_patch(sand) sea = matplotlib.patches.Rectangle([xlim[0], 0], (xlim[1] - xlim[0]), (ylim[1] - ylim[0]) / 2.0, color=&quot;blue&quot;, alpha=0.4) ax.add_patch(sea) ###### sand ##### ax.text(0.95, 0.05, r&quot;(1) sand&quot;, transform=ax.transAxes, horizontalalignment=&#39;right&#39;) ###### sea ##### ax.text(0.95, 0.50, r&quot;(2) sea&quot;, transform=ax.transAxes, horizontalalignment=&#39;right&#39;, verticalalignment=&quot;bottom&quot;) . Text(0.95, 0.5, &#39;(2) sea&#39;) . spines through origin . ax.spines[&#39;left&#39;].set_position(&#39;zero&#39;) ax.spines[&#39;right&#39;].set_color(&#39;none&#39;) ax.spines[&#39;bottom&#39;].set_position(&#39;zero&#39;) ax.spines[&#39;top&#39;].set_color(&#39;none&#39;) ax.spines[&#39;left&#39;].set_smart_bounds(False) ax.spines[&#39;bottom&#39;].set_smart_bounds(False) # ax.xaxis.set_ticks_position(&#39;bottom&#39;) # ax.yaxis.set_ticks_position(&#39;left&#39;) ax.set_xticks([]) ax.set_yticks([]) . [] . annotations . ax.annotate(&quot;&quot;, xy=(lifeguard[0] - 0.3, lifeguard[1]), xycoords=&#39;data&#39;, xytext=(lifeguard[0] - 0.3, 0), textcoords=&#39;data&#39;, size=tick_size, arrowprops=dict(arrowstyle=&quot;&lt;-&gt;&quot;, connectionstyle=&quot;arc3&quot;), ) ax.text(lifeguard[0] - 0.2, lifeguard[1] / 2.0, r&quot;$h_1$&quot;, verticalalignment=&quot;center&quot;, horizontalalignment=&quot;left&quot;) # h_2 ax.annotate(&quot;&quot;, xy=(lifeguard[0] - 0.3, drowning[1]), xycoords=&#39;data&#39;, xytext=(lifeguard[0] - 0.3, 0), textcoords=&#39;data&#39;, size=tick_size, arrowprops=dict(arrowstyle=&quot;&lt;-&gt;&quot;, connectionstyle=&quot;arc3&quot;), ) ax.text(lifeguard[0] - 0.2, drowning[1] / 2.0, r&quot;$h_2$&quot;, verticalalignment=&quot;center&quot;, horizontalalignment=&quot;left&quot;) # L ax.annotate(&quot;&quot;, xy=(lifeguard[0], drowning[1] + 0.3), xycoords=&#39;data&#39;, xytext=(drowning[0], drowning[1] + 0.3), textcoords=&#39;data&#39;, size=tick_size, arrowprops=dict(arrowstyle=&quot;&lt;-&gt;&quot;, shrinkA=0, shrinkB=0, connectionstyle=&quot;arc3&quot;), ) ax.text((lifeguard[1] - lifeguard[0]) / 2.0, drowning[1] + 0.3, r&quot;$L$&quot;, verticalalignment=&quot;bottom&quot;, horizontalalignment=&quot;left&quot;) # l1 ax.text(lifeguard[0] / 2.0, 1.10 * lifeguard[1] / 2.0, r&quot;$ ell_1$&quot;, verticalalignment=&quot;top&quot;, horizontalalignment=&quot;left&quot;) # l2 ax.text(drowning[0] / 2.0, 0.95 * drowning[1] / 2.0, r&quot;$ ell_2$&quot;, verticalalignment=&quot;top&quot;, horizontalalignment=&quot;left&quot;) # theta_1 ax.annotate(&quot;&quot;, xy=(0, 0.5 * lifeguard[1]), xycoords=&#39;data&#39;, xytext=(0.2 * lifeguard[0], 0.2 * lifeguard[1]), textcoords=&#39;data&#39;, size=tick_size, arrowprops=dict(arrowstyle=&quot;-&quot;, lw=2, connectionstyle=&quot;angle3,angleA=-60,angleB=0&quot;), ) ax.text(0.1 * lifeguard[0], 0.5 * lifeguard[1], r&quot;$ theta_1$&quot;, verticalalignment=&quot;top&quot;, horizontalalignment=&quot;right&quot;) # theta_2 ax.annotate(&quot;&quot;, xy=(0, 0.3 * drowning[1]), xycoords=&#39;data&#39;, xytext=(0.2 * drowning[0], 0.2 * drowning[1]), textcoords=&#39;data&#39;, size=tick_size, arrowprops=dict(arrowstyle=&quot;-&quot;, lw=2, connectionstyle=&quot;angle3,angleA=120,angleB=0&quot;), ) ax.text(0.1 * drowning[0], 0.5 * drowning[1], r&quot;$ theta_2$&quot;, verticalalignment=&quot;top&quot;, horizontalalignment=&quot;left&quot;) . Text(0.2, 1.5, &#39;$ theta_2$&#39;) . %matplotlib inline fig.savefig(&quot;python_figures/bestpath.png&quot;, dpi=300) fig .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/bestpath.html",
            "relUrl": "/jupyter/2020/01/01/bestpath.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post57": {
            "title": "Bar plot",
            "content": ". Introduction . This code produces the figure above. Here we showcase the use of unicode text. . The code . from __future__ import unicode_literals import numpy as np import matplotlib import matplotlib.pyplot as plt from bidi import algorithm as bidialg # needed for arabic, hebrew import arabic_reshaper # needed for arabic . ModuleNotFoundError Traceback (most recent call last) &lt;ipython-input-2-aaa74850711b&gt; in &lt;module&gt; 4 import matplotlib.pyplot as plt 5 from bidi import algorithm as bidialg # needed for arabic, hebrew -&gt; 6 import arabic_reshaper # needed for arabic ModuleNotFoundError: No module named &#39;arabic_reshaper&#39; . pts_per_inch = 72.27 # this is a latex constant, don&#39;t change it. text_width_in_pts = 300.0 # write &quot; the textwidth&quot; (or &quot; showthe columnwidth&quot; for a 2 collumn text) # inside a figure environment in latex, the result will be on the dvi/pdf next to the figure. See url above. text_width_in_inches=text_width_in_pts/pts_per_inch golden_ratio = 0.618 # make rectangles with a nice proportion inverse_latex_scale = 2 # figure.png or figure.eps will be intentionally larger, because it is prettier # when compiling latex code, use includegraphics[scale=(1/inverse_latex_scale)]{figure} fig_proportion = (3.0 / 3.0) # we want the figure to occupy 2/3 (for example) of the text width csize = inverse_latex_scale * fig_proportion * text_width_in_inches fig_size = (1 * csize, 1.3 * csize) # always 1.0 on the first argument text_size = inverse_latex_scale * 10 # find out the fontsize of your latex text, and put it here label_size = inverse_latex_scale * 10 tick_size = inverse_latex_scale * 8 # learn how to configure: # http://matplotlib.sourceforge.net/users/customizing.html params = {&#39;backend&#39;: &#39;ps&#39;, &#39;axes.labelsize&#39;: 16, &#39;legend.fontsize&#39;: 14, &#39;legend.handlelength&#39;: 2.5, &#39;legend.borderaxespad&#39;: 0, &#39;axes.labelsize&#39;: label_size, &#39;xtick.labelsize&#39;: tick_size, &#39;ytick.labelsize&#39;: tick_size, # &#39;font.family&#39;: &#39;serif&#39;, &#39;font.size&#39;: text_size, # &#39;font.serif&#39;: [&#39;Computer Modern Roman&#39;], &#39;ps.usedistiller&#39;: &#39;xpdf&#39;, # &#39;text.usetex&#39;: True, &#39;figure.figsize&#39;: fig_size, #&#39;text.latex.unicode&#39;: True, } plt.rcParams.update(params) plt.ioff() fig = plt.figure(1, figsize=fig_size) # figsize accepts only inches. fig.clf() dpi = 100 pixel_size = (700,700) fig_size = (pixel_size[0]/dpi,pixel_size[1]/dpi) ax1=fig.add_subplot(211) ax2=fig.add_subplot(212) fig.subplots_adjust(left=0.30, right=0.97, top=0.95, bottom=0.06, hspace=0.2, wspace=0.1) . words = [u&#39;Fußball Ångström nsøster Россия&#39;, u&#39;français maître nvoilà égoïste&#39;, u&#39;España&#39;, u&#39;İstanbul ağzı&#39;, u&#39;Anything Unicode&#39; ] values1 = [2575, 5851, 3191, 2303, 3029] values2 = [4813, 5219, 5505, 6229, 6961] values1 = np.array(values1) values2 = np.array(values2) width = 0.35 # the width of the bars r = np.arange(len(values1)) . ax1 , horizontal bars . v1 = ax1.barh(r, values1, width, color=&#39;pink&#39;) v2 = ax1.barh(r + width, values2, width, color=&#39;brown&#39;) ax1.axis([0, 8600, r.min() - 0.3, r.max() + 1]) ax1.set_yticks(r) ax1.set_yticks(r + 1 * width) ax1.set_yticklabels(words) xt = np.arange(0, 8100, 1000) ax1.set_xticks(xt) ax1.set_xticklabels(xt) ax1.set_xlabel(u&#39;the values&#39;, fontsize=16) ax1.set_title(u&#39;Title here&#39;, fontsize=18) ax1.xaxis.grid(True) ax1.tick_params( axis=&#39;y&#39;, # changes apply to the y-axis which=&#39;both&#39;, # both major and minor ticks are affected left=&#39;off&#39;, # ticks along the left edge are off right=&#39;off&#39;, # ticks along the right edge are off labelleft=&#39;on&#39;) # labels along the bottom edge are on ax1.legend((v1, v2), (u&#39;2016&#39;, u&#39;2015&#39;), loc=(0.74,0.05)) def autolabel_hor(rects,ax, offset_x, offset_y): # attach some text labels at the tip of the bars for i,rect in enumerate(rects): width = rect.get_width() height = rect.get_height() ax.text(width + offset_x, rect.get_y() + offset_y * height, &#39;%d&#39; % int(width), ha=&#39;left&#39;, va=&#39;bottom&#39;, fontsize=14) autolabel_hor(v1, ax1, 100.0, -0.20) autolabel_hor(v2, ax1, 100.0, -0.10) . ax2, vertical bars . from bidi import algorithm as bidialg w1 = ax2.bar(r, values1, width, color=&#39;pink&#39;) w2 = ax2.bar(r + width, values2, width, color=&#39;brown&#39;) ax2.axis([r.min() - 0.3, r.max() + 1, 0, 8600]) ax2.set_xticks(r) ax2.set_xticks(r + 1 * width) shalom = bidialg.get_display(u&#39;שלום&#39;) salam = bidialg.get_display(arabic_reshaper.reshape(u&#39;سلام&#39;)) ax2.set_xticklabels([shalom, salam, &#39;ccc&#39;, &#39;ddd&#39;, &#39;eee&#39;]) xt = np.arange(0, 8200, 1000) ax2.set_yticks(xt) ax2.set_yticklabels(xt) ax2.yaxis.grid(True) ax2.tick_params( axis=&#39;x&#39;, # changes apply to the x-axis which=&#39;both&#39;, # both major and minor ticks are affected top=&#39;off&#39;, # ticks along the top edge are off bottom=&#39;off&#39;, # ticks along the bottom edge are off labelbottom=&#39;on&#39;) # labels along the bottom edge are on ax2.legend((w1, w2), (u&#39;2016&#39;, u&#39;2015&#39;), loc=&quot;upper center&quot;) def autolabel_ver(rects,ax, offset_x, offset_y): # attach some text labels at the tip of the bars for i,rect in enumerate(rects): width = rect.get_width() height = rect.get_height() ax.text(rect.get_x() + offset_x * width, height + offset_y, &#39;%d&#39; % int(height), ha=&#39;left&#39;, va=&#39;bottom&#39;, fontsize=14) autolabel_ver(w1, ax2, -0.3, 100.0) autolabel_ver(w2, ax2, 0., 100.0) . %matplotlib inline fig.savefig(&quot;./python_figures/bars.png&quot;) plt.show() fig .",
            "url": "https://yairmau.github.io/website/jupyter/2020/01/01/bars.html",
            "relUrl": "/jupyter/2020/01/01/bars.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://yairmau.github.io/website/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Artigos",
          "content": "",
          "url": "https://yairmau.github.io/website/more/artigos/",
          "relUrl": "/more/artigos/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "",
          "content": " This is my personal website.  I put here a lot of random stuff.  Use the menu above to navigate. . .   Click here if you are looking for my professional website. . . . Piet Hein Problems worthy   of attack prove their worth   by hitting back. .",
          "url": "https://yairmau.github.io/website/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
      ,"page4": {
          "title": "Books",
          "content": "my read shelf:&lt;a href=”https://www.goodreads.com/review/list/52721996?shelf=read” title=”Yair Mau’s book recommendations, liked quotes, book clubs, book trivia, book lists (read shelf)”, rel=”nofollow”&gt;&lt;/a&gt; .",
          "url": "https://yairmau.github.io/website/more/books/",
          "relUrl": "/more/books/",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "More",
          "content": "Books . Artigos . Five-star Content .",
          "url": "https://yairmau.github.io/website/more/",
          "relUrl": "/more/",
          "date": ""
      }
      
  

  
      ,"page6": {
          "title": "Geek stuff",
          "content": "",
          "url": "https://yairmau.github.io/website/blog/geek/",
          "relUrl": "/blog/geek/",
          "date": ""
      }
      
  

  
      ,"page7": {
          "title": "Five-Star Content I Recommend",
          "content": "Books . [Check out my Goodreads profile]. . Superintelligence: Paths, Dangers, Strategies, by Nick Bostrom. | The Unfolding of Language: An Evolutionary Tour of Mankind’s Greatest Invention, by Guy Deutscher. | . Blogs . Wait but why, by Tim Urban. | Fuck Yeah Fluid Dynamics, by Nicole Sharp. | . Short stories . They’re made out of meat, by Terry Bisson. | The Sentinel, by Arthur C. Clarke. | On Exactitude in Science, by Jorge Luis Borges. | The Feeling Of Power , by Isaac Asimov. | . Technical stuff . Linux Shell Scripting Tutorial | Pythonic Perambulations, by Jake VanderPlas. | . YouTube channels . 3Blue1Brown, minute physics, Veritasium, Smarter Every Day, CGP Grey, Kurzgesagt, Primitive Technology, Vsauce, Nerdwriter, Mathologer, Sciencium, Steve Mould . Podcasts . Hardcore History with Dan Carlin, especially the series “Blueprint for Armageddon” and “Wrath of the Khans”. | 99% Invisible | Revisionist History | Lexicon Valley | Making Sense, with Sam Harris | .",
          "url": "https://yairmau.github.io/website/more/five-stars/",
          "relUrl": "/more/five-stars/",
          "date": ""
      }
      
  

  
      ,"page8": {
          "title": "Blog",
          "content": "Geek thoughts . This is where I write about random geek/math/puzzles stuff . Art . Art, origami, mathematical constructions, music, random projects . . . Selected blogposts . Here are a few blogposts that you might find interesting .",
          "url": "https://yairmau.github.io/website/blog/",
          "relUrl": "/blog/",
          "date": ""
      }
      
  

  
      ,"page9": {
          "title": "Art",
          "content": "",
          "url": "https://yairmau.github.io/website/blog/art/",
          "relUrl": "/blog/art/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
      ,"page16": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://yairmau.github.io/website/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}