{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Evapotranspiration\n",
    "\n",
    "- toc: false \n",
    "- badges: true\n",
    "- comments: false\n",
    "- categories: [jupyter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  instructions\n",
    "This is where learning happens, not during a lecture. You'll learn a ton of things by doing them yourself. Much success! \n",
    "\n",
    "Create a Jupyter Notebook called `assignment-02-IDNUMBER`, where `IDNUMBER` is your 9-digit ID. This is the file only file we will check.\n",
    "\n",
    "##  locations and data\n",
    "\n",
    "**Choose two stations with different climates.**\n",
    "\n",
    "Go to NOAA's [Climate Reference Network Data](https://www.ncdc.noaa.gov/crn/qcdatasets.html) website. The sub-hourly (5-min) data contains information on\n",
    "* air temperature,\n",
    "* precipitation,\n",
    "* global solar radiation,\n",
    "* surface infrared temperature,\n",
    "* relative humidity,\n",
    "* soil moisture and temperature,\n",
    "* wetness, and\n",
    "* 1.5 meter wind speed. \n",
    "There is no data on air pressure, so one needs to use the stations coordinates (lat, lon) to find its height above sea level, and from that infer the air pressure. You can use Google Earth or any other means to find the station's height.\n",
    "\n",
    "In the Data Access link, choose a year and a station you would like to analyze. If you are not sure where the stations are, find them using the 2-letter state abbreviation and the station name.\n",
    "\n",
    "Download the following files:\n",
    "1. One full year of data for each station. Make sure important data we need to calculate Penman's ET estimation is available.\n",
    "2. The headers file\n",
    "3. The documentation file\n",
    "\n",
    "Make sure you understand what are the units provided for each measurement (see documentation).\n",
    "\n",
    "##  tasks\n",
    "\n",
    "Produce potential ET estimates using Thornthwaite's equation and Penman's equation.\n",
    "Produce plots of ET as a function of time for each station, comparing the two methods you used.\n",
    "Also, using Penman's ET estimates, compare the two stations and discuss about their differences/similarities.\n",
    "\n",
    "You might find interesting things in the data, such as periods of unusually high/low temperatures, radiation, etc. Discuss how these factors might have affected the ET estimates that you calculated.\n",
    "\n",
    "You will have **two weeks** to deliver your assignment. You should **not** hand in a dry document with only figures and code, I'm expecting text before and after each code/graph cell, explaining what you did, why you did it, and how it fits the story you are telling. Don't forget to put labels on your plot axes, title, legend, etc.  \n",
    "\n",
    "Your Jupyter Notebook should be **fully functional**: if we press `Kernel > Restart & Run All`, all the code must work without any errors.\n",
    "\n",
    "##  presentation\n",
    "All the assignment must be in **one single** Jupyter Notebook. Use markdown cells to discuss the analysis and results, and in code cells show **all the code** you used to produce the figures and data analysis. Leave only the code necessary for your analysis, delete unnecessary lines your wrote while analyzing your data. Don't forget to comment your code, just like we did during exercise sessions.  \n",
    "\n",
    "You can write in English or in Hebrew, but the text in the figures must be in English. If you choose to write the discussion in Hebrew, be aware that Jupyter Notebooks don't have native right-to-left language support:\n",
    "\n",
    "转 转 注专转, 专转 砖  专 状 ...\n",
    "\n",
    "You can use some HTML code to achieve best results in Hebrew. Type the following\n",
    "```html\n",
    "<p dir=\"rtl\" style=\"text-align: right;\">\n",
    "注砖 专 转专 !\n",
    "</p>\n",
    "```\n",
    "to get\n",
    "<p dir=\"rtl\" style=\"text-align: right;\">\n",
    "注砖 专 转专 !\n",
    "</p> \n",
    "\n",
    "If you have many paragraphs in hebrew, do the following: \n",
    "<p dir=\"rtl\" style=\"text-align: right;\">\n",
    "驻住拽 住驻专 1.\n",
    "</p>\n",
    "\n",
    "<p dir=\"rtl\" style=\"text-align: right;\">\n",
    "驻住拽 住驻专 2.\n",
    "</p>\n",
    "\n",
    "\n",
    "<p dir=\"rtl\" style=\"text-align: right;\">\n",
    " 砖   驻住拽转,  转  转 转 \"dir\" 砖\n",
    "</p>\n",
    "\n",
    "In my opinion it is too complicated to write in Hebrew in Jupyter Notebooks, just write in English, your grade will not be affected by typos nor less-than-perfect English proficiency.\n",
    "\n",
    "##  evaluation\n",
    "\n",
    "Your assignment will be evaluated according to the following criteria:\n",
    "* 40% Presentation. How the graphs look, labels, general organization, markdown, clean code.\n",
    "* 30% Discussion. This is where you explain what you did, what you found out, etc.\n",
    "* 15% Depth of analysis. You can analyze/explore the data with different levels of complexity, this is where we take that into consideration.\n",
    "* 10% Replicability: Your code runs flawlessly.\n",
    "* 5%: Code commenting. Explain in your code what you are doing, this is good for everyone, especially for yourself!\n",
    "\n",
    "\n",
    "##  importing the data\n",
    "\n",
    "Below you can find an example of how to import the data file provided by NOAA's Climate Reference Network Data website. You might have to make some adjustments to it.\n",
    "\n",
    "```python\n",
    "data_file = \"CRNS0101-05-2020-CO_Boulder_14_W.txt\"\n",
    "df = pd.read_csv(data_file,\n",
    "                 header=None,                      # no headers needed, we'll do that later\n",
    "                 delim_whitespace=True,            # blank spaces separate between columns\n",
    "                 na_values=[\"-99.000\", \"-9999.0\"]  # substitute these values for missing (NaN) values\n",
    "                )\n",
    "headers = pd.read_csv(\"HEADERS_sub_hourly.txt\",    # load headers file\n",
    "                      header=1,                    # skip the first [0] line\n",
    "                      delim_whitespace=True\n",
    "                     )\n",
    "df.columns = headers.columns                       # rename df columns with headers columns\n",
    "# LST = local standard time\n",
    "df[\"LST_TIME\"] = [f\"{x:04d}\" for x in df[\"LST_TIME\"]]  # time needs padding of zeros, then convert to string\n",
    "df['LST_DATE'] = df['LST_DATE'].astype(str)            # convert date into string\n",
    "df['datetime'] = df['LST_DATE'] + ' ' + df['LST_TIME'] # combine date+time into datetime\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])        # interpret datetime\n",
    "df = df.set_index('datetime')                          # make datetime the index\n",
    "df\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
